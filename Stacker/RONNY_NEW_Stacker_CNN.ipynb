{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RONNY_NEW_Stacker_CNN.ipynb","provenance":[{"file_id":"1FXi3zbfBALx2XXt1jIIKwQNEDHamDAF5","timestamp":1599517612626},{"file_id":"1Rq3CggdBxoUZfFxO5ltiJuMAW9ZfP2eo","timestamp":1599461231248},{"file_id":"1VyIF-R13cftYaFnZuZiWNIGO7Cv4w1Iv","timestamp":1599418520736}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KOnYzVBxcT93","colab_type":"code","colab":{}},"source":["!pip install --upgrade pandas==0.25.3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3arOHSJwCtNq","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3a3kmo_dFfJ","colab_type":"code","colab":{}},"source":["#import necessary dependecies\n","import plotly.express as px\n","import seaborn as sns\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier,ExtraTreesClassifier,VotingClassifier\n"," \n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.cluster import KMeans\n","import math\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.pipeline import Pipeline\n","import os\n","import warnings\n","import numpy as np  \n","import seaborn as sns\n","import pandas as pd, os, gc\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc, log_loss\n","from sklearn.feature_selection import mutual_info_classif\n","from sklearn.preprocessing import StandardScaler, RobustScaler\n","%matplotlib inline\n","warnings.filterwarnings('ignore')\n","from typing import List\n","import tensorflow as tf\n","import random\n","from tqdm import tqdm \n","import copy\n"," \n","tf.random.set_seed(111)\n","np.random.seed(111)\n","random.seed(111)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FMGIYgAlyTXB","colab_type":"code","colab":{}},"source":["def attention_3d_block(inputs, name):\n","  # inputs.shape = (batch_size, time_steps, input_dim)\n","  TIME_STEPS = inputs.shape[1]\n","  SINGLE_ATTENTION_VECTOR = False\n","  \n","  input_dim = inputs.shape[2]\n","  a = Permute((2, 1))(inputs)\n","  a = Dense(TIME_STEPS, activation='softmax')(a)\n","  if SINGLE_ATTENTION_VECTOR:  \n","    a = Lambda(lambda x: K.mean(x, axis=1))(a)\n","    a = RepeatVector(input_dim)(a)\n","  a_probs = Permute((2, 1), name=name)(a)\n","  output_attention_mul = Multiply()([inputs, a_probs])\n","  return output_attention_mul"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nrGyB3OIzd78","colab_type":"code","colab":{}},"source":["import keras\n","from keras.layers import *\n","from keras.optimizers import Adam\n","from keras.models import Model\n","from keras.initializers import glorot_normal\n","from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n","from keras.regularizers import l2\n","\n","def get_model():\n","  tf.random.set_seed(1)\n","  np.random.seed(1)\n","  random.seed(1)\n","    \n","  input_tensor = Input(shape=(1,df_train.shape[1]))\n","\n","  x = Conv1D(64, 5,strides=5,padding='same',activation='relu')(input_tensor)\n","  x = attention_3d_block(x, 'attention_vec_1')\n","  x = Dropout(0.15)(x)\n","\n","  x = Conv1D(128, 4,strides=3,padding='same',activation='relu')(x)\n","  x = attention_3d_block(x, 'attention_vec_2')\n","  x = Dropout(0.15)(x)\n","\n","  x = Conv1D(256, 3,strides=3,padding='same',activation='relu')(x)\n","  x = attention_3d_block(x, 'attention_vec_3')\n","  x = Dropout(0.15)(x)\n","\n","  x = GlobalMaxPooling1D()(x)\n","\n","  x = Dropout(0.15)(x)\n","\n","  out = Dense(21,kernel_initializer=glorot_normal(seed=1),\n","              bias_initializer=glorot_normal(seed=1),\n","              activation=\"softmax\")(x)\n","\n","  model = Model(inputs=input_tensor,outputs =out)\n","\n","  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hHXGrWSwdpQp","colab_type":"code","colab":{}},"source":["from sklearn.multiclass import OneVsRestClassifier,OneVsOneClassifier\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n","from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier,GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import GridSearchCV,StratifiedKFold\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.pipeline import make_pipeline\n","from sklearn.impute import SimpleImputer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j4sxXpQoHqFu","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder,StandardScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3ZCXtzKDiDe","colab_type":"code","colab":{}},"source":["train_ = pd.read_csv('/content/drive/My Drive/ZimnatInsurance/Train.csv')\n","test_ = pd.read_csv('/content/drive/My Drive/ZimnatInsurance/Test.csv')\n","submission_ = pd.read_csv('/content/drive/My Drive/ZimnatInsurance/SampleSubmission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rx1uOaRsGG2M","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import KFold,GroupKFold\n","\n","def get_train_test_names(train_, test_, submission_):\n","  kf = KFold(n_splits=5, shuffle=False)\n","  for r, (train_index, test_index) in enumerate(kf.split(train_)):\n","    test = train_.iloc[test_index]\n","\n","    X_test = []\n","    X_test_columns = test.columns\n","    for v in test.values:\n","      info = v[:8]\n","      binary = v[8:]\n","      index = [k for k, i in enumerate(binary) if i == 1]\n","      for i in index:\n","        for k in range(len(binary)):\n","          if k == i:\n","            binary_transformed = list(copy.copy(binary))\n","            binary_transformed[i] = 0\n","            X_test.append(list(info) + binary_transformed)\n","\n","    X_test = pd.DataFrame(X_test)\n","    X_test.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n","          'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n","          '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n","          'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3']\n","    X_test['ID'] = [str(r)+'_'+str(i) for i in range(X_test.shape[0])]\n","\n","    yield train_.iloc[train_index], X_test, submission_, '0_fold' + str(r) + '.csv'\n","  yield train_, test_, submission_, '0_main.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pq9Hzf6Ms0BH","colab_type":"code","colab":{}},"source":["def process(df):\n","  binary_features = []\n","  df['IS_30H5'] = df['branch_code'] == '30H5'\n","  df['IS_30H5'] = df['IS_30H5'].astype('int')\n","\n","  df['IS_748L'] = df['branch_code'] == '748L'\n","  df['IS_748L'] = df['IS_748L'].astype('int')\n","\n","  df['IS_1X1H'] = df['branch_code'] == '1X1H'\n","  df['IS_1X1H'] = df['IS_1X1H'].astype('int')\n","\n","  df['IS_XX25'] = df['branch_code'] == 'XX25'\n","  df['IS_XX25'] = df['IS_XX25'].astype('int')\n","\n","  df['IS_O67J'] = df['branch_code'] == 'O67J'\n","  df['IS_O67J'] = df['IS_O67J'].astype('int')\n","\n","  df['IS_BOAS'] = df['branch_code'] == 'BOAS'\n","  df['IS_BOAS'] = df['IS_BOAS'].astype('int')\n","  \n","  df['IS_90QI'] = df['occupation_category_code'] == '90QI'\n","  df['IS_90QI'] = df['IS_90QI'].astype('int')\n","\n","  df['IS_56SI'] = df['occupation_category_code'] == '56SI'\n","  df['IS_56SI'] = df['IS_56SI'].astype('int')\n","\n","  \n","  \n","  df['IS_1982_1993_1984'] = df['birth_year'].apply(lambda x : 1 if x in [1993,1984,1982] else 0)\n","  df['IS_1982_1993_1984'] = df['IS_1982_1993_1984'].astype('int')\n","  \n","  #df['date3'] = df['date3'].astype('int')\n","  #df['IS_2019_2018'] = df['date3'].apply(lambda x : 1 if x in [2019,2018] else 0)\n","  #df['IS_2019_2018'] = df['IS_2019_2018'].astype('int')\n","  \n","  df['join_month'] = df['join_month'].astype('int')\n","  df['IS_5_4'] = df['join_month'].apply(lambda x : 1 if x in [4,5] else 0)\n","  df['IS_5_4'] = df['IS_5_4'].astype('int')\n","  \n","  df['age'] = df['age'].astype('int')\n","  df['IS_33_34_to_38'] = df['age'].apply(lambda x : 1 if x in [33,34,35,36,37,38] else 0)\n","  df['IS_33_34_to_38'] = df['IS_33_34_to_38'].astype('int')\n","\n","\n","  #df['IS_2019_2018_and_748L'] = df.apply(lambda x : 1 if (x['branch_code']=='748L' and x['date3'] in [2019,2018])  else 0 ,axis=1)\n","  \n","  #df['IS_2019_2018_and_T4MS'] = df.apply(lambda x : 1 if (x['occupation_category_code']=='90QI' and x['date3'] in [2019,2018])  else 0,axis=1)\n","\n","  df['IS_1993_1982_1984_and_748L'] = df.apply(lambda x : 1 if (x['branch_code']=='748L' and x['birth_year'] in [1993,1984,1982])  else 0,axis=1)\n","  \n","\n","  df['IS_1993_1982_1984_and_T4MS'] = df.apply(lambda x : 1 if (x['occupation_category_code']=='90QI' and x['birth_year'] in [1993,1984,1982])  else 0,axis=1)\n","  \n","\n","  df['IS_1993_1982_1984_and_month4'] = df.apply(lambda x : 1 if (x['join_month']==4 and x['birth_year'] in [1993,1984,1982])  else 0,axis=1)\n","  df['IS_1993_1982_1984_and_month5'] = df.apply(lambda x : 1 if (x['join_month']==5 and x['birth_year'] in [1993,1984,1982])  else 0,axis=1)\n","  \n","\n","\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_ELVeoVgv3v","colab_type":"text"},"source":["### Get folds"]},{"cell_type":"code","metadata":{"id":"oxjj_QAfEyZw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1599546699274,"user_tz":0,"elapsed":6994477,"user":{"displayName":"Ronny Polle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSUHi8xY87CD_SAU1iZlf4pZkMVcGnWvyQr3uhhQ=s64","userId":"03851089912616657277"}},"outputId":"be72cc3d-b966-4e0c-eb90-be249c4090aa"},"source":["for train, test, submission, name in get_train_test_names(train_, test_, submission_):\n","  X_train = []\n","  X_train_columns = train.columns\n","  c = 0\n","  for v in train.values:\n","    info = v[:8]\n","    binary = v[8:]\n","    index = [k for k, i in enumerate(binary) if i == 1]\n","    for i in index:\n","      c+=1\n","      for k in range(len(binary)):\n","        if k == i:\n","          binary_transformed = list(copy.copy(binary))\n","          binary_transformed[i] = 0\n","          X_train.append(list(info) + binary_transformed + [X_train_columns[8+k]] + [c])\n","\n","  X_train = pd.DataFrame(X_train)\n","  X_train.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n","        'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n","        '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n","        'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'product_pred', 'ID2']\n","\n","\n","  X_test = []\n","  true_values = []\n","  c = 0\n","  for v in test.values:\n","    c += 1\n","    info = v[:8]\n","    binary = v[8:]\n","    index = [k for k, i in enumerate(binary) if i == 1]\n","    X_test.append(list(info) + list(binary) + [c])\n","    for k in test.columns[8:][index]:\n","      true_values.append(v[0] + ' X ' + k)\n","\n","  X_test = pd.DataFrame(X_test)\n","  X_test.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n","        'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n","        '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n","        'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'ID2']\n","\n","\n","  features_train = []\n","  features_test = []\n","  columns = []\n","\n","  append_features = ['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', \n","  'N2MW', 'AHXO','BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', \n","  'ECY3', 'ID', 'ID2', 'join_date', 'sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',\n","  'birth_year']\n","  for v in append_features:\n","    features_train.append(X_train[v].values.reshape(-1, 1))\n","    features_test.append(X_test[v].values.reshape(-1, 1))\n","    columns.append(np.array([v]))\n","\n","  y_train = X_train[['product_pred']]\n","\n","\n","  features_train = np.concatenate(features_train, axis=1)\n","  features_test = np.concatenate(features_test, axis=1)\n","  columns = np.concatenate(np.array(columns))\n","\n","  X_train = pd.DataFrame(features_train)\n","  X_train.columns = columns\n","  X_test = pd.DataFrame(features_test)\n","  X_test.columns = columns\n","############################## fix code ##############################\n","  X_train.join_date = pd.to_datetime(X_train.join_date,)\n","  X_test.join_date = pd.to_datetime(X_test.join_date,)\n","\n","  X_train.join_date = pd.to_datetime(X_train.join_date, format=\"%Y-%m-%d\")\n","  X_test.join_date = pd.to_datetime(X_test.join_date, format=\"%Y-%m-%d\")\n","\n","  # new features\n","  X_train['num_products_subscribed'] = X_train.apply(lambda x : sum(x[X_train.columns[:21]]), axis = 1)\n","  X_train['join_month'] = X_train['join_date'].dt.month\n","  X_train['day_of_week'] = X_train['join_date'].dt.dayofweek\n","  X_train['day_of_week_name'] = X_train['join_date'].dt.weekday_name\n","  X_train['age'] = np.abs(X_train['join_date'].dt.year - X_train['birth_year'])\n","  X_train['join_time_elapsed'] = np.abs(2020 - X_train['join_date'].dt.year)\n","  X_train['current_age'] = np.abs(2020 - X_train['birth_year'])\n","  \n","  X_test['num_products_subscribed'] = X_test.apply(lambda x : sum(x[X_test.columns[:21]]), axis = 1)\n","  X_test['join_month'] = X_test['join_date'].dt.month\n","  X_test['day_of_week'] = X_test['join_date'].dt.dayofweek\n","  X_test['day_of_week_name'] = X_test['join_date'].dt.weekday_name\n","  X_test['join_time_elapsed'] = np.abs(2020 - X_test['join_date'].dt.year)\n","  X_test['age'] = np.abs( X_test['join_date'].dt.year - X_test['birth_year'])\n","  X_test['current_age'] = np.abs(2020 - X_test['birth_year'])\n","\n","\n","\n","        \n","  X_train = X_train.fillna(0)\n","  X_test = X_test.fillna(0)\n","  y_train = y_train.fillna(0)\n","\n","  X_train = process(X_train)\n","  X_test = process(X_test)\n","  \n","  # LABEL ENCODE\n","  enc = LabelEncoder()\n","  def encode_LE(train,test,cols,verbose=True):\n","    for col in cols:\n","  \n","      df_comb = pd.concat([train[col].astype('str'),test[col].astype('str')],axis=0)\n","      df_comb = enc.fit_transform(df_comb)\n","      nm = col\n","      if df_comb.max()>32000: \n","        train[nm] = df_comb[:len(train)].astype('int32')\n","        test[nm] = df_comb[len(train):].astype('int32')\n","      else:\n","        train[nm] = df_comb[:len(train)].astype('int16')\n","        test[nm] = df_comb[len(train):].astype('int16')\n","      del df_comb; x=gc.collect()\n","      if verbose: print(nm,', ',end='')\n","\n","  X_train.day_of_week_name = X_train.day_of_week_name.astype('str')\n","  X_test.day_of_week_name = X_test.day_of_week_name.astype('str')\n","  X_train.join_date = X_train.join_date.astype('str')\n","  X_test.join_date = X_test.join_date.astype('str')\n","\n","  data = X_train.append(X_test)\n","  for v in ['sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code','day_of_week_name','join_date']:\n","    data.loc[:,v] = enc.fit_transform(data.loc[:,v])\n","  X_train = data[:X_train.shape[0]]\n","  X_test = data[-X_test.shape[0]:]\n","\n","  enc.fit(y_train.iloc[:,0])\n","  y_train = pd.DataFrame(enc.transform(y_train.iloc[:,0]))\n","  y_train.columns = ['target']\n","\n","  X = X_train.drop(['ID','ID2'], axis=1)\n","  test = X_test.drop(['ID','ID2'], axis=1)\n","\n","  scaler = StandardScaler()\n","  \n","  \n","  X[['age']] = scaler.fit_transform(X[['age']])\n","  test[['age']] = scaler.fit_transform(test[['age']])\n","  \n","\n","  X[['birth_year']] = scaler.fit_transform(X[['birth_year']])\n","  test[['birth_year']] = scaler.fit_transform(test[['birth_year']])\n","\n","\n","  df_train =X.values\n","  df_test =test.values\n","  y = y_train.target\n","\n","  x = df_train.reshape(df_train.shape[0], 1,df_train.shape[1])\n","  xtest = df_test.reshape(df_test.shape[0],1,df_test.shape[1])\n","\n","############################### MODELING CODE : PAY attention :) ######################################\n"," \n","  sk = StratifiedKFold(n_splits= 5,random_state=1,shuffle=True)\n","\n","  es = EarlyStopping(monitor =\"val_loss\", mode =\"min\", verbose =1, patience = 50)\n","    \n","  cnn_predictions = list()\n","  \n","  for fold, (train_idx, test_idx) in enumerate(sk.split(x,y)):\n","  \n","    model = get_model()\n","  \n","    print('######### Training on Fold %i  #############'%(fold+1))\n","    \n","    #print(model.summary())\n","  \n","    model.fit( \n","        x[train_idx],\n","        y[train_idx],\n","        validation_data =(x[test_idx], y[test_idx]),\n","        callbacks =[es],\n","        epochs = 1000,\n","        batch_size = 1024)\n","    \n","    preds = model.predict(xtest, batch_size= 1024, verbose =1)\n","    cnn_predictions.append(preds)\n","    \n","  # get preds :D\n","  proba = np.average(cnn_predictions, axis=0)\n","  y_test = pd.DataFrame(proba)\n","  y_test.columns = enc.inverse_transform(y_test.columns)\n","\n","  answer_mass = []\n","  for i in range(X_test.shape[0]):\n","    id = X_test['ID'].iloc[i]\n","    for c in y_test.columns:\n","      answer_mass.append([id + ' X ' + c, y_test[c].iloc[i]])\n","\n","  df_answer = pd.DataFrame(answer_mass)\n","  df_answer.columns = ['ID X PCODE', 'Label']\n","  for i in range(df_answer.shape[0]):\n","    if df_answer['ID X PCODE'].iloc[i] in true_values:\n","      df_answer['Label'].iloc[i] = 1.0\n","\n","  df_answer.reset_index(drop=True, inplace=True)\n","  df_answer.to_csv(name, index=False)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["######### Training on Fold 1  #############\n","Epoch 1/1000\n","42/42 [==============================] - 4s 98ms/step - loss: 1.9276 - accuracy: 0.3489 - val_loss: 1.6977 - val_accuracy: 0.3861\n","Epoch 2/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 1.7101 - accuracy: 0.3746 - val_loss: 1.6629 - val_accuracy: 0.4486\n","Epoch 3/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 1.6685 - accuracy: 0.3946 - val_loss: 1.6176 - val_accuracy: 0.5385\n","Epoch 4/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 1.6016 - accuracy: 0.4584 - val_loss: 1.4418 - val_accuracy: 0.6282\n","Epoch 5/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 1.3568 - accuracy: 0.6062 - val_loss: 1.0150 - val_accuracy: 0.7112\n","Epoch 6/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 1.0521 - accuracy: 0.7003 - val_loss: 0.8896 - val_accuracy: 0.7368\n","Epoch 7/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.9308 - accuracy: 0.7307 - val_loss: 0.8079 - val_accuracy: 0.7659\n","Epoch 8/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.8674 - accuracy: 0.7477 - val_loss: 0.7688 - val_accuracy: 0.7774\n","Epoch 9/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.8143 - accuracy: 0.7617 - val_loss: 0.7095 - val_accuracy: 0.7941\n","Epoch 10/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.7722 - accuracy: 0.7728 - val_loss: 0.7113 - val_accuracy: 0.7940\n","Epoch 11/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.7325 - accuracy: 0.7869 - val_loss: 0.6465 - val_accuracy: 0.8145\n","Epoch 12/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.7012 - accuracy: 0.7976 - val_loss: 0.6327 - val_accuracy: 0.8163\n","Epoch 13/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.6687 - accuracy: 0.8060 - val_loss: 0.6013 - val_accuracy: 0.8245\n","Epoch 14/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.6482 - accuracy: 0.8117 - val_loss: 0.5713 - val_accuracy: 0.8341\n","Epoch 15/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.6176 - accuracy: 0.8200 - val_loss: 0.5580 - val_accuracy: 0.8375\n","Epoch 16/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.5960 - accuracy: 0.8270 - val_loss: 0.5356 - val_accuracy: 0.8410\n","Epoch 17/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5836 - accuracy: 0.8287 - val_loss: 0.5301 - val_accuracy: 0.8418\n","Epoch 18/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5718 - accuracy: 0.8314 - val_loss: 0.5292 - val_accuracy: 0.8454\n","Epoch 19/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.5689 - accuracy: 0.8329 - val_loss: 0.5166 - val_accuracy: 0.8465\n","Epoch 20/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.5598 - accuracy: 0.8349 - val_loss: 0.5099 - val_accuracy: 0.8468\n","Epoch 21/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.5519 - accuracy: 0.8370 - val_loss: 0.5188 - val_accuracy: 0.8463\n","Epoch 22/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.5466 - accuracy: 0.8374 - val_loss: 0.4996 - val_accuracy: 0.8495\n","Epoch 23/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5421 - accuracy: 0.8398 - val_loss: 0.4951 - val_accuracy: 0.8496\n","Epoch 24/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5314 - accuracy: 0.8428 - val_loss: 0.4916 - val_accuracy: 0.8517\n","Epoch 25/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5340 - accuracy: 0.8421 - val_loss: 0.5079 - val_accuracy: 0.8484\n","Epoch 26/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5253 - accuracy: 0.8426 - val_loss: 0.4948 - val_accuracy: 0.8507\n","Epoch 27/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5250 - accuracy: 0.8431 - val_loss: 0.4897 - val_accuracy: 0.8505\n","Epoch 28/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5153 - accuracy: 0.8456 - val_loss: 0.4835 - val_accuracy: 0.8526\n","Epoch 29/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5169 - accuracy: 0.8441 - val_loss: 0.4842 - val_accuracy: 0.8536\n","Epoch 30/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5102 - accuracy: 0.8459 - val_loss: 0.4833 - val_accuracy: 0.8567\n","Epoch 31/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5136 - accuracy: 0.8458 - val_loss: 0.4849 - val_accuracy: 0.8530\n","Epoch 32/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5088 - accuracy: 0.8457 - val_loss: 0.4835 - val_accuracy: 0.8524\n","Epoch 33/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5012 - accuracy: 0.8488 - val_loss: 0.4760 - val_accuracy: 0.8541\n","Epoch 34/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.5054 - accuracy: 0.8459 - val_loss: 0.4782 - val_accuracy: 0.8549\n","Epoch 35/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4980 - accuracy: 0.8494 - val_loss: 0.4734 - val_accuracy: 0.8549\n","Epoch 36/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4962 - accuracy: 0.8479 - val_loss: 0.4754 - val_accuracy: 0.8554\n","Epoch 37/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4930 - accuracy: 0.8492 - val_loss: 0.4850 - val_accuracy: 0.8548\n","Epoch 38/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4946 - accuracy: 0.8502 - val_loss: 0.4716 - val_accuracy: 0.8550\n","Epoch 39/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4927 - accuracy: 0.8479 - val_loss: 0.4743 - val_accuracy: 0.8549\n","Epoch 40/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4894 - accuracy: 0.8515 - val_loss: 0.4771 - val_accuracy: 0.8549\n","Epoch 41/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4886 - accuracy: 0.8499 - val_loss: 0.4731 - val_accuracy: 0.8559\n","Epoch 42/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4835 - accuracy: 0.8511 - val_loss: 0.4672 - val_accuracy: 0.8567\n","Epoch 43/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4825 - accuracy: 0.8540 - val_loss: 0.4666 - val_accuracy: 0.8569\n","Epoch 44/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4816 - accuracy: 0.8534 - val_loss: 0.4668 - val_accuracy: 0.8588\n","Epoch 45/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4803 - accuracy: 0.8518 - val_loss: 0.4641 - val_accuracy: 0.8577\n","Epoch 46/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4828 - accuracy: 0.8532 - val_loss: 0.4716 - val_accuracy: 0.8559\n","Epoch 47/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4827 - accuracy: 0.8537 - val_loss: 0.4620 - val_accuracy: 0.8569\n","Epoch 48/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4826 - accuracy: 0.8527 - val_loss: 0.4613 - val_accuracy: 0.8586\n","Epoch 49/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4720 - accuracy: 0.8564 - val_loss: 0.4670 - val_accuracy: 0.8566\n","Epoch 50/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4722 - accuracy: 0.8539 - val_loss: 0.4683 - val_accuracy: 0.8581\n","Epoch 51/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4702 - accuracy: 0.8559 - val_loss: 0.4611 - val_accuracy: 0.8591\n","Epoch 52/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4732 - accuracy: 0.8558 - val_loss: 0.4600 - val_accuracy: 0.8582\n","Epoch 53/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4748 - accuracy: 0.8531 - val_loss: 0.4586 - val_accuracy: 0.8583\n","Epoch 54/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4726 - accuracy: 0.8543 - val_loss: 0.4611 - val_accuracy: 0.8592\n","Epoch 55/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4659 - accuracy: 0.8556 - val_loss: 0.4635 - val_accuracy: 0.8596\n","Epoch 56/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4658 - accuracy: 0.8559 - val_loss: 0.4598 - val_accuracy: 0.8588\n","Epoch 57/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4678 - accuracy: 0.8560 - val_loss: 0.4562 - val_accuracy: 0.8573\n","Epoch 58/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4648 - accuracy: 0.8573 - val_loss: 0.4676 - val_accuracy: 0.8539\n","Epoch 59/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4666 - accuracy: 0.8556 - val_loss: 0.4547 - val_accuracy: 0.8588\n","Epoch 60/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4620 - accuracy: 0.8583 - val_loss: 0.4586 - val_accuracy: 0.8598\n","Epoch 61/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4680 - accuracy: 0.8564 - val_loss: 0.4576 - val_accuracy: 0.8597\n","Epoch 62/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4649 - accuracy: 0.8575 - val_loss: 0.4534 - val_accuracy: 0.8582\n","Epoch 63/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4606 - accuracy: 0.8569 - val_loss: 0.4562 - val_accuracy: 0.8605\n","Epoch 64/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4585 - accuracy: 0.8593 - val_loss: 0.4522 - val_accuracy: 0.8616\n","Epoch 65/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4591 - accuracy: 0.8584 - val_loss: 0.4538 - val_accuracy: 0.8598\n","Epoch 66/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4581 - accuracy: 0.8586 - val_loss: 0.4537 - val_accuracy: 0.8605\n","Epoch 67/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4596 - accuracy: 0.8573 - val_loss: 0.4489 - val_accuracy: 0.8601\n","Epoch 68/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4568 - accuracy: 0.8589 - val_loss: 0.4495 - val_accuracy: 0.8615\n","Epoch 69/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4525 - accuracy: 0.8616 - val_loss: 0.4524 - val_accuracy: 0.8607\n","Epoch 70/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4513 - accuracy: 0.8603 - val_loss: 0.4511 - val_accuracy: 0.8598\n","Epoch 71/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4554 - accuracy: 0.8590 - val_loss: 0.4539 - val_accuracy: 0.8598\n","Epoch 72/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4530 - accuracy: 0.8591 - val_loss: 0.4484 - val_accuracy: 0.8615\n","Epoch 73/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4509 - accuracy: 0.8592 - val_loss: 0.4510 - val_accuracy: 0.8621\n","Epoch 74/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4486 - accuracy: 0.8602 - val_loss: 0.4511 - val_accuracy: 0.8616\n","Epoch 75/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4495 - accuracy: 0.8604 - val_loss: 0.4514 - val_accuracy: 0.8586\n","Epoch 76/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4502 - accuracy: 0.8597 - val_loss: 0.4503 - val_accuracy: 0.8633\n","Epoch 77/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4479 - accuracy: 0.8588 - val_loss: 0.4562 - val_accuracy: 0.8587\n","Epoch 78/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4475 - accuracy: 0.8605 - val_loss: 0.4502 - val_accuracy: 0.8614\n","Epoch 79/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4463 - accuracy: 0.8619 - val_loss: 0.4463 - val_accuracy: 0.8611\n","Epoch 80/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4487 - accuracy: 0.8601 - val_loss: 0.4512 - val_accuracy: 0.8615\n","Epoch 81/1000\n","42/42 [==============================] - 4s 90ms/step - loss: 0.4499 - accuracy: 0.8603 - val_loss: 0.4473 - val_accuracy: 0.8623\n","Epoch 82/1000\n","42/42 [==============================] - 4s 90ms/step - loss: 0.4464 - accuracy: 0.8601 - val_loss: 0.4482 - val_accuracy: 0.8603\n","Epoch 83/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4424 - accuracy: 0.8616 - val_loss: 0.4491 - val_accuracy: 0.8609\n","Epoch 84/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4484 - accuracy: 0.8597 - val_loss: 0.4477 - val_accuracy: 0.8615\n","Epoch 85/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4435 - accuracy: 0.8614 - val_loss: 0.4489 - val_accuracy: 0.8602\n","Epoch 86/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4430 - accuracy: 0.8614 - val_loss: 0.4461 - val_accuracy: 0.8617\n","Epoch 87/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4435 - accuracy: 0.8610 - val_loss: 0.4441 - val_accuracy: 0.8615\n","Epoch 88/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4390 - accuracy: 0.8635 - val_loss: 0.4435 - val_accuracy: 0.8645\n","Epoch 89/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4405 - accuracy: 0.8626 - val_loss: 0.4435 - val_accuracy: 0.8598\n","Epoch 90/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4450 - accuracy: 0.8621 - val_loss: 0.4488 - val_accuracy: 0.8615\n","Epoch 91/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4389 - accuracy: 0.8608 - val_loss: 0.4485 - val_accuracy: 0.8600\n","Epoch 92/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4391 - accuracy: 0.8620 - val_loss: 0.4423 - val_accuracy: 0.8627\n","Epoch 93/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4395 - accuracy: 0.8618 - val_loss: 0.4427 - val_accuracy: 0.8619\n","Epoch 94/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4387 - accuracy: 0.8626 - val_loss: 0.4445 - val_accuracy: 0.8618\n","Epoch 95/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4383 - accuracy: 0.8628 - val_loss: 0.4424 - val_accuracy: 0.8617\n","Epoch 96/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4390 - accuracy: 0.8636 - val_loss: 0.4478 - val_accuracy: 0.8613\n","Epoch 97/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4368 - accuracy: 0.8625 - val_loss: 0.4460 - val_accuracy: 0.8616\n","Epoch 98/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4393 - accuracy: 0.8622 - val_loss: 0.4446 - val_accuracy: 0.8629\n","Epoch 99/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4395 - accuracy: 0.8627 - val_loss: 0.4406 - val_accuracy: 0.8632\n","Epoch 100/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4351 - accuracy: 0.8628 - val_loss: 0.4432 - val_accuracy: 0.8612\n","Epoch 101/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4370 - accuracy: 0.8629 - val_loss: 0.4393 - val_accuracy: 0.8639\n","Epoch 102/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4345 - accuracy: 0.8624 - val_loss: 0.4447 - val_accuracy: 0.8619\n","Epoch 103/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4330 - accuracy: 0.8633 - val_loss: 0.4416 - val_accuracy: 0.8622\n","Epoch 104/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4331 - accuracy: 0.8642 - val_loss: 0.4486 - val_accuracy: 0.8602\n","Epoch 105/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4335 - accuracy: 0.8625 - val_loss: 0.4407 - val_accuracy: 0.8634\n","Epoch 106/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4296 - accuracy: 0.8639 - val_loss: 0.4412 - val_accuracy: 0.8612\n","Epoch 107/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4322 - accuracy: 0.8646 - val_loss: 0.4392 - val_accuracy: 0.8620\n","Epoch 108/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4271 - accuracy: 0.8651 - val_loss: 0.4403 - val_accuracy: 0.8624\n","Epoch 109/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4330 - accuracy: 0.8631 - val_loss: 0.4429 - val_accuracy: 0.8631\n","Epoch 110/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4315 - accuracy: 0.8644 - val_loss: 0.4425 - val_accuracy: 0.8616\n","Epoch 111/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4334 - accuracy: 0.8635 - val_loss: 0.4380 - val_accuracy: 0.8636\n","Epoch 112/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4308 - accuracy: 0.8657 - val_loss: 0.4393 - val_accuracy: 0.8629\n","Epoch 113/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4275 - accuracy: 0.8654 - val_loss: 0.4378 - val_accuracy: 0.8626\n","Epoch 114/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4278 - accuracy: 0.8648 - val_loss: 0.4421 - val_accuracy: 0.8608\n","Epoch 115/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4287 - accuracy: 0.8644 - val_loss: 0.4405 - val_accuracy: 0.8641\n","Epoch 116/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4303 - accuracy: 0.8629 - val_loss: 0.4376 - val_accuracy: 0.8621\n","Epoch 117/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4262 - accuracy: 0.8653 - val_loss: 0.4385 - val_accuracy: 0.8621\n","Epoch 118/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4237 - accuracy: 0.8658 - val_loss: 0.4423 - val_accuracy: 0.8628\n","Epoch 119/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4239 - accuracy: 0.8662 - val_loss: 0.4389 - val_accuracy: 0.8618\n","Epoch 120/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4224 - accuracy: 0.8654 - val_loss: 0.4380 - val_accuracy: 0.8634\n","Epoch 121/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4248 - accuracy: 0.8656 - val_loss: 0.4400 - val_accuracy: 0.8631\n","Epoch 122/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4261 - accuracy: 0.8645 - val_loss: 0.4368 - val_accuracy: 0.8631\n","Epoch 123/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4233 - accuracy: 0.8670 - val_loss: 0.4382 - val_accuracy: 0.8634\n","Epoch 124/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4244 - accuracy: 0.8645 - val_loss: 0.4378 - val_accuracy: 0.8633\n","Epoch 125/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4232 - accuracy: 0.8654 - val_loss: 0.4354 - val_accuracy: 0.8635\n","Epoch 126/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4243 - accuracy: 0.8661 - val_loss: 0.4402 - val_accuracy: 0.8612\n","Epoch 127/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4245 - accuracy: 0.8646 - val_loss: 0.4353 - val_accuracy: 0.8637\n","Epoch 128/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4208 - accuracy: 0.8659 - val_loss: 0.4332 - val_accuracy: 0.8624\n","Epoch 129/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4220 - accuracy: 0.8659 - val_loss: 0.4389 - val_accuracy: 0.8625\n","Epoch 130/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4229 - accuracy: 0.8643 - val_loss: 0.4387 - val_accuracy: 0.8629\n","Epoch 131/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4195 - accuracy: 0.8670 - val_loss: 0.4345 - val_accuracy: 0.8639\n","Epoch 132/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4234 - accuracy: 0.8659 - val_loss: 0.4352 - val_accuracy: 0.8630\n","Epoch 133/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4204 - accuracy: 0.8665 - val_loss: 0.4400 - val_accuracy: 0.8636\n","Epoch 134/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4268 - accuracy: 0.8640 - val_loss: 0.4354 - val_accuracy: 0.8640\n","Epoch 135/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4205 - accuracy: 0.8667 - val_loss: 0.4330 - val_accuracy: 0.8644\n","Epoch 136/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4201 - accuracy: 0.8662 - val_loss: 0.4358 - val_accuracy: 0.8623\n","Epoch 137/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4200 - accuracy: 0.8663 - val_loss: 0.4338 - val_accuracy: 0.8644\n","Epoch 138/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4210 - accuracy: 0.8635 - val_loss: 0.4353 - val_accuracy: 0.8639\n","Epoch 139/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4192 - accuracy: 0.8668 - val_loss: 0.4368 - val_accuracy: 0.8635\n","Epoch 140/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4145 - accuracy: 0.8682 - val_loss: 0.4338 - val_accuracy: 0.8622\n","Epoch 141/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4180 - accuracy: 0.8669 - val_loss: 0.4316 - val_accuracy: 0.8647\n","Epoch 142/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4160 - accuracy: 0.8668 - val_loss: 0.4315 - val_accuracy: 0.8652\n","Epoch 143/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4146 - accuracy: 0.8685 - val_loss: 0.4336 - val_accuracy: 0.8636\n","Epoch 144/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4172 - accuracy: 0.8674 - val_loss: 0.4353 - val_accuracy: 0.8643\n","Epoch 145/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4177 - accuracy: 0.8675 - val_loss: 0.4358 - val_accuracy: 0.8649\n","Epoch 146/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4160 - accuracy: 0.8683 - val_loss: 0.4320 - val_accuracy: 0.8648\n","Epoch 147/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4149 - accuracy: 0.8675 - val_loss: 0.4359 - val_accuracy: 0.8639\n","Epoch 148/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4152 - accuracy: 0.8668 - val_loss: 0.4332 - val_accuracy: 0.8646\n","Epoch 149/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4160 - accuracy: 0.8659 - val_loss: 0.4306 - val_accuracy: 0.8647\n","Epoch 150/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4118 - accuracy: 0.8690 - val_loss: 0.4353 - val_accuracy: 0.8654\n","Epoch 151/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4135 - accuracy: 0.8671 - val_loss: 0.4349 - val_accuracy: 0.8641\n","Epoch 152/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4138 - accuracy: 0.8670 - val_loss: 0.4311 - val_accuracy: 0.8646\n","Epoch 153/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4124 - accuracy: 0.8688 - val_loss: 0.4373 - val_accuracy: 0.8626\n","Epoch 154/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4113 - accuracy: 0.8677 - val_loss: 0.4306 - val_accuracy: 0.8636\n","Epoch 155/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4123 - accuracy: 0.8686 - val_loss: 0.4333 - val_accuracy: 0.8635\n","Epoch 156/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4124 - accuracy: 0.8684 - val_loss: 0.4317 - val_accuracy: 0.8652\n","Epoch 157/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4115 - accuracy: 0.8691 - val_loss: 0.4342 - val_accuracy: 0.8663\n","Epoch 158/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4174 - accuracy: 0.8687 - val_loss: 0.4317 - val_accuracy: 0.8632\n","Epoch 159/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4092 - accuracy: 0.8690 - val_loss: 0.4372 - val_accuracy: 0.8652\n","Epoch 160/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4109 - accuracy: 0.8690 - val_loss: 0.4322 - val_accuracy: 0.8651\n","Epoch 161/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4077 - accuracy: 0.8693 - val_loss: 0.4314 - val_accuracy: 0.8656\n","Epoch 162/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4077 - accuracy: 0.8699 - val_loss: 0.4334 - val_accuracy: 0.8620\n","Epoch 163/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4140 - accuracy: 0.8677 - val_loss: 0.4305 - val_accuracy: 0.8653\n","Epoch 164/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4080 - accuracy: 0.8694 - val_loss: 0.4324 - val_accuracy: 0.8648\n","Epoch 165/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4077 - accuracy: 0.8704 - val_loss: 0.4283 - val_accuracy: 0.8640\n","Epoch 166/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4041 - accuracy: 0.8698 - val_loss: 0.4371 - val_accuracy: 0.8633\n","Epoch 167/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4116 - accuracy: 0.8683 - val_loss: 0.4345 - val_accuracy: 0.8639\n","Epoch 168/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4086 - accuracy: 0.8697 - val_loss: 0.4296 - val_accuracy: 0.8638\n","Epoch 169/1000\n","42/42 [==============================] - 4s 93ms/step - loss: 0.4056 - accuracy: 0.8702 - val_loss: 0.4282 - val_accuracy: 0.8637\n","Epoch 170/1000\n","42/42 [==============================] - 7s 160ms/step - loss: 0.4109 - accuracy: 0.8690 - val_loss: 0.4305 - val_accuracy: 0.8648\n","Epoch 171/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4121 - accuracy: 0.8691 - val_loss: 0.4309 - val_accuracy: 0.8641\n","Epoch 172/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4080 - accuracy: 0.8691 - val_loss: 0.4318 - val_accuracy: 0.8648\n","Epoch 173/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4060 - accuracy: 0.8693 - val_loss: 0.4308 - val_accuracy: 0.8639\n","Epoch 174/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4070 - accuracy: 0.8684 - val_loss: 0.4293 - val_accuracy: 0.8645\n","Epoch 175/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4096 - accuracy: 0.8681 - val_loss: 0.4294 - val_accuracy: 0.8667\n","Epoch 176/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4066 - accuracy: 0.8691 - val_loss: 0.4306 - val_accuracy: 0.8660\n","Epoch 177/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4053 - accuracy: 0.8705 - val_loss: 0.4349 - val_accuracy: 0.8638\n","Epoch 178/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4047 - accuracy: 0.8716 - val_loss: 0.4331 - val_accuracy: 0.8627\n","Epoch 179/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4062 - accuracy: 0.8687 - val_loss: 0.4327 - val_accuracy: 0.8680\n","Epoch 180/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4069 - accuracy: 0.8684 - val_loss: 0.4308 - val_accuracy: 0.8647\n","Epoch 181/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4051 - accuracy: 0.8699 - val_loss: 0.4367 - val_accuracy: 0.8650\n","Epoch 182/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4031 - accuracy: 0.8695 - val_loss: 0.4319 - val_accuracy: 0.8634\n","Epoch 183/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4038 - accuracy: 0.8704 - val_loss: 0.4310 - val_accuracy: 0.8647\n","Epoch 184/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4046 - accuracy: 0.8694 - val_loss: 0.4331 - val_accuracy: 0.8648\n","Epoch 185/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4014 - accuracy: 0.8690 - val_loss: 0.4306 - val_accuracy: 0.8648\n","Epoch 186/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4025 - accuracy: 0.8718 - val_loss: 0.4295 - val_accuracy: 0.8648\n","Epoch 187/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4035 - accuracy: 0.8701 - val_loss: 0.4399 - val_accuracy: 0.8626\n","Epoch 188/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4023 - accuracy: 0.8702 - val_loss: 0.4345 - val_accuracy: 0.8659\n","Epoch 189/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3984 - accuracy: 0.8710 - val_loss: 0.4309 - val_accuracy: 0.8656\n","Epoch 190/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3984 - accuracy: 0.8706 - val_loss: 0.4303 - val_accuracy: 0.8658\n","Epoch 191/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4032 - accuracy: 0.8701 - val_loss: 0.4316 - val_accuracy: 0.8666\n","Epoch 192/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3996 - accuracy: 0.8697 - val_loss: 0.4325 - val_accuracy: 0.8644\n","Epoch 193/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4027 - accuracy: 0.8705 - val_loss: 0.4326 - val_accuracy: 0.8653\n","Epoch 194/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4065 - accuracy: 0.8689 - val_loss: 0.4351 - val_accuracy: 0.8657\n","Epoch 195/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3984 - accuracy: 0.8710 - val_loss: 0.4286 - val_accuracy: 0.8661\n","Epoch 196/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4026 - accuracy: 0.8706 - val_loss: 0.4380 - val_accuracy: 0.8662\n","Epoch 197/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4018 - accuracy: 0.8707 - val_loss: 0.4357 - val_accuracy: 0.8659\n","Epoch 198/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4007 - accuracy: 0.8707 - val_loss: 0.4277 - val_accuracy: 0.8668\n","Epoch 199/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4003 - accuracy: 0.8718 - val_loss: 0.4316 - val_accuracy: 0.8648\n","Epoch 200/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3999 - accuracy: 0.8704 - val_loss: 0.4310 - val_accuracy: 0.8647\n","Epoch 201/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3972 - accuracy: 0.8704 - val_loss: 0.4295 - val_accuracy: 0.8653\n","Epoch 202/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3984 - accuracy: 0.8704 - val_loss: 0.4296 - val_accuracy: 0.8676\n","Epoch 203/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3984 - accuracy: 0.8710 - val_loss: 0.4325 - val_accuracy: 0.8644\n","Epoch 204/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3998 - accuracy: 0.8708 - val_loss: 0.4360 - val_accuracy: 0.8647\n","Epoch 205/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4005 - accuracy: 0.8714 - val_loss: 0.4303 - val_accuracy: 0.8651\n","Epoch 206/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3961 - accuracy: 0.8699 - val_loss: 0.4364 - val_accuracy: 0.8636\n","Epoch 207/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3992 - accuracy: 0.8715 - val_loss: 0.4290 - val_accuracy: 0.8652\n","Epoch 208/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3942 - accuracy: 0.8721 - val_loss: 0.4356 - val_accuracy: 0.8646\n","Epoch 209/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3960 - accuracy: 0.8715 - val_loss: 0.4268 - val_accuracy: 0.8664\n","Epoch 210/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3956 - accuracy: 0.8704 - val_loss: 0.4361 - val_accuracy: 0.8676\n","Epoch 211/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3977 - accuracy: 0.8724 - val_loss: 0.4344 - val_accuracy: 0.8667\n","Epoch 212/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3969 - accuracy: 0.8721 - val_loss: 0.4333 - val_accuracy: 0.8668\n","Epoch 213/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3997 - accuracy: 0.8720 - val_loss: 0.4298 - val_accuracy: 0.8652\n","Epoch 214/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3922 - accuracy: 0.8717 - val_loss: 0.4296 - val_accuracy: 0.8671\n","Epoch 215/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3985 - accuracy: 0.8719 - val_loss: 0.4312 - val_accuracy: 0.8678\n","Epoch 216/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3903 - accuracy: 0.8728 - val_loss: 0.4283 - val_accuracy: 0.8664\n","Epoch 217/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3932 - accuracy: 0.8725 - val_loss: 0.4316 - val_accuracy: 0.8632\n","Epoch 218/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3954 - accuracy: 0.8723 - val_loss: 0.4284 - val_accuracy: 0.8653\n","Epoch 219/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3978 - accuracy: 0.8719 - val_loss: 0.4287 - val_accuracy: 0.8662\n","Epoch 220/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3933 - accuracy: 0.8725 - val_loss: 0.4305 - val_accuracy: 0.8665\n","Epoch 221/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3942 - accuracy: 0.8723 - val_loss: 0.4339 - val_accuracy: 0.8650\n","Epoch 222/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3980 - accuracy: 0.8700 - val_loss: 0.4325 - val_accuracy: 0.8658\n","Epoch 223/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3913 - accuracy: 0.8724 - val_loss: 0.4399 - val_accuracy: 0.8643\n","Epoch 224/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3934 - accuracy: 0.8720 - val_loss: 0.4329 - val_accuracy: 0.8647\n","Epoch 225/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3959 - accuracy: 0.8714 - val_loss: 0.4302 - val_accuracy: 0.8661\n","Epoch 226/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3929 - accuracy: 0.8724 - val_loss: 0.4298 - val_accuracy: 0.8666\n","Epoch 227/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3912 - accuracy: 0.8729 - val_loss: 0.4277 - val_accuracy: 0.8661\n","Epoch 228/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3916 - accuracy: 0.8724 - val_loss: 0.4284 - val_accuracy: 0.8668\n","Epoch 229/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3909 - accuracy: 0.8719 - val_loss: 0.4323 - val_accuracy: 0.8650\n","Epoch 230/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3930 - accuracy: 0.8722 - val_loss: 0.4317 - val_accuracy: 0.8664\n","Epoch 231/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3925 - accuracy: 0.8725 - val_loss: 0.4292 - val_accuracy: 0.8647\n","Epoch 232/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3888 - accuracy: 0.8724 - val_loss: 0.4274 - val_accuracy: 0.8665\n","Epoch 233/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3923 - accuracy: 0.8734 - val_loss: 0.4309 - val_accuracy: 0.8666\n","Epoch 234/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3914 - accuracy: 0.8730 - val_loss: 0.4329 - val_accuracy: 0.8653\n","Epoch 235/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3913 - accuracy: 0.8727 - val_loss: 0.4323 - val_accuracy: 0.8659\n","Epoch 236/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3898 - accuracy: 0.8748 - val_loss: 0.4307 - val_accuracy: 0.8663\n","Epoch 237/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3897 - accuracy: 0.8736 - val_loss: 0.4331 - val_accuracy: 0.8674\n","Epoch 238/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3895 - accuracy: 0.8736 - val_loss: 0.4303 - val_accuracy: 0.8659\n","Epoch 239/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3888 - accuracy: 0.8730 - val_loss: 0.4292 - val_accuracy: 0.8667\n","Epoch 240/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3894 - accuracy: 0.8730 - val_loss: 0.4312 - val_accuracy: 0.8658\n","Epoch 241/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3893 - accuracy: 0.8730 - val_loss: 0.4332 - val_accuracy: 0.8648\n","Epoch 242/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3896 - accuracy: 0.8731 - val_loss: 0.4300 - val_accuracy: 0.8678\n","Epoch 243/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3892 - accuracy: 0.8727 - val_loss: 0.4322 - val_accuracy: 0.8656\n","Epoch 244/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3899 - accuracy: 0.8738 - val_loss: 0.4341 - val_accuracy: 0.8664\n","Epoch 245/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3886 - accuracy: 0.8733 - val_loss: 0.4296 - val_accuracy: 0.8675\n","Epoch 246/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3886 - accuracy: 0.8743 - val_loss: 0.4345 - val_accuracy: 0.8639\n","Epoch 247/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3908 - accuracy: 0.8724 - val_loss: 0.4331 - val_accuracy: 0.8658\n","Epoch 248/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3937 - accuracy: 0.8723 - val_loss: 0.4291 - val_accuracy: 0.8663\n","Epoch 249/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3897 - accuracy: 0.8731 - val_loss: 0.4313 - val_accuracy: 0.8661\n","Epoch 250/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3898 - accuracy: 0.8730 - val_loss: 0.4275 - val_accuracy: 0.8667\n","Epoch 251/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3888 - accuracy: 0.8744 - val_loss: 0.4293 - val_accuracy: 0.8673\n","Epoch 252/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3850 - accuracy: 0.8752 - val_loss: 0.4313 - val_accuracy: 0.8652\n","Epoch 253/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3890 - accuracy: 0.8728 - val_loss: 0.4317 - val_accuracy: 0.8666\n","Epoch 254/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.3872 - accuracy: 0.8723 - val_loss: 0.4304 - val_accuracy: 0.8664\n","Epoch 255/1000\n","42/42 [==============================] - 4s 94ms/step - loss: 0.3866 - accuracy: 0.8748 - val_loss: 0.4367 - val_accuracy: 0.8667\n","Epoch 256/1000\n","42/42 [==============================] - 4s 101ms/step - loss: 0.3853 - accuracy: 0.8749 - val_loss: 0.4328 - val_accuracy: 0.8651\n","Epoch 257/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.3888 - accuracy: 0.8726 - val_loss: 0.4322 - val_accuracy: 0.8653\n","Epoch 258/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.3847 - accuracy: 0.8744 - val_loss: 0.4357 - val_accuracy: 0.8655\n","Epoch 259/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.3887 - accuracy: 0.8730 - val_loss: 0.4321 - val_accuracy: 0.8662\n","Epoch 00259: early stopping\n","13/13 [==============================] - 0s 12ms/step\n","######### Training on Fold 2  #############\n","Epoch 1/1000\n","42/42 [==============================] - 4s 93ms/step - loss: 1.9320 - accuracy: 0.3486 - val_loss: 1.7028 - val_accuracy: 0.3781\n","Epoch 2/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 1.7113 - accuracy: 0.3722 - val_loss: 1.6669 - val_accuracy: 0.3918\n","Epoch 3/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 1.6703 - accuracy: 0.3903 - val_loss: 1.6210 - val_accuracy: 0.4166\n","Epoch 4/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 1.6212 - accuracy: 0.4397 - val_loss: 1.4918 - val_accuracy: 0.5326\n","Epoch 5/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 1.4227 - accuracy: 0.5737 - val_loss: 1.1518 - val_accuracy: 0.6842\n","Epoch 6/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 1.0831 - accuracy: 0.6901 - val_loss: 0.8762 - val_accuracy: 0.7454\n","Epoch 7/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.9341 - accuracy: 0.7295 - val_loss: 0.8427 - val_accuracy: 0.7458\n","Epoch 8/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.8805 - accuracy: 0.7424 - val_loss: 0.7716 - val_accuracy: 0.7746\n","Epoch 9/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.8208 - accuracy: 0.7580 - val_loss: 0.7071 - val_accuracy: 0.7992\n","Epoch 10/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.7737 - accuracy: 0.7703 - val_loss: 0.6751 - val_accuracy: 0.8055\n","Epoch 11/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.7386 - accuracy: 0.7812 - val_loss: 0.6496 - val_accuracy: 0.8133\n","Epoch 12/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.7084 - accuracy: 0.7923 - val_loss: 0.6207 - val_accuracy: 0.8199\n","Epoch 13/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.6846 - accuracy: 0.8001 - val_loss: 0.5935 - val_accuracy: 0.8257\n","Epoch 14/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.6550 - accuracy: 0.8100 - val_loss: 0.5692 - val_accuracy: 0.8289\n","Epoch 15/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.6311 - accuracy: 0.8155 - val_loss: 0.5456 - val_accuracy: 0.8390\n","Epoch 16/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.6121 - accuracy: 0.8206 - val_loss: 0.5342 - val_accuracy: 0.8472\n","Epoch 17/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5924 - accuracy: 0.8270 - val_loss: 0.5183 - val_accuracy: 0.8496\n","Epoch 18/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5798 - accuracy: 0.8282 - val_loss: 0.5162 - val_accuracy: 0.8472\n","Epoch 19/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5692 - accuracy: 0.8331 - val_loss: 0.4987 - val_accuracy: 0.8528\n","Epoch 20/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5589 - accuracy: 0.8332 - val_loss: 0.5024 - val_accuracy: 0.8524\n","Epoch 21/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5544 - accuracy: 0.8360 - val_loss: 0.4872 - val_accuracy: 0.8540\n","Epoch 22/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5457 - accuracy: 0.8382 - val_loss: 0.4916 - val_accuracy: 0.8541\n","Epoch 23/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5382 - accuracy: 0.8390 - val_loss: 0.4835 - val_accuracy: 0.8542\n","Epoch 24/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5344 - accuracy: 0.8402 - val_loss: 0.4789 - val_accuracy: 0.8577\n","Epoch 25/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5336 - accuracy: 0.8401 - val_loss: 0.4797 - val_accuracy: 0.8558\n","Epoch 26/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5268 - accuracy: 0.8415 - val_loss: 0.4758 - val_accuracy: 0.8567\n","Epoch 27/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5193 - accuracy: 0.8441 - val_loss: 0.4757 - val_accuracy: 0.8575\n","Epoch 28/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5225 - accuracy: 0.8421 - val_loss: 0.4712 - val_accuracy: 0.8584\n","Epoch 29/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5187 - accuracy: 0.8453 - val_loss: 0.4709 - val_accuracy: 0.8574\n","Epoch 30/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.5158 - accuracy: 0.8445 - val_loss: 0.4670 - val_accuracy: 0.8585\n","Epoch 31/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.5129 - accuracy: 0.8452 - val_loss: 0.4732 - val_accuracy: 0.8565\n","Epoch 32/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.5111 - accuracy: 0.8445 - val_loss: 0.4696 - val_accuracy: 0.8605\n","Epoch 33/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.5069 - accuracy: 0.8458 - val_loss: 0.4679 - val_accuracy: 0.8570\n","Epoch 34/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5027 - accuracy: 0.8474 - val_loss: 0.4647 - val_accuracy: 0.8596\n","Epoch 35/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.5031 - accuracy: 0.8477 - val_loss: 0.4635 - val_accuracy: 0.8588\n","Epoch 36/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4980 - accuracy: 0.8492 - val_loss: 0.4650 - val_accuracy: 0.8579\n","Epoch 37/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4974 - accuracy: 0.8482 - val_loss: 0.4607 - val_accuracy: 0.8591\n","Epoch 38/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4959 - accuracy: 0.8479 - val_loss: 0.4567 - val_accuracy: 0.8599\n","Epoch 39/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4947 - accuracy: 0.8497 - val_loss: 0.4589 - val_accuracy: 0.8586\n","Epoch 40/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4934 - accuracy: 0.8494 - val_loss: 0.4582 - val_accuracy: 0.8611\n","Epoch 41/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4920 - accuracy: 0.8487 - val_loss: 0.4550 - val_accuracy: 0.8613\n","Epoch 42/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4878 - accuracy: 0.8513 - val_loss: 0.4564 - val_accuracy: 0.8610\n","Epoch 43/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4856 - accuracy: 0.8496 - val_loss: 0.4596 - val_accuracy: 0.8604\n","Epoch 44/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4933 - accuracy: 0.8484 - val_loss: 0.4634 - val_accuracy: 0.8614\n","Epoch 45/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4868 - accuracy: 0.8516 - val_loss: 0.4514 - val_accuracy: 0.8608\n","Epoch 46/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4820 - accuracy: 0.8520 - val_loss: 0.4537 - val_accuracy: 0.8615\n","Epoch 47/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4860 - accuracy: 0.8504 - val_loss: 0.4557 - val_accuracy: 0.8619\n","Epoch 48/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4821 - accuracy: 0.8512 - val_loss: 0.4516 - val_accuracy: 0.8611\n","Epoch 49/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4775 - accuracy: 0.8531 - val_loss: 0.4512 - val_accuracy: 0.8624\n","Epoch 50/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4763 - accuracy: 0.8535 - val_loss: 0.4460 - val_accuracy: 0.8627\n","Epoch 51/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4765 - accuracy: 0.8532 - val_loss: 0.4544 - val_accuracy: 0.8614\n","Epoch 52/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4761 - accuracy: 0.8531 - val_loss: 0.4513 - val_accuracy: 0.8597\n","Epoch 53/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4765 - accuracy: 0.8535 - val_loss: 0.4534 - val_accuracy: 0.8638\n","Epoch 54/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4728 - accuracy: 0.8538 - val_loss: 0.4564 - val_accuracy: 0.8581\n","Epoch 55/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4733 - accuracy: 0.8541 - val_loss: 0.4455 - val_accuracy: 0.8650\n","Epoch 56/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4707 - accuracy: 0.8548 - val_loss: 0.4456 - val_accuracy: 0.8631\n","Epoch 57/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4701 - accuracy: 0.8542 - val_loss: 0.4423 - val_accuracy: 0.8647\n","Epoch 58/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4669 - accuracy: 0.8558 - val_loss: 0.4387 - val_accuracy: 0.8657\n","Epoch 59/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4672 - accuracy: 0.8551 - val_loss: 0.4429 - val_accuracy: 0.8662\n","Epoch 60/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4654 - accuracy: 0.8561 - val_loss: 0.4421 - val_accuracy: 0.8627\n","Epoch 61/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4657 - accuracy: 0.8559 - val_loss: 0.4400 - val_accuracy: 0.8647\n","Epoch 62/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4674 - accuracy: 0.8539 - val_loss: 0.4569 - val_accuracy: 0.8608\n","Epoch 63/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4676 - accuracy: 0.8551 - val_loss: 0.4448 - val_accuracy: 0.8657\n","Epoch 64/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4652 - accuracy: 0.8540 - val_loss: 0.4409 - val_accuracy: 0.8656\n","Epoch 65/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4619 - accuracy: 0.8556 - val_loss: 0.4370 - val_accuracy: 0.8673\n","Epoch 66/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4605 - accuracy: 0.8574 - val_loss: 0.4350 - val_accuracy: 0.8668\n","Epoch 67/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4600 - accuracy: 0.8566 - val_loss: 0.4329 - val_accuracy: 0.8652\n","Epoch 68/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4596 - accuracy: 0.8561 - val_loss: 0.4438 - val_accuracy: 0.8623\n","Epoch 69/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4609 - accuracy: 0.8560 - val_loss: 0.4376 - val_accuracy: 0.8646\n","Epoch 70/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4571 - accuracy: 0.8583 - val_loss: 0.4450 - val_accuracy: 0.8639\n","Epoch 71/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4617 - accuracy: 0.8575 - val_loss: 0.4389 - val_accuracy: 0.8683\n","Epoch 72/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4568 - accuracy: 0.8581 - val_loss: 0.4365 - val_accuracy: 0.8659\n","Epoch 73/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4547 - accuracy: 0.8575 - val_loss: 0.4339 - val_accuracy: 0.8674\n","Epoch 74/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4546 - accuracy: 0.8582 - val_loss: 0.4325 - val_accuracy: 0.8667\n","Epoch 75/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4535 - accuracy: 0.8581 - val_loss: 0.4390 - val_accuracy: 0.8655\n","Epoch 76/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4535 - accuracy: 0.8578 - val_loss: 0.4346 - val_accuracy: 0.8669\n","Epoch 77/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4521 - accuracy: 0.8592 - val_loss: 0.4400 - val_accuracy: 0.8659\n","Epoch 78/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4509 - accuracy: 0.8595 - val_loss: 0.4342 - val_accuracy: 0.8656\n","Epoch 79/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4496 - accuracy: 0.8586 - val_loss: 0.4337 - val_accuracy: 0.8670\n","Epoch 80/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4521 - accuracy: 0.8598 - val_loss: 0.4316 - val_accuracy: 0.8670\n","Epoch 81/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4490 - accuracy: 0.8593 - val_loss: 0.4329 - val_accuracy: 0.8656\n","Epoch 82/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4467 - accuracy: 0.8585 - val_loss: 0.4309 - val_accuracy: 0.8666\n","Epoch 83/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4516 - accuracy: 0.8576 - val_loss: 0.4383 - val_accuracy: 0.8662\n","Epoch 84/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4483 - accuracy: 0.8597 - val_loss: 0.4304 - val_accuracy: 0.8681\n","Epoch 85/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4482 - accuracy: 0.8600 - val_loss: 0.4324 - val_accuracy: 0.8657\n","Epoch 86/1000\n","42/42 [==============================] - 4s 92ms/step - loss: 0.4463 - accuracy: 0.8600 - val_loss: 0.4355 - val_accuracy: 0.8650\n","Epoch 87/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4443 - accuracy: 0.8613 - val_loss: 0.4311 - val_accuracy: 0.8674\n","Epoch 88/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4413 - accuracy: 0.8620 - val_loss: 0.4304 - val_accuracy: 0.8689\n","Epoch 89/1000\n","42/42 [==============================] - 4s 92ms/step - loss: 0.4402 - accuracy: 0.8607 - val_loss: 0.4332 - val_accuracy: 0.8664\n","Epoch 90/1000\n","42/42 [==============================] - 4s 93ms/step - loss: 0.4404 - accuracy: 0.8606 - val_loss: 0.4267 - val_accuracy: 0.8699\n","Epoch 91/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4462 - accuracy: 0.8598 - val_loss: 0.4341 - val_accuracy: 0.8671\n","Epoch 92/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4440 - accuracy: 0.8601 - val_loss: 0.4318 - val_accuracy: 0.8655\n","Epoch 93/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4427 - accuracy: 0.8617 - val_loss: 0.4298 - val_accuracy: 0.8677\n","Epoch 94/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4406 - accuracy: 0.8608 - val_loss: 0.4295 - val_accuracy: 0.8668\n","Epoch 95/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4407 - accuracy: 0.8627 - val_loss: 0.4271 - val_accuracy: 0.8685\n","Epoch 96/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4381 - accuracy: 0.8626 - val_loss: 0.4308 - val_accuracy: 0.8682\n","Epoch 97/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4399 - accuracy: 0.8621 - val_loss: 0.4291 - val_accuracy: 0.8679\n","Epoch 98/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4423 - accuracy: 0.8601 - val_loss: 0.4297 - val_accuracy: 0.8664\n","Epoch 99/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4389 - accuracy: 0.8604 - val_loss: 0.4320 - val_accuracy: 0.8674\n","Epoch 100/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4387 - accuracy: 0.8605 - val_loss: 0.4285 - val_accuracy: 0.8688\n","Epoch 101/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4397 - accuracy: 0.8613 - val_loss: 0.4273 - val_accuracy: 0.8687\n","Epoch 102/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4374 - accuracy: 0.8627 - val_loss: 0.4273 - val_accuracy: 0.8688\n","Epoch 103/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4352 - accuracy: 0.8628 - val_loss: 0.4270 - val_accuracy: 0.8696\n","Epoch 104/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4367 - accuracy: 0.8620 - val_loss: 0.4271 - val_accuracy: 0.8676\n","Epoch 105/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4354 - accuracy: 0.8632 - val_loss: 0.4314 - val_accuracy: 0.8680\n","Epoch 106/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4346 - accuracy: 0.8624 - val_loss: 0.4249 - val_accuracy: 0.8702\n","Epoch 107/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4303 - accuracy: 0.8639 - val_loss: 0.4274 - val_accuracy: 0.8661\n","Epoch 108/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4330 - accuracy: 0.8624 - val_loss: 0.4261 - val_accuracy: 0.8690\n","Epoch 109/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4345 - accuracy: 0.8635 - val_loss: 0.4289 - val_accuracy: 0.8673\n","Epoch 110/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4317 - accuracy: 0.8644 - val_loss: 0.4272 - val_accuracy: 0.8708\n","Epoch 111/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4311 - accuracy: 0.8633 - val_loss: 0.4295 - val_accuracy: 0.8683\n","Epoch 112/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4320 - accuracy: 0.8638 - val_loss: 0.4238 - val_accuracy: 0.8711\n","Epoch 113/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4325 - accuracy: 0.8628 - val_loss: 0.4241 - val_accuracy: 0.8698\n","Epoch 114/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4296 - accuracy: 0.8634 - val_loss: 0.4287 - val_accuracy: 0.8716\n","Epoch 115/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4347 - accuracy: 0.8619 - val_loss: 0.4247 - val_accuracy: 0.8693\n","Epoch 116/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4309 - accuracy: 0.8630 - val_loss: 0.4257 - val_accuracy: 0.8686\n","Epoch 117/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4336 - accuracy: 0.8629 - val_loss: 0.4289 - val_accuracy: 0.8683\n","Epoch 118/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4241 - accuracy: 0.8658 - val_loss: 0.4282 - val_accuracy: 0.8669\n","Epoch 119/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4257 - accuracy: 0.8641 - val_loss: 0.4289 - val_accuracy: 0.8682\n","Epoch 120/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4268 - accuracy: 0.8642 - val_loss: 0.4248 - val_accuracy: 0.8710\n","Epoch 121/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4259 - accuracy: 0.8654 - val_loss: 0.4269 - val_accuracy: 0.8686\n","Epoch 122/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4255 - accuracy: 0.8646 - val_loss: 0.4276 - val_accuracy: 0.8710\n","Epoch 123/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4267 - accuracy: 0.8643 - val_loss: 0.4228 - val_accuracy: 0.8716\n","Epoch 124/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4277 - accuracy: 0.8639 - val_loss: 0.4235 - val_accuracy: 0.8689\n","Epoch 125/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4251 - accuracy: 0.8651 - val_loss: 0.4256 - val_accuracy: 0.8718\n","Epoch 126/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4256 - accuracy: 0.8645 - val_loss: 0.4238 - val_accuracy: 0.8709\n","Epoch 127/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4239 - accuracy: 0.8654 - val_loss: 0.4207 - val_accuracy: 0.8701\n","Epoch 128/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4247 - accuracy: 0.8636 - val_loss: 0.4260 - val_accuracy: 0.8688\n","Epoch 129/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4280 - accuracy: 0.8634 - val_loss: 0.4249 - val_accuracy: 0.8686\n","Epoch 130/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4258 - accuracy: 0.8650 - val_loss: 0.4245 - val_accuracy: 0.8687\n","Epoch 131/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4251 - accuracy: 0.8650 - val_loss: 0.4247 - val_accuracy: 0.8685\n","Epoch 132/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4237 - accuracy: 0.8655 - val_loss: 0.4245 - val_accuracy: 0.8707\n","Epoch 133/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4241 - accuracy: 0.8656 - val_loss: 0.4209 - val_accuracy: 0.8699\n","Epoch 134/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4252 - accuracy: 0.8651 - val_loss: 0.4208 - val_accuracy: 0.8713\n","Epoch 135/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4196 - accuracy: 0.8658 - val_loss: 0.4234 - val_accuracy: 0.8697\n","Epoch 136/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4241 - accuracy: 0.8643 - val_loss: 0.4229 - val_accuracy: 0.8696\n","Epoch 137/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4203 - accuracy: 0.8670 - val_loss: 0.4227 - val_accuracy: 0.8678\n","Epoch 138/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4220 - accuracy: 0.8651 - val_loss: 0.4238 - val_accuracy: 0.8706\n","Epoch 139/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4231 - accuracy: 0.8644 - val_loss: 0.4207 - val_accuracy: 0.8707\n","Epoch 140/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4224 - accuracy: 0.8651 - val_loss: 0.4265 - val_accuracy: 0.8680\n","Epoch 141/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4197 - accuracy: 0.8655 - val_loss: 0.4225 - val_accuracy: 0.8697\n","Epoch 142/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4191 - accuracy: 0.8675 - val_loss: 0.4220 - val_accuracy: 0.8710\n","Epoch 143/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4168 - accuracy: 0.8664 - val_loss: 0.4208 - val_accuracy: 0.8695\n","Epoch 144/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4147 - accuracy: 0.8676 - val_loss: 0.4238 - val_accuracy: 0.8694\n","Epoch 145/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4160 - accuracy: 0.8685 - val_loss: 0.4214 - val_accuracy: 0.8698\n","Epoch 146/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4184 - accuracy: 0.8676 - val_loss: 0.4221 - val_accuracy: 0.8717\n","Epoch 147/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4211 - accuracy: 0.8637 - val_loss: 0.4266 - val_accuracy: 0.8662\n","Epoch 148/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4139 - accuracy: 0.8674 - val_loss: 0.4234 - val_accuracy: 0.8698\n","Epoch 149/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4180 - accuracy: 0.8657 - val_loss: 0.4233 - val_accuracy: 0.8695\n","Epoch 150/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4207 - accuracy: 0.8664 - val_loss: 0.4220 - val_accuracy: 0.8706\n","Epoch 151/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4162 - accuracy: 0.8659 - val_loss: 0.4209 - val_accuracy: 0.8700\n","Epoch 152/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4171 - accuracy: 0.8664 - val_loss: 0.4222 - val_accuracy: 0.8698\n","Epoch 153/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4159 - accuracy: 0.8679 - val_loss: 0.4231 - val_accuracy: 0.8713\n","Epoch 154/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4142 - accuracy: 0.8678 - val_loss: 0.4232 - val_accuracy: 0.8697\n","Epoch 155/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4176 - accuracy: 0.8673 - val_loss: 0.4227 - val_accuracy: 0.8716\n","Epoch 156/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4144 - accuracy: 0.8686 - val_loss: 0.4233 - val_accuracy: 0.8699\n","Epoch 157/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4148 - accuracy: 0.8677 - val_loss: 0.4224 - val_accuracy: 0.8683\n","Epoch 158/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4108 - accuracy: 0.8681 - val_loss: 0.4204 - val_accuracy: 0.8704\n","Epoch 159/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4151 - accuracy: 0.8676 - val_loss: 0.4223 - val_accuracy: 0.8726\n","Epoch 160/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4123 - accuracy: 0.8690 - val_loss: 0.4194 - val_accuracy: 0.8712\n","Epoch 161/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4115 - accuracy: 0.8684 - val_loss: 0.4237 - val_accuracy: 0.8701\n","Epoch 162/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4086 - accuracy: 0.8688 - val_loss: 0.4176 - val_accuracy: 0.8718\n","Epoch 163/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4124 - accuracy: 0.8679 - val_loss: 0.4214 - val_accuracy: 0.8694\n","Epoch 164/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4115 - accuracy: 0.8694 - val_loss: 0.4264 - val_accuracy: 0.8702\n","Epoch 165/1000\n","42/42 [==============================] - 4s 92ms/step - loss: 0.4121 - accuracy: 0.8671 - val_loss: 0.4192 - val_accuracy: 0.8710\n","Epoch 166/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4113 - accuracy: 0.8680 - val_loss: 0.4269 - val_accuracy: 0.8682\n","Epoch 167/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4103 - accuracy: 0.8685 - val_loss: 0.4178 - val_accuracy: 0.8704\n","Epoch 168/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4087 - accuracy: 0.8679 - val_loss: 0.4201 - val_accuracy: 0.8723\n","Epoch 169/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4067 - accuracy: 0.8683 - val_loss: 0.4215 - val_accuracy: 0.8706\n","Epoch 170/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4133 - accuracy: 0.8671 - val_loss: 0.4218 - val_accuracy: 0.8690\n","Epoch 171/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4088 - accuracy: 0.8682 - val_loss: 0.4237 - val_accuracy: 0.8709\n","Epoch 172/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4054 - accuracy: 0.8687 - val_loss: 0.4234 - val_accuracy: 0.8688\n","Epoch 173/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4091 - accuracy: 0.8685 - val_loss: 0.4215 - val_accuracy: 0.8699\n","Epoch 174/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4064 - accuracy: 0.8688 - val_loss: 0.4243 - val_accuracy: 0.8699\n","Epoch 175/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4070 - accuracy: 0.8700 - val_loss: 0.4227 - val_accuracy: 0.8687\n","Epoch 176/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4076 - accuracy: 0.8691 - val_loss: 0.4201 - val_accuracy: 0.8695\n","Epoch 177/1000\n","42/42 [==============================] - 4s 95ms/step - loss: 0.4087 - accuracy: 0.8691 - val_loss: 0.4266 - val_accuracy: 0.8703\n","Epoch 178/1000\n","42/42 [==============================] - 4s 98ms/step - loss: 0.4113 - accuracy: 0.8680 - val_loss: 0.4211 - val_accuracy: 0.8704\n","Epoch 179/1000\n","42/42 [==============================] - 4s 95ms/step - loss: 0.4098 - accuracy: 0.8691 - val_loss: 0.4217 - val_accuracy: 0.8733\n","Epoch 180/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4079 - accuracy: 0.8688 - val_loss: 0.4208 - val_accuracy: 0.8710\n","Epoch 181/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4085 - accuracy: 0.8681 - val_loss: 0.4209 - val_accuracy: 0.8698\n","Epoch 182/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4024 - accuracy: 0.8705 - val_loss: 0.4224 - val_accuracy: 0.8686\n","Epoch 183/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4067 - accuracy: 0.8694 - val_loss: 0.4201 - val_accuracy: 0.8703\n","Epoch 184/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4041 - accuracy: 0.8696 - val_loss: 0.4175 - val_accuracy: 0.8718\n","Epoch 185/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4040 - accuracy: 0.8697 - val_loss: 0.4252 - val_accuracy: 0.8696\n","Epoch 186/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4098 - accuracy: 0.8683 - val_loss: 0.4198 - val_accuracy: 0.8698\n","Epoch 187/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4047 - accuracy: 0.8686 - val_loss: 0.4249 - val_accuracy: 0.8688\n","Epoch 188/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4013 - accuracy: 0.8702 - val_loss: 0.4202 - val_accuracy: 0.8730\n","Epoch 189/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4039 - accuracy: 0.8698 - val_loss: 0.4159 - val_accuracy: 0.8708\n","Epoch 190/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4015 - accuracy: 0.8705 - val_loss: 0.4259 - val_accuracy: 0.8718\n","Epoch 191/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4018 - accuracy: 0.8692 - val_loss: 0.4212 - val_accuracy: 0.8721\n","Epoch 192/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4033 - accuracy: 0.8712 - val_loss: 0.4207 - val_accuracy: 0.8706\n","Epoch 193/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4057 - accuracy: 0.8682 - val_loss: 0.4195 - val_accuracy: 0.8726\n","Epoch 194/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4032 - accuracy: 0.8695 - val_loss: 0.4181 - val_accuracy: 0.8703\n","Epoch 195/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4014 - accuracy: 0.8708 - val_loss: 0.4201 - val_accuracy: 0.8718\n","Epoch 196/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3989 - accuracy: 0.8701 - val_loss: 0.4230 - val_accuracy: 0.8696\n","Epoch 197/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4019 - accuracy: 0.8700 - val_loss: 0.4202 - val_accuracy: 0.8706\n","Epoch 198/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4012 - accuracy: 0.8699 - val_loss: 0.4233 - val_accuracy: 0.8710\n","Epoch 199/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4035 - accuracy: 0.8691 - val_loss: 0.4207 - val_accuracy: 0.8722\n","Epoch 200/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4046 - accuracy: 0.8695 - val_loss: 0.4223 - val_accuracy: 0.8709\n","Epoch 201/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4003 - accuracy: 0.8703 - val_loss: 0.4266 - val_accuracy: 0.8676\n","Epoch 202/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4054 - accuracy: 0.8700 - val_loss: 0.4225 - val_accuracy: 0.8696\n","Epoch 203/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4049 - accuracy: 0.8686 - val_loss: 0.4200 - val_accuracy: 0.8725\n","Epoch 204/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4009 - accuracy: 0.8695 - val_loss: 0.4202 - val_accuracy: 0.8711\n","Epoch 205/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3985 - accuracy: 0.8705 - val_loss: 0.4196 - val_accuracy: 0.8702\n","Epoch 206/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4019 - accuracy: 0.8701 - val_loss: 0.4218 - val_accuracy: 0.8723\n","Epoch 207/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3992 - accuracy: 0.8705 - val_loss: 0.4215 - val_accuracy: 0.8703\n","Epoch 208/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4003 - accuracy: 0.8706 - val_loss: 0.4217 - val_accuracy: 0.8717\n","Epoch 209/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4018 - accuracy: 0.8704 - val_loss: 0.4183 - val_accuracy: 0.8721\n","Epoch 210/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3987 - accuracy: 0.8717 - val_loss: 0.4211 - val_accuracy: 0.8712\n","Epoch 211/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4001 - accuracy: 0.8715 - val_loss: 0.4229 - val_accuracy: 0.8690\n","Epoch 212/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3948 - accuracy: 0.8716 - val_loss: 0.4222 - val_accuracy: 0.8705\n","Epoch 213/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3958 - accuracy: 0.8723 - val_loss: 0.4234 - val_accuracy: 0.8713\n","Epoch 214/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3987 - accuracy: 0.8720 - val_loss: 0.4190 - val_accuracy: 0.8726\n","Epoch 215/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3980 - accuracy: 0.8700 - val_loss: 0.4203 - val_accuracy: 0.8724\n","Epoch 216/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3973 - accuracy: 0.8710 - val_loss: 0.4215 - val_accuracy: 0.8712\n","Epoch 217/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3987 - accuracy: 0.8701 - val_loss: 0.4206 - val_accuracy: 0.8701\n","Epoch 218/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4012 - accuracy: 0.8711 - val_loss: 0.4210 - val_accuracy: 0.8716\n","Epoch 219/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3978 - accuracy: 0.8710 - val_loss: 0.4209 - val_accuracy: 0.8703\n","Epoch 220/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3991 - accuracy: 0.8709 - val_loss: 0.4197 - val_accuracy: 0.8713\n","Epoch 221/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.3955 - accuracy: 0.8701 - val_loss: 0.4208 - val_accuracy: 0.8713\n","Epoch 222/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3951 - accuracy: 0.8723 - val_loss: 0.4228 - val_accuracy: 0.8709\n","Epoch 223/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3966 - accuracy: 0.8721 - val_loss: 0.4185 - val_accuracy: 0.8742\n","Epoch 224/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3937 - accuracy: 0.8711 - val_loss: 0.4203 - val_accuracy: 0.8678\n","Epoch 225/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3937 - accuracy: 0.8732 - val_loss: 0.4206 - val_accuracy: 0.8680\n","Epoch 226/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3949 - accuracy: 0.8716 - val_loss: 0.4236 - val_accuracy: 0.8697\n","Epoch 227/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3916 - accuracy: 0.8718 - val_loss: 0.4202 - val_accuracy: 0.8713\n","Epoch 228/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3959 - accuracy: 0.8708 - val_loss: 0.4197 - val_accuracy: 0.8694\n","Epoch 229/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3965 - accuracy: 0.8712 - val_loss: 0.4185 - val_accuracy: 0.8707\n","Epoch 230/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3929 - accuracy: 0.8732 - val_loss: 0.4225 - val_accuracy: 0.8716\n","Epoch 231/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3905 - accuracy: 0.8734 - val_loss: 0.4204 - val_accuracy: 0.8723\n","Epoch 232/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3979 - accuracy: 0.8707 - val_loss: 0.4185 - val_accuracy: 0.8727\n","Epoch 233/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3946 - accuracy: 0.8723 - val_loss: 0.4240 - val_accuracy: 0.8702\n","Epoch 234/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3944 - accuracy: 0.8715 - val_loss: 0.4218 - val_accuracy: 0.8713\n","Epoch 235/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3906 - accuracy: 0.8729 - val_loss: 0.4204 - val_accuracy: 0.8697\n","Epoch 236/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3899 - accuracy: 0.8716 - val_loss: 0.4206 - val_accuracy: 0.8729\n","Epoch 237/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3908 - accuracy: 0.8730 - val_loss: 0.4272 - val_accuracy: 0.8688\n","Epoch 238/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3950 - accuracy: 0.8711 - val_loss: 0.4233 - val_accuracy: 0.8734\n","Epoch 239/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3918 - accuracy: 0.8734 - val_loss: 0.4177 - val_accuracy: 0.8706\n","Epoch 00239: early stopping\n","13/13 [==============================] - 0s 12ms/step\n","######### Training on Fold 3  #############\n","Epoch 1/1000\n","42/42 [==============================] - 4s 95ms/step - loss: 1.9270 - accuracy: 0.3455 - val_loss: 1.6952 - val_accuracy: 0.4041\n","Epoch 2/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 1.7126 - accuracy: 0.3739 - val_loss: 1.6432 - val_accuracy: 0.4603\n","Epoch 3/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 1.6697 - accuracy: 0.3949 - val_loss: 1.6015 - val_accuracy: 0.4657\n","Epoch 4/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 1.6042 - accuracy: 0.4548 - val_loss: 1.4735 - val_accuracy: 0.5640\n","Epoch 5/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 1.3724 - accuracy: 0.5972 - val_loss: 1.1225 - val_accuracy: 0.6821\n","Epoch 6/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 1.0790 - accuracy: 0.6958 - val_loss: 0.9007 - val_accuracy: 0.7397\n","Epoch 7/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.9527 - accuracy: 0.7266 - val_loss: 0.8496 - val_accuracy: 0.7369\n","Epoch 8/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.8828 - accuracy: 0.7432 - val_loss: 0.7639 - val_accuracy: 0.7762\n","Epoch 9/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.8313 - accuracy: 0.7572 - val_loss: 0.7459 - val_accuracy: 0.7824\n","Epoch 10/1000\n","42/42 [==============================] - 4s 90ms/step - loss: 0.7929 - accuracy: 0.7660 - val_loss: 0.6942 - val_accuracy: 0.7927\n","Epoch 11/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.7497 - accuracy: 0.7795 - val_loss: 0.6637 - val_accuracy: 0.8087\n","Epoch 12/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.7313 - accuracy: 0.7846 - val_loss: 0.6534 - val_accuracy: 0.8071\n","Epoch 13/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.7004 - accuracy: 0.7961 - val_loss: 0.6141 - val_accuracy: 0.8201\n","Epoch 14/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.6727 - accuracy: 0.8051 - val_loss: 0.5891 - val_accuracy: 0.8275\n","Epoch 15/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.6397 - accuracy: 0.8146 - val_loss: 0.5565 - val_accuracy: 0.8366\n","Epoch 16/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.6163 - accuracy: 0.8214 - val_loss: 0.5346 - val_accuracy: 0.8400\n","Epoch 17/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5997 - accuracy: 0.8278 - val_loss: 0.5198 - val_accuracy: 0.8430\n","Epoch 18/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5844 - accuracy: 0.8303 - val_loss: 0.5117 - val_accuracy: 0.8440\n","Epoch 19/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5778 - accuracy: 0.8303 - val_loss: 0.5012 - val_accuracy: 0.8455\n","Epoch 20/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5605 - accuracy: 0.8353 - val_loss: 0.5022 - val_accuracy: 0.8465\n","Epoch 21/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5575 - accuracy: 0.8351 - val_loss: 0.4933 - val_accuracy: 0.8481\n","Epoch 22/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5493 - accuracy: 0.8386 - val_loss: 0.4954 - val_accuracy: 0.8478\n","Epoch 23/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.5441 - accuracy: 0.8396 - val_loss: 0.4942 - val_accuracy: 0.8470\n","Epoch 24/1000\n","42/42 [==============================] - 4s 95ms/step - loss: 0.5374 - accuracy: 0.8404 - val_loss: 0.4867 - val_accuracy: 0.8498\n","Epoch 25/1000\n","42/42 [==============================] - 4s 93ms/step - loss: 0.5335 - accuracy: 0.8412 - val_loss: 0.4887 - val_accuracy: 0.8490\n","Epoch 26/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.5319 - accuracy: 0.8420 - val_loss: 0.4941 - val_accuracy: 0.8473\n","Epoch 27/1000\n","42/42 [==============================] - 4s 90ms/step - loss: 0.5253 - accuracy: 0.8433 - val_loss: 0.4787 - val_accuracy: 0.8517\n","Epoch 28/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.5178 - accuracy: 0.8459 - val_loss: 0.4752 - val_accuracy: 0.8523\n","Epoch 29/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.5170 - accuracy: 0.8445 - val_loss: 0.4754 - val_accuracy: 0.8512\n","Epoch 30/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5191 - accuracy: 0.8436 - val_loss: 0.4750 - val_accuracy: 0.8560\n","Epoch 31/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5116 - accuracy: 0.8462 - val_loss: 0.4698 - val_accuracy: 0.8548\n","Epoch 32/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5091 - accuracy: 0.8474 - val_loss: 0.4764 - val_accuracy: 0.8522\n","Epoch 33/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5060 - accuracy: 0.8491 - val_loss: 0.4700 - val_accuracy: 0.8533\n","Epoch 34/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5058 - accuracy: 0.8479 - val_loss: 0.4701 - val_accuracy: 0.8547\n","Epoch 35/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5024 - accuracy: 0.8496 - val_loss: 0.4635 - val_accuracy: 0.8546\n","Epoch 36/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5005 - accuracy: 0.8493 - val_loss: 0.4671 - val_accuracy: 0.8545\n","Epoch 37/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4963 - accuracy: 0.8502 - val_loss: 0.4650 - val_accuracy: 0.8554\n","Epoch 38/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4967 - accuracy: 0.8505 - val_loss: 0.4618 - val_accuracy: 0.8577\n","Epoch 39/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4945 - accuracy: 0.8500 - val_loss: 0.4600 - val_accuracy: 0.8565\n","Epoch 40/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4929 - accuracy: 0.8515 - val_loss: 0.4624 - val_accuracy: 0.8554\n","Epoch 41/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4891 - accuracy: 0.8516 - val_loss: 0.4590 - val_accuracy: 0.8557\n","Epoch 42/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4910 - accuracy: 0.8508 - val_loss: 0.4611 - val_accuracy: 0.8563\n","Epoch 43/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4865 - accuracy: 0.8516 - val_loss: 0.4557 - val_accuracy: 0.8574\n","Epoch 44/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4885 - accuracy: 0.8530 - val_loss: 0.4549 - val_accuracy: 0.8570\n","Epoch 45/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4850 - accuracy: 0.8528 - val_loss: 0.4596 - val_accuracy: 0.8553\n","Epoch 46/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4814 - accuracy: 0.8527 - val_loss: 0.4554 - val_accuracy: 0.8580\n","Epoch 47/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4805 - accuracy: 0.8536 - val_loss: 0.4548 - val_accuracy: 0.8567\n","Epoch 48/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4784 - accuracy: 0.8543 - val_loss: 0.4538 - val_accuracy: 0.8582\n","Epoch 49/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4788 - accuracy: 0.8536 - val_loss: 0.4555 - val_accuracy: 0.8572\n","Epoch 50/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4781 - accuracy: 0.8541 - val_loss: 0.4590 - val_accuracy: 0.8557\n","Epoch 51/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4769 - accuracy: 0.8537 - val_loss: 0.4567 - val_accuracy: 0.8573\n","Epoch 52/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4739 - accuracy: 0.8546 - val_loss: 0.4515 - val_accuracy: 0.8589\n","Epoch 53/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4759 - accuracy: 0.8537 - val_loss: 0.4515 - val_accuracy: 0.8570\n","Epoch 54/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4727 - accuracy: 0.8543 - val_loss: 0.4539 - val_accuracy: 0.8571\n","Epoch 55/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4702 - accuracy: 0.8569 - val_loss: 0.4484 - val_accuracy: 0.8570\n","Epoch 56/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4685 - accuracy: 0.8559 - val_loss: 0.4467 - val_accuracy: 0.8604\n","Epoch 57/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4688 - accuracy: 0.8559 - val_loss: 0.4511 - val_accuracy: 0.8592\n","Epoch 58/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4713 - accuracy: 0.8556 - val_loss: 0.4484 - val_accuracy: 0.8569\n","Epoch 59/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4646 - accuracy: 0.8570 - val_loss: 0.4464 - val_accuracy: 0.8612\n","Epoch 60/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4636 - accuracy: 0.8577 - val_loss: 0.4513 - val_accuracy: 0.8562\n","Epoch 61/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4664 - accuracy: 0.8560 - val_loss: 0.4482 - val_accuracy: 0.8587\n","Epoch 62/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4654 - accuracy: 0.8568 - val_loss: 0.4443 - val_accuracy: 0.8596\n","Epoch 63/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4613 - accuracy: 0.8579 - val_loss: 0.4476 - val_accuracy: 0.8581\n","Epoch 64/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4636 - accuracy: 0.8569 - val_loss: 0.4478 - val_accuracy: 0.8595\n","Epoch 65/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4591 - accuracy: 0.8590 - val_loss: 0.4412 - val_accuracy: 0.8604\n","Epoch 66/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4610 - accuracy: 0.8578 - val_loss: 0.4430 - val_accuracy: 0.8608\n","Epoch 67/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4580 - accuracy: 0.8586 - val_loss: 0.4413 - val_accuracy: 0.8600\n","Epoch 68/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4594 - accuracy: 0.8569 - val_loss: 0.4427 - val_accuracy: 0.8594\n","Epoch 69/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4561 - accuracy: 0.8582 - val_loss: 0.4403 - val_accuracy: 0.8608\n","Epoch 70/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4561 - accuracy: 0.8597 - val_loss: 0.4408 - val_accuracy: 0.8577\n","Epoch 71/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4596 - accuracy: 0.8585 - val_loss: 0.4481 - val_accuracy: 0.8592\n","Epoch 72/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4581 - accuracy: 0.8588 - val_loss: 0.4497 - val_accuracy: 0.8598\n","Epoch 73/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4587 - accuracy: 0.8583 - val_loss: 0.4408 - val_accuracy: 0.8596\n","Epoch 74/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4578 - accuracy: 0.8593 - val_loss: 0.4373 - val_accuracy: 0.8617\n","Epoch 75/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4519 - accuracy: 0.8604 - val_loss: 0.4382 - val_accuracy: 0.8622\n","Epoch 76/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4527 - accuracy: 0.8590 - val_loss: 0.4360 - val_accuracy: 0.8602\n","Epoch 77/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4490 - accuracy: 0.8614 - val_loss: 0.4358 - val_accuracy: 0.8618\n","Epoch 78/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4490 - accuracy: 0.8600 - val_loss: 0.4422 - val_accuracy: 0.8624\n","Epoch 79/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4511 - accuracy: 0.8615 - val_loss: 0.4343 - val_accuracy: 0.8608\n","Epoch 80/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4476 - accuracy: 0.8596 - val_loss: 0.4365 - val_accuracy: 0.8628\n","Epoch 81/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4467 - accuracy: 0.8620 - val_loss: 0.4357 - val_accuracy: 0.8635\n","Epoch 82/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4485 - accuracy: 0.8610 - val_loss: 0.4347 - val_accuracy: 0.8613\n","Epoch 83/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4445 - accuracy: 0.8611 - val_loss: 0.4309 - val_accuracy: 0.8631\n","Epoch 84/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4448 - accuracy: 0.8621 - val_loss: 0.4357 - val_accuracy: 0.8634\n","Epoch 85/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4454 - accuracy: 0.8624 - val_loss: 0.4407 - val_accuracy: 0.8608\n","Epoch 86/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4458 - accuracy: 0.8619 - val_loss: 0.4329 - val_accuracy: 0.8628\n","Epoch 87/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4430 - accuracy: 0.8628 - val_loss: 0.4350 - val_accuracy: 0.8607\n","Epoch 88/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4393 - accuracy: 0.8638 - val_loss: 0.4342 - val_accuracy: 0.8645\n","Epoch 89/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4417 - accuracy: 0.8639 - val_loss: 0.4410 - val_accuracy: 0.8607\n","Epoch 90/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4419 - accuracy: 0.8621 - val_loss: 0.4321 - val_accuracy: 0.8629\n","Epoch 91/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4381 - accuracy: 0.8641 - val_loss: 0.4311 - val_accuracy: 0.8646\n","Epoch 92/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4438 - accuracy: 0.8620 - val_loss: 0.4329 - val_accuracy: 0.8614\n","Epoch 93/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4390 - accuracy: 0.8631 - val_loss: 0.4356 - val_accuracy: 0.8620\n","Epoch 94/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4404 - accuracy: 0.8630 - val_loss: 0.4325 - val_accuracy: 0.8632\n","Epoch 95/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4383 - accuracy: 0.8648 - val_loss: 0.4325 - val_accuracy: 0.8642\n","Epoch 96/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4376 - accuracy: 0.8632 - val_loss: 0.4305 - val_accuracy: 0.8625\n","Epoch 97/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4374 - accuracy: 0.8633 - val_loss: 0.4304 - val_accuracy: 0.8645\n","Epoch 98/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4374 - accuracy: 0.8624 - val_loss: 0.4356 - val_accuracy: 0.8619\n","Epoch 99/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4391 - accuracy: 0.8630 - val_loss: 0.4314 - val_accuracy: 0.8638\n","Epoch 100/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4372 - accuracy: 0.8648 - val_loss: 0.4340 - val_accuracy: 0.8619\n","Epoch 101/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4392 - accuracy: 0.8615 - val_loss: 0.4298 - val_accuracy: 0.8629\n","Epoch 102/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4341 - accuracy: 0.8638 - val_loss: 0.4298 - val_accuracy: 0.8635\n","Epoch 103/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4351 - accuracy: 0.8637 - val_loss: 0.4317 - val_accuracy: 0.8632\n","Epoch 104/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4332 - accuracy: 0.8644 - val_loss: 0.4298 - val_accuracy: 0.8620\n","Epoch 105/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4319 - accuracy: 0.8656 - val_loss: 0.4311 - val_accuracy: 0.8631\n","Epoch 106/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4305 - accuracy: 0.8652 - val_loss: 0.4319 - val_accuracy: 0.8654\n","Epoch 107/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4350 - accuracy: 0.8634 - val_loss: 0.4340 - val_accuracy: 0.8634\n","Epoch 108/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4341 - accuracy: 0.8650 - val_loss: 0.4269 - val_accuracy: 0.8636\n","Epoch 109/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4308 - accuracy: 0.8663 - val_loss: 0.4268 - val_accuracy: 0.8642\n","Epoch 110/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4344 - accuracy: 0.8635 - val_loss: 0.4358 - val_accuracy: 0.8616\n","Epoch 111/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4301 - accuracy: 0.8661 - val_loss: 0.4277 - val_accuracy: 0.8662\n","Epoch 112/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4298 - accuracy: 0.8653 - val_loss: 0.4301 - val_accuracy: 0.8634\n","Epoch 113/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4308 - accuracy: 0.8666 - val_loss: 0.4269 - val_accuracy: 0.8659\n","Epoch 114/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4292 - accuracy: 0.8651 - val_loss: 0.4279 - val_accuracy: 0.8636\n","Epoch 115/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4299 - accuracy: 0.8661 - val_loss: 0.4277 - val_accuracy: 0.8658\n","Epoch 116/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4278 - accuracy: 0.8651 - val_loss: 0.4297 - val_accuracy: 0.8652\n","Epoch 117/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4277 - accuracy: 0.8659 - val_loss: 0.4267 - val_accuracy: 0.8643\n","Epoch 118/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4253 - accuracy: 0.8660 - val_loss: 0.4271 - val_accuracy: 0.8644\n","Epoch 119/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4271 - accuracy: 0.8653 - val_loss: 0.4242 - val_accuracy: 0.8645\n","Epoch 120/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4287 - accuracy: 0.8660 - val_loss: 0.4285 - val_accuracy: 0.8640\n","Epoch 121/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4265 - accuracy: 0.8653 - val_loss: 0.4234 - val_accuracy: 0.8654\n","Epoch 122/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4214 - accuracy: 0.8683 - val_loss: 0.4315 - val_accuracy: 0.8628\n","Epoch 123/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4236 - accuracy: 0.8680 - val_loss: 0.4310 - val_accuracy: 0.8631\n","Epoch 124/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4259 - accuracy: 0.8655 - val_loss: 0.4233 - val_accuracy: 0.8647\n","Epoch 125/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4242 - accuracy: 0.8662 - val_loss: 0.4294 - val_accuracy: 0.8632\n","Epoch 126/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4222 - accuracy: 0.8675 - val_loss: 0.4298 - val_accuracy: 0.8645\n","Epoch 127/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4231 - accuracy: 0.8671 - val_loss: 0.4249 - val_accuracy: 0.8650\n","Epoch 128/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4258 - accuracy: 0.8655 - val_loss: 0.4265 - val_accuracy: 0.8646\n","Epoch 129/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4252 - accuracy: 0.8663 - val_loss: 0.4227 - val_accuracy: 0.8663\n","Epoch 130/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4210 - accuracy: 0.8680 - val_loss: 0.4281 - val_accuracy: 0.8662\n","Epoch 131/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4235 - accuracy: 0.8665 - val_loss: 0.4261 - val_accuracy: 0.8654\n","Epoch 132/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4187 - accuracy: 0.8671 - val_loss: 0.4244 - val_accuracy: 0.8638\n","Epoch 133/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4205 - accuracy: 0.8669 - val_loss: 0.4243 - val_accuracy: 0.8642\n","Epoch 134/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4197 - accuracy: 0.8668 - val_loss: 0.4225 - val_accuracy: 0.8658\n","Epoch 135/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4178 - accuracy: 0.8673 - val_loss: 0.4281 - val_accuracy: 0.8655\n","Epoch 136/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4202 - accuracy: 0.8672 - val_loss: 0.4248 - val_accuracy: 0.8660\n","Epoch 137/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4161 - accuracy: 0.8682 - val_loss: 0.4231 - val_accuracy: 0.8650\n","Epoch 138/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4146 - accuracy: 0.8664 - val_loss: 0.4265 - val_accuracy: 0.8653\n","Epoch 139/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4168 - accuracy: 0.8684 - val_loss: 0.4245 - val_accuracy: 0.8665\n","Epoch 140/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4193 - accuracy: 0.8681 - val_loss: 0.4226 - val_accuracy: 0.8670\n","Epoch 141/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4174 - accuracy: 0.8671 - val_loss: 0.4236 - val_accuracy: 0.8637\n","Epoch 142/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4191 - accuracy: 0.8675 - val_loss: 0.4235 - val_accuracy: 0.8653\n","Epoch 143/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4130 - accuracy: 0.8680 - val_loss: 0.4242 - val_accuracy: 0.8664\n","Epoch 144/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4150 - accuracy: 0.8676 - val_loss: 0.4252 - val_accuracy: 0.8647\n","Epoch 145/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4175 - accuracy: 0.8685 - val_loss: 0.4207 - val_accuracy: 0.8666\n","Epoch 146/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4129 - accuracy: 0.8693 - val_loss: 0.4212 - val_accuracy: 0.8656\n","Epoch 147/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4125 - accuracy: 0.8693 - val_loss: 0.4299 - val_accuracy: 0.8638\n","Epoch 148/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4158 - accuracy: 0.8680 - val_loss: 0.4244 - val_accuracy: 0.8651\n","Epoch 149/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4120 - accuracy: 0.8690 - val_loss: 0.4227 - val_accuracy: 0.8645\n","Epoch 150/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4119 - accuracy: 0.8691 - val_loss: 0.4211 - val_accuracy: 0.8663\n","Epoch 151/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4116 - accuracy: 0.8698 - val_loss: 0.4300 - val_accuracy: 0.8632\n","Epoch 152/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4170 - accuracy: 0.8671 - val_loss: 0.4237 - val_accuracy: 0.8666\n","Epoch 153/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4112 - accuracy: 0.8683 - val_loss: 0.4238 - val_accuracy: 0.8655\n","Epoch 154/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4083 - accuracy: 0.8700 - val_loss: 0.4207 - val_accuracy: 0.8666\n","Epoch 155/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4115 - accuracy: 0.8697 - val_loss: 0.4242 - val_accuracy: 0.8662\n","Epoch 156/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4119 - accuracy: 0.8700 - val_loss: 0.4253 - val_accuracy: 0.8653\n","Epoch 157/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4086 - accuracy: 0.8706 - val_loss: 0.4218 - val_accuracy: 0.8681\n","Epoch 158/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4114 - accuracy: 0.8688 - val_loss: 0.4252 - val_accuracy: 0.8660\n","Epoch 159/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4103 - accuracy: 0.8694 - val_loss: 0.4231 - val_accuracy: 0.8650\n","Epoch 160/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4100 - accuracy: 0.8690 - val_loss: 0.4235 - val_accuracy: 0.8659\n","Epoch 161/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4071 - accuracy: 0.8710 - val_loss: 0.4248 - val_accuracy: 0.8637\n","Epoch 162/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4095 - accuracy: 0.8697 - val_loss: 0.4212 - val_accuracy: 0.8662\n","Epoch 163/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4041 - accuracy: 0.8723 - val_loss: 0.4191 - val_accuracy: 0.8662\n","Epoch 164/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4069 - accuracy: 0.8705 - val_loss: 0.4259 - val_accuracy: 0.8664\n","Epoch 165/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4072 - accuracy: 0.8705 - val_loss: 0.4266 - val_accuracy: 0.8651\n","Epoch 166/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4092 - accuracy: 0.8690 - val_loss: 0.4222 - val_accuracy: 0.8658\n","Epoch 167/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4082 - accuracy: 0.8691 - val_loss: 0.4255 - val_accuracy: 0.8654\n","Epoch 168/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4102 - accuracy: 0.8685 - val_loss: 0.4235 - val_accuracy: 0.8649\n","Epoch 169/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4089 - accuracy: 0.8697 - val_loss: 0.4228 - val_accuracy: 0.8671\n","Epoch 170/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4030 - accuracy: 0.8710 - val_loss: 0.4191 - val_accuracy: 0.8649\n","Epoch 171/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4057 - accuracy: 0.8701 - val_loss: 0.4213 - val_accuracy: 0.8652\n","Epoch 172/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4045 - accuracy: 0.8705 - val_loss: 0.4208 - val_accuracy: 0.8648\n","Epoch 173/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4068 - accuracy: 0.8704 - val_loss: 0.4263 - val_accuracy: 0.8646\n","Epoch 174/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4036 - accuracy: 0.8713 - val_loss: 0.4270 - val_accuracy: 0.8638\n","Epoch 175/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4049 - accuracy: 0.8698 - val_loss: 0.4231 - val_accuracy: 0.8660\n","Epoch 176/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4023 - accuracy: 0.8719 - val_loss: 0.4212 - val_accuracy: 0.8659\n","Epoch 177/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4018 - accuracy: 0.8717 - val_loss: 0.4202 - val_accuracy: 0.8669\n","Epoch 178/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4050 - accuracy: 0.8696 - val_loss: 0.4218 - val_accuracy: 0.8658\n","Epoch 179/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4041 - accuracy: 0.8711 - val_loss: 0.4212 - val_accuracy: 0.8645\n","Epoch 180/1000\n","42/42 [==============================] - 4s 90ms/step - loss: 0.4017 - accuracy: 0.8715 - val_loss: 0.4253 - val_accuracy: 0.8653\n","Epoch 181/1000\n","42/42 [==============================] - 4s 90ms/step - loss: 0.4019 - accuracy: 0.8714 - val_loss: 0.4203 - val_accuracy: 0.8679\n","Epoch 182/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4011 - accuracy: 0.8719 - val_loss: 0.4222 - val_accuracy: 0.8652\n","Epoch 183/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4029 - accuracy: 0.8724 - val_loss: 0.4227 - val_accuracy: 0.8654\n","Epoch 184/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3975 - accuracy: 0.8718 - val_loss: 0.4244 - val_accuracy: 0.8654\n","Epoch 185/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4000 - accuracy: 0.8702 - val_loss: 0.4233 - val_accuracy: 0.8650\n","Epoch 186/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4029 - accuracy: 0.8712 - val_loss: 0.4194 - val_accuracy: 0.8656\n","Epoch 187/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4013 - accuracy: 0.8735 - val_loss: 0.4207 - val_accuracy: 0.8658\n","Epoch 188/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4059 - accuracy: 0.8702 - val_loss: 0.4197 - val_accuracy: 0.8678\n","Epoch 189/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3994 - accuracy: 0.8711 - val_loss: 0.4198 - val_accuracy: 0.8647\n","Epoch 190/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4003 - accuracy: 0.8723 - val_loss: 0.4222 - val_accuracy: 0.8678\n","Epoch 191/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4016 - accuracy: 0.8718 - val_loss: 0.4168 - val_accuracy: 0.8687\n","Epoch 192/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3974 - accuracy: 0.8719 - val_loss: 0.4219 - val_accuracy: 0.8644\n","Epoch 193/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3994 - accuracy: 0.8722 - val_loss: 0.4220 - val_accuracy: 0.8651\n","Epoch 194/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3977 - accuracy: 0.8730 - val_loss: 0.4204 - val_accuracy: 0.8671\n","Epoch 195/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3949 - accuracy: 0.8739 - val_loss: 0.4232 - val_accuracy: 0.8655\n","Epoch 196/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3981 - accuracy: 0.8705 - val_loss: 0.4214 - val_accuracy: 0.8659\n","Epoch 197/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3954 - accuracy: 0.8726 - val_loss: 0.4222 - val_accuracy: 0.8675\n","Epoch 198/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3975 - accuracy: 0.8712 - val_loss: 0.4211 - val_accuracy: 0.8665\n","Epoch 199/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3969 - accuracy: 0.8730 - val_loss: 0.4215 - val_accuracy: 0.8663\n","Epoch 200/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3974 - accuracy: 0.8728 - val_loss: 0.4219 - val_accuracy: 0.8643\n","Epoch 201/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3973 - accuracy: 0.8708 - val_loss: 0.4224 - val_accuracy: 0.8647\n","Epoch 202/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.3994 - accuracy: 0.8725 - val_loss: 0.4236 - val_accuracy: 0.8649\n","Epoch 203/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4004 - accuracy: 0.8723 - val_loss: 0.4191 - val_accuracy: 0.8656\n","Epoch 204/1000\n","42/42 [==============================] - 4s 90ms/step - loss: 0.3958 - accuracy: 0.8732 - val_loss: 0.4168 - val_accuracy: 0.8660\n","Epoch 205/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.3944 - accuracy: 0.8735 - val_loss: 0.4208 - val_accuracy: 0.8672\n","Epoch 206/1000\n","42/42 [==============================] - 4s 92ms/step - loss: 0.3963 - accuracy: 0.8723 - val_loss: 0.4179 - val_accuracy: 0.8679\n","Epoch 207/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.3964 - accuracy: 0.8722 - val_loss: 0.4203 - val_accuracy: 0.8636\n","Epoch 208/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.3937 - accuracy: 0.8724 - val_loss: 0.4197 - val_accuracy: 0.8657\n","Epoch 209/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3914 - accuracy: 0.8739 - val_loss: 0.4229 - val_accuracy: 0.8657\n","Epoch 210/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3956 - accuracy: 0.8724 - val_loss: 0.4194 - val_accuracy: 0.8676\n","Epoch 211/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3960 - accuracy: 0.8727 - val_loss: 0.4240 - val_accuracy: 0.8667\n","Epoch 212/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3930 - accuracy: 0.8723 - val_loss: 0.4221 - val_accuracy: 0.8667\n","Epoch 213/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3928 - accuracy: 0.8748 - val_loss: 0.4237 - val_accuracy: 0.8674\n","Epoch 214/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3967 - accuracy: 0.8721 - val_loss: 0.4151 - val_accuracy: 0.8685\n","Epoch 215/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3941 - accuracy: 0.8742 - val_loss: 0.4195 - val_accuracy: 0.8666\n","Epoch 216/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3978 - accuracy: 0.8720 - val_loss: 0.4199 - val_accuracy: 0.8662\n","Epoch 217/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3996 - accuracy: 0.8704 - val_loss: 0.4216 - val_accuracy: 0.8655\n","Epoch 218/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3916 - accuracy: 0.8724 - val_loss: 0.4176 - val_accuracy: 0.8679\n","Epoch 219/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3929 - accuracy: 0.8727 - val_loss: 0.4160 - val_accuracy: 0.8676\n","Epoch 220/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3921 - accuracy: 0.8724 - val_loss: 0.4169 - val_accuracy: 0.8684\n","Epoch 221/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3931 - accuracy: 0.8722 - val_loss: 0.4175 - val_accuracy: 0.8664\n","Epoch 222/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3922 - accuracy: 0.8724 - val_loss: 0.4170 - val_accuracy: 0.8672\n","Epoch 223/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3884 - accuracy: 0.8749 - val_loss: 0.4186 - val_accuracy: 0.8680\n","Epoch 224/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3932 - accuracy: 0.8735 - val_loss: 0.4194 - val_accuracy: 0.8661\n","Epoch 225/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3926 - accuracy: 0.8739 - val_loss: 0.4239 - val_accuracy: 0.8658\n","Epoch 226/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3910 - accuracy: 0.8744 - val_loss: 0.4212 - val_accuracy: 0.8662\n","Epoch 227/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3898 - accuracy: 0.8737 - val_loss: 0.4201 - val_accuracy: 0.8673\n","Epoch 228/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3907 - accuracy: 0.8738 - val_loss: 0.4186 - val_accuracy: 0.8664\n","Epoch 229/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3935 - accuracy: 0.8740 - val_loss: 0.4208 - val_accuracy: 0.8682\n","Epoch 230/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3896 - accuracy: 0.8750 - val_loss: 0.4168 - val_accuracy: 0.8690\n","Epoch 231/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3903 - accuracy: 0.8752 - val_loss: 0.4217 - val_accuracy: 0.8666\n","Epoch 232/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3919 - accuracy: 0.8745 - val_loss: 0.4185 - val_accuracy: 0.8668\n","Epoch 233/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3884 - accuracy: 0.8744 - val_loss: 0.4210 - val_accuracy: 0.8684\n","Epoch 234/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3897 - accuracy: 0.8743 - val_loss: 0.4189 - val_accuracy: 0.8667\n","Epoch 235/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3893 - accuracy: 0.8735 - val_loss: 0.4168 - val_accuracy: 0.8674\n","Epoch 236/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3847 - accuracy: 0.8751 - val_loss: 0.4150 - val_accuracy: 0.8681\n","Epoch 237/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3854 - accuracy: 0.8759 - val_loss: 0.4225 - val_accuracy: 0.8656\n","Epoch 238/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3827 - accuracy: 0.8753 - val_loss: 0.4176 - val_accuracy: 0.8664\n","Epoch 239/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3864 - accuracy: 0.8755 - val_loss: 0.4199 - val_accuracy: 0.8677\n","Epoch 240/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3902 - accuracy: 0.8739 - val_loss: 0.4227 - val_accuracy: 0.8661\n","Epoch 241/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3879 - accuracy: 0.8742 - val_loss: 0.4206 - val_accuracy: 0.8666\n","Epoch 242/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3902 - accuracy: 0.8748 - val_loss: 0.4207 - val_accuracy: 0.8673\n","Epoch 243/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3861 - accuracy: 0.8748 - val_loss: 0.4196 - val_accuracy: 0.8657\n","Epoch 244/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3858 - accuracy: 0.8749 - val_loss: 0.4200 - val_accuracy: 0.8684\n","Epoch 245/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3891 - accuracy: 0.8754 - val_loss: 0.4218 - val_accuracy: 0.8660\n","Epoch 246/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3874 - accuracy: 0.8743 - val_loss: 0.4225 - val_accuracy: 0.8660\n","Epoch 247/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.3880 - accuracy: 0.8738 - val_loss: 0.4201 - val_accuracy: 0.8668\n","Epoch 248/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.3861 - accuracy: 0.8755 - val_loss: 0.4231 - val_accuracy: 0.8670\n","Epoch 249/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3849 - accuracy: 0.8761 - val_loss: 0.4219 - val_accuracy: 0.8659\n","Epoch 250/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3857 - accuracy: 0.8732 - val_loss: 0.4210 - val_accuracy: 0.8675\n","Epoch 251/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3855 - accuracy: 0.8750 - val_loss: 0.4201 - val_accuracy: 0.8660\n","Epoch 252/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3872 - accuracy: 0.8752 - val_loss: 0.4186 - val_accuracy: 0.8658\n","Epoch 253/1000\n","42/42 [==============================] - 5s 121ms/step - loss: 0.3853 - accuracy: 0.8748 - val_loss: 0.4222 - val_accuracy: 0.8650\n","Epoch 254/1000\n","42/42 [==============================] - 6s 133ms/step - loss: 0.3858 - accuracy: 0.8745 - val_loss: 0.4207 - val_accuracy: 0.8655\n","Epoch 255/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3828 - accuracy: 0.8761 - val_loss: 0.4247 - val_accuracy: 0.8662\n","Epoch 256/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3858 - accuracy: 0.8749 - val_loss: 0.4180 - val_accuracy: 0.8684\n","Epoch 257/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3869 - accuracy: 0.8741 - val_loss: 0.4200 - val_accuracy: 0.8660\n","Epoch 258/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3863 - accuracy: 0.8756 - val_loss: 0.4248 - val_accuracy: 0.8644\n","Epoch 259/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3911 - accuracy: 0.8749 - val_loss: 0.4226 - val_accuracy: 0.8645\n","Epoch 260/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3832 - accuracy: 0.8749 - val_loss: 0.4212 - val_accuracy: 0.8657\n","Epoch 261/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3839 - accuracy: 0.8743 - val_loss: 0.4200 - val_accuracy: 0.8673\n","Epoch 262/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3866 - accuracy: 0.8747 - val_loss: 0.4204 - val_accuracy: 0.8666\n","Epoch 263/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3842 - accuracy: 0.8753 - val_loss: 0.4221 - val_accuracy: 0.8682\n","Epoch 264/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.3853 - accuracy: 0.8752 - val_loss: 0.4223 - val_accuracy: 0.8664\n","Epoch 265/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.3828 - accuracy: 0.8761 - val_loss: 0.4235 - val_accuracy: 0.8671\n","Epoch 266/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3811 - accuracy: 0.8762 - val_loss: 0.4244 - val_accuracy: 0.8652\n","Epoch 267/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3845 - accuracy: 0.8744 - val_loss: 0.4245 - val_accuracy: 0.8651\n","Epoch 268/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3888 - accuracy: 0.8739 - val_loss: 0.4243 - val_accuracy: 0.8656\n","Epoch 269/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3846 - accuracy: 0.8749 - val_loss: 0.4228 - val_accuracy: 0.8657\n","Epoch 270/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3791 - accuracy: 0.8777 - val_loss: 0.4218 - val_accuracy: 0.8678\n","Epoch 271/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3817 - accuracy: 0.8752 - val_loss: 0.4217 - val_accuracy: 0.8662\n","Epoch 272/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3792 - accuracy: 0.8769 - val_loss: 0.4216 - val_accuracy: 0.8661\n","Epoch 273/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3848 - accuracy: 0.8751 - val_loss: 0.4177 - val_accuracy: 0.8663\n","Epoch 274/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3825 - accuracy: 0.8760 - val_loss: 0.4217 - val_accuracy: 0.8667\n","Epoch 275/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3800 - accuracy: 0.8752 - val_loss: 0.4244 - val_accuracy: 0.8656\n","Epoch 276/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.3823 - accuracy: 0.8760 - val_loss: 0.4218 - val_accuracy: 0.8653\n","Epoch 277/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.3815 - accuracy: 0.8753 - val_loss: 0.4220 - val_accuracy: 0.8655\n","Epoch 278/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3823 - accuracy: 0.8766 - val_loss: 0.4194 - val_accuracy: 0.8661\n","Epoch 279/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3796 - accuracy: 0.8762 - val_loss: 0.4218 - val_accuracy: 0.8664\n","Epoch 280/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3778 - accuracy: 0.8777 - val_loss: 0.4194 - val_accuracy: 0.8663\n","Epoch 281/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3795 - accuracy: 0.8760 - val_loss: 0.4233 - val_accuracy: 0.8680\n","Epoch 282/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3817 - accuracy: 0.8746 - val_loss: 0.4283 - val_accuracy: 0.8651\n","Epoch 283/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3818 - accuracy: 0.8759 - val_loss: 0.4258 - val_accuracy: 0.8647\n","Epoch 284/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3780 - accuracy: 0.8764 - val_loss: 0.4230 - val_accuracy: 0.8657\n","Epoch 285/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3800 - accuracy: 0.8766 - val_loss: 0.4194 - val_accuracy: 0.8663\n","Epoch 286/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3801 - accuracy: 0.8762 - val_loss: 0.4221 - val_accuracy: 0.8655\n","Epoch 00286: early stopping\n","13/13 [==============================] - 0s 12ms/step\n","######### Training on Fold 4  #############\n","Epoch 1/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 1.9284 - accuracy: 0.3485 - val_loss: 1.7204 - val_accuracy: 0.3893\n","Epoch 2/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 1.7078 - accuracy: 0.3743 - val_loss: 1.6664 - val_accuracy: 0.4393\n","Epoch 3/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 1.6689 - accuracy: 0.3933 - val_loss: 1.6344 - val_accuracy: 0.4917\n","Epoch 4/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 1.6112 - accuracy: 0.4483 - val_loss: 1.4971 - val_accuracy: 0.5866\n","Epoch 5/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 1.4231 - accuracy: 0.5761 - val_loss: 1.1460 - val_accuracy: 0.6892\n","Epoch 6/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 1.1165 - accuracy: 0.6842 - val_loss: 0.9023 - val_accuracy: 0.7255\n","Epoch 7/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.9731 - accuracy: 0.7185 - val_loss: 0.8550 - val_accuracy: 0.7421\n","Epoch 8/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.8855 - accuracy: 0.7427 - val_loss: 0.8074 - val_accuracy: 0.7592\n","Epoch 9/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.8296 - accuracy: 0.7591 - val_loss: 0.7394 - val_accuracy: 0.7843\n","Epoch 10/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.7851 - accuracy: 0.7715 - val_loss: 0.6946 - val_accuracy: 0.7937\n","Epoch 11/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.7466 - accuracy: 0.7806 - val_loss: 0.6600 - val_accuracy: 0.8074\n","Epoch 12/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.7139 - accuracy: 0.7925 - val_loss: 0.6334 - val_accuracy: 0.8174\n","Epoch 13/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.6868 - accuracy: 0.7997 - val_loss: 0.6058 - val_accuracy: 0.8240\n","Epoch 14/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.6554 - accuracy: 0.8107 - val_loss: 0.5747 - val_accuracy: 0.8321\n","Epoch 15/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.6264 - accuracy: 0.8171 - val_loss: 0.5511 - val_accuracy: 0.8363\n","Epoch 16/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.6050 - accuracy: 0.8227 - val_loss: 0.5392 - val_accuracy: 0.8390\n","Epoch 17/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5873 - accuracy: 0.8268 - val_loss: 0.5218 - val_accuracy: 0.8424\n","Epoch 18/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5711 - accuracy: 0.8302 - val_loss: 0.5282 - val_accuracy: 0.8427\n","Epoch 19/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5620 - accuracy: 0.8337 - val_loss: 0.5073 - val_accuracy: 0.8510\n","Epoch 20/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5499 - accuracy: 0.8361 - val_loss: 0.4981 - val_accuracy: 0.8530\n","Epoch 21/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5474 - accuracy: 0.8387 - val_loss: 0.4952 - val_accuracy: 0.8517\n","Epoch 22/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5427 - accuracy: 0.8380 - val_loss: 0.4939 - val_accuracy: 0.8531\n","Epoch 23/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5374 - accuracy: 0.8399 - val_loss: 0.4819 - val_accuracy: 0.8554\n","Epoch 24/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5289 - accuracy: 0.8401 - val_loss: 0.4900 - val_accuracy: 0.8529\n","Epoch 25/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5251 - accuracy: 0.8420 - val_loss: 0.4818 - val_accuracy: 0.8563\n","Epoch 26/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5196 - accuracy: 0.8429 - val_loss: 0.4734 - val_accuracy: 0.8572\n","Epoch 27/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5196 - accuracy: 0.8437 - val_loss: 0.4741 - val_accuracy: 0.8573\n","Epoch 28/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5204 - accuracy: 0.8418 - val_loss: 0.4881 - val_accuracy: 0.8544\n","Epoch 29/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5160 - accuracy: 0.8438 - val_loss: 0.4723 - val_accuracy: 0.8586\n","Epoch 30/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5128 - accuracy: 0.8457 - val_loss: 0.4740 - val_accuracy: 0.8566\n","Epoch 31/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.5069 - accuracy: 0.8473 - val_loss: 0.4738 - val_accuracy: 0.8573\n","Epoch 32/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5064 - accuracy: 0.8480 - val_loss: 0.4750 - val_accuracy: 0.8568\n","Epoch 33/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5039 - accuracy: 0.8473 - val_loss: 0.4698 - val_accuracy: 0.8585\n","Epoch 34/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4980 - accuracy: 0.8500 - val_loss: 0.4688 - val_accuracy: 0.8580\n","Epoch 35/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4961 - accuracy: 0.8492 - val_loss: 0.4634 - val_accuracy: 0.8580\n","Epoch 36/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4964 - accuracy: 0.8499 - val_loss: 0.4626 - val_accuracy: 0.8587\n","Epoch 37/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4952 - accuracy: 0.8505 - val_loss: 0.4614 - val_accuracy: 0.8605\n","Epoch 38/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4903 - accuracy: 0.8501 - val_loss: 0.4618 - val_accuracy: 0.8607\n","Epoch 39/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4913 - accuracy: 0.8500 - val_loss: 0.4571 - val_accuracy: 0.8628\n","Epoch 40/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4874 - accuracy: 0.8519 - val_loss: 0.4595 - val_accuracy: 0.8589\n","Epoch 41/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4867 - accuracy: 0.8519 - val_loss: 0.4643 - val_accuracy: 0.8605\n","Epoch 42/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4856 - accuracy: 0.8524 - val_loss: 0.4550 - val_accuracy: 0.8612\n","Epoch 43/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4853 - accuracy: 0.8509 - val_loss: 0.4568 - val_accuracy: 0.8582\n","Epoch 44/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4854 - accuracy: 0.8515 - val_loss: 0.4525 - val_accuracy: 0.8624\n","Epoch 45/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4829 - accuracy: 0.8521 - val_loss: 0.4528 - val_accuracy: 0.8613\n","Epoch 46/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4765 - accuracy: 0.8538 - val_loss: 0.4513 - val_accuracy: 0.8604\n","Epoch 47/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4761 - accuracy: 0.8535 - val_loss: 0.4546 - val_accuracy: 0.8627\n","Epoch 48/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4780 - accuracy: 0.8535 - val_loss: 0.4598 - val_accuracy: 0.8612\n","Epoch 49/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4751 - accuracy: 0.8542 - val_loss: 0.4491 - val_accuracy: 0.8599\n","Epoch 50/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4731 - accuracy: 0.8540 - val_loss: 0.4568 - val_accuracy: 0.8603\n","Epoch 51/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4755 - accuracy: 0.8540 - val_loss: 0.4472 - val_accuracy: 0.8618\n","Epoch 52/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4698 - accuracy: 0.8541 - val_loss: 0.4492 - val_accuracy: 0.8623\n","Epoch 53/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4721 - accuracy: 0.8558 - val_loss: 0.4551 - val_accuracy: 0.8609\n","Epoch 54/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4727 - accuracy: 0.8560 - val_loss: 0.4487 - val_accuracy: 0.8639\n","Epoch 55/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4717 - accuracy: 0.8544 - val_loss: 0.4487 - val_accuracy: 0.8617\n","Epoch 56/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4643 - accuracy: 0.8569 - val_loss: 0.4458 - val_accuracy: 0.8645\n","Epoch 57/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4658 - accuracy: 0.8561 - val_loss: 0.4516 - val_accuracy: 0.8612\n","Epoch 58/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4649 - accuracy: 0.8563 - val_loss: 0.4410 - val_accuracy: 0.8658\n","Epoch 59/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4630 - accuracy: 0.8563 - val_loss: 0.4494 - val_accuracy: 0.8635\n","Epoch 60/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4631 - accuracy: 0.8568 - val_loss: 0.4423 - val_accuracy: 0.8631\n","Epoch 61/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4594 - accuracy: 0.8588 - val_loss: 0.4433 - val_accuracy: 0.8629\n","Epoch 62/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4596 - accuracy: 0.8578 - val_loss: 0.4399 - val_accuracy: 0.8639\n","Epoch 63/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4557 - accuracy: 0.8577 - val_loss: 0.4466 - val_accuracy: 0.8650\n","Epoch 64/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4588 - accuracy: 0.8571 - val_loss: 0.4427 - val_accuracy: 0.8644\n","Epoch 65/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4575 - accuracy: 0.8580 - val_loss: 0.4507 - val_accuracy: 0.8612\n","Epoch 66/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4616 - accuracy: 0.8572 - val_loss: 0.4372 - val_accuracy: 0.8669\n","Epoch 67/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4537 - accuracy: 0.8584 - val_loss: 0.4413 - val_accuracy: 0.8643\n","Epoch 68/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4563 - accuracy: 0.8581 - val_loss: 0.4393 - val_accuracy: 0.8646\n","Epoch 69/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4531 - accuracy: 0.8602 - val_loss: 0.4406 - val_accuracy: 0.8668\n","Epoch 70/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4496 - accuracy: 0.8606 - val_loss: 0.4377 - val_accuracy: 0.8652\n","Epoch 71/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4498 - accuracy: 0.8596 - val_loss: 0.4377 - val_accuracy: 0.8658\n","Epoch 72/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4512 - accuracy: 0.8593 - val_loss: 0.4430 - val_accuracy: 0.8634\n","Epoch 73/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4504 - accuracy: 0.8598 - val_loss: 0.4348 - val_accuracy: 0.8651\n","Epoch 74/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4512 - accuracy: 0.8587 - val_loss: 0.4385 - val_accuracy: 0.8651\n","Epoch 75/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4497 - accuracy: 0.8601 - val_loss: 0.4360 - val_accuracy: 0.8656\n","Epoch 76/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4494 - accuracy: 0.8601 - val_loss: 0.4357 - val_accuracy: 0.8656\n","Epoch 77/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4469 - accuracy: 0.8602 - val_loss: 0.4374 - val_accuracy: 0.8662\n","Epoch 78/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4475 - accuracy: 0.8610 - val_loss: 0.4377 - val_accuracy: 0.8631\n","Epoch 79/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4468 - accuracy: 0.8604 - val_loss: 0.4372 - val_accuracy: 0.8666\n","Epoch 80/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4475 - accuracy: 0.8615 - val_loss: 0.4387 - val_accuracy: 0.8637\n","Epoch 81/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4479 - accuracy: 0.8609 - val_loss: 0.4434 - val_accuracy: 0.8649\n","Epoch 82/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4471 - accuracy: 0.8593 - val_loss: 0.4371 - val_accuracy: 0.8639\n","Epoch 83/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4424 - accuracy: 0.8598 - val_loss: 0.4346 - val_accuracy: 0.8652\n","Epoch 84/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4445 - accuracy: 0.8611 - val_loss: 0.4432 - val_accuracy: 0.8653\n","Epoch 85/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4454 - accuracy: 0.8600 - val_loss: 0.4365 - val_accuracy: 0.8652\n","Epoch 86/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4407 - accuracy: 0.8613 - val_loss: 0.4365 - val_accuracy: 0.8634\n","Epoch 87/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4472 - accuracy: 0.8594 - val_loss: 0.4350 - val_accuracy: 0.8656\n","Epoch 88/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4437 - accuracy: 0.8604 - val_loss: 0.4363 - val_accuracy: 0.8673\n","Epoch 89/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4441 - accuracy: 0.8619 - val_loss: 0.4359 - val_accuracy: 0.8658\n","Epoch 90/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4400 - accuracy: 0.8622 - val_loss: 0.4334 - val_accuracy: 0.8665\n","Epoch 91/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4389 - accuracy: 0.8626 - val_loss: 0.4340 - val_accuracy: 0.8680\n","Epoch 92/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4362 - accuracy: 0.8612 - val_loss: 0.4317 - val_accuracy: 0.8669\n","Epoch 93/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4406 - accuracy: 0.8626 - val_loss: 0.4354 - val_accuracy: 0.8649\n","Epoch 94/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4389 - accuracy: 0.8624 - val_loss: 0.4360 - val_accuracy: 0.8663\n","Epoch 95/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4374 - accuracy: 0.8618 - val_loss: 0.4310 - val_accuracy: 0.8688\n","Epoch 96/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4346 - accuracy: 0.8632 - val_loss: 0.4342 - val_accuracy: 0.8663\n","Epoch 97/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4381 - accuracy: 0.8616 - val_loss: 0.4324 - val_accuracy: 0.8653\n","Epoch 98/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4333 - accuracy: 0.8623 - val_loss: 0.4316 - val_accuracy: 0.8663\n","Epoch 99/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4322 - accuracy: 0.8634 - val_loss: 0.4383 - val_accuracy: 0.8658\n","Epoch 100/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4339 - accuracy: 0.8629 - val_loss: 0.4299 - val_accuracy: 0.8679\n","Epoch 101/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4329 - accuracy: 0.8634 - val_loss: 0.4336 - val_accuracy: 0.8664\n","Epoch 102/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4351 - accuracy: 0.8622 - val_loss: 0.4345 - val_accuracy: 0.8656\n","Epoch 103/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4333 - accuracy: 0.8634 - val_loss: 0.4297 - val_accuracy: 0.8657\n","Epoch 104/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4310 - accuracy: 0.8644 - val_loss: 0.4308 - val_accuracy: 0.8666\n","Epoch 105/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4349 - accuracy: 0.8624 - val_loss: 0.4283 - val_accuracy: 0.8652\n","Epoch 106/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4320 - accuracy: 0.8642 - val_loss: 0.4328 - val_accuracy: 0.8671\n","Epoch 107/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4265 - accuracy: 0.8640 - val_loss: 0.4337 - val_accuracy: 0.8674\n","Epoch 108/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4279 - accuracy: 0.8648 - val_loss: 0.4334 - val_accuracy: 0.8651\n","Epoch 109/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4284 - accuracy: 0.8646 - val_loss: 0.4310 - val_accuracy: 0.8692\n","Epoch 110/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4274 - accuracy: 0.8640 - val_loss: 0.4291 - val_accuracy: 0.8695\n","Epoch 111/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4294 - accuracy: 0.8646 - val_loss: 0.4355 - val_accuracy: 0.8647\n","Epoch 112/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4259 - accuracy: 0.8650 - val_loss: 0.4286 - val_accuracy: 0.8681\n","Epoch 113/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4267 - accuracy: 0.8650 - val_loss: 0.4353 - val_accuracy: 0.8665\n","Epoch 114/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4286 - accuracy: 0.8648 - val_loss: 0.4334 - val_accuracy: 0.8676\n","Epoch 115/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4300 - accuracy: 0.8641 - val_loss: 0.4302 - val_accuracy: 0.8681\n","Epoch 116/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4271 - accuracy: 0.8653 - val_loss: 0.4295 - val_accuracy: 0.8676\n","Epoch 117/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4251 - accuracy: 0.8650 - val_loss: 0.4288 - val_accuracy: 0.8678\n","Epoch 118/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4230 - accuracy: 0.8657 - val_loss: 0.4277 - val_accuracy: 0.8703\n","Epoch 119/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4242 - accuracy: 0.8650 - val_loss: 0.4317 - val_accuracy: 0.8680\n","Epoch 120/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4280 - accuracy: 0.8647 - val_loss: 0.4305 - val_accuracy: 0.8702\n","Epoch 121/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4204 - accuracy: 0.8662 - val_loss: 0.4291 - val_accuracy: 0.8667\n","Epoch 122/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4220 - accuracy: 0.8656 - val_loss: 0.4295 - val_accuracy: 0.8676\n","Epoch 123/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4219 - accuracy: 0.8654 - val_loss: 0.4263 - val_accuracy: 0.8649\n","Epoch 124/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4226 - accuracy: 0.8657 - val_loss: 0.4273 - val_accuracy: 0.8672\n","Epoch 125/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4236 - accuracy: 0.8656 - val_loss: 0.4283 - val_accuracy: 0.8670\n","Epoch 126/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4258 - accuracy: 0.8651 - val_loss: 0.4271 - val_accuracy: 0.8681\n","Epoch 127/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4195 - accuracy: 0.8655 - val_loss: 0.4296 - val_accuracy: 0.8687\n","Epoch 128/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4213 - accuracy: 0.8647 - val_loss: 0.4290 - val_accuracy: 0.8675\n","Epoch 129/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4223 - accuracy: 0.8651 - val_loss: 0.4395 - val_accuracy: 0.8643\n","Epoch 130/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4203 - accuracy: 0.8639 - val_loss: 0.4280 - val_accuracy: 0.8676\n","Epoch 131/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4178 - accuracy: 0.8662 - val_loss: 0.4270 - val_accuracy: 0.8679\n","Epoch 132/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4176 - accuracy: 0.8666 - val_loss: 0.4287 - val_accuracy: 0.8661\n","Epoch 133/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4197 - accuracy: 0.8668 - val_loss: 0.4256 - val_accuracy: 0.8710\n","Epoch 134/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4194 - accuracy: 0.8666 - val_loss: 0.4281 - val_accuracy: 0.8666\n","Epoch 135/1000\n","42/42 [==============================] - 5s 115ms/step - loss: 0.4180 - accuracy: 0.8666 - val_loss: 0.4251 - val_accuracy: 0.8680\n","Epoch 136/1000\n","42/42 [==============================] - 6s 137ms/step - loss: 0.4179 - accuracy: 0.8664 - val_loss: 0.4363 - val_accuracy: 0.8676\n","Epoch 137/1000\n","42/42 [==============================] - 5s 110ms/step - loss: 0.4160 - accuracy: 0.8677 - val_loss: 0.4265 - val_accuracy: 0.8672\n","Epoch 138/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4202 - accuracy: 0.8663 - val_loss: 0.4256 - val_accuracy: 0.8669\n","Epoch 139/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4157 - accuracy: 0.8676 - val_loss: 0.4269 - val_accuracy: 0.8677\n","Epoch 140/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4158 - accuracy: 0.8676 - val_loss: 0.4270 - val_accuracy: 0.8699\n","Epoch 141/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4180 - accuracy: 0.8662 - val_loss: 0.4313 - val_accuracy: 0.8652\n","Epoch 142/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4154 - accuracy: 0.8675 - val_loss: 0.4294 - val_accuracy: 0.8694\n","Epoch 143/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4150 - accuracy: 0.8669 - val_loss: 0.4255 - val_accuracy: 0.8700\n","Epoch 144/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4186 - accuracy: 0.8661 - val_loss: 0.4300 - val_accuracy: 0.8695\n","Epoch 145/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4140 - accuracy: 0.8680 - val_loss: 0.4250 - val_accuracy: 0.8675\n","Epoch 146/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4105 - accuracy: 0.8677 - val_loss: 0.4308 - val_accuracy: 0.8692\n","Epoch 147/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4161 - accuracy: 0.8674 - val_loss: 0.4269 - val_accuracy: 0.8678\n","Epoch 148/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4133 - accuracy: 0.8680 - val_loss: 0.4252 - val_accuracy: 0.8709\n","Epoch 149/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4105 - accuracy: 0.8680 - val_loss: 0.4279 - val_accuracy: 0.8710\n","Epoch 150/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4136 - accuracy: 0.8677 - val_loss: 0.4277 - val_accuracy: 0.8686\n","Epoch 151/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4102 - accuracy: 0.8695 - val_loss: 0.4256 - val_accuracy: 0.8703\n","Epoch 152/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4134 - accuracy: 0.8685 - val_loss: 0.4264 - val_accuracy: 0.8676\n","Epoch 153/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4115 - accuracy: 0.8693 - val_loss: 0.4284 - val_accuracy: 0.8690\n","Epoch 154/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4137 - accuracy: 0.8671 - val_loss: 0.4251 - val_accuracy: 0.8678\n","Epoch 155/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4155 - accuracy: 0.8660 - val_loss: 0.4287 - val_accuracy: 0.8709\n","Epoch 156/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4089 - accuracy: 0.8695 - val_loss: 0.4230 - val_accuracy: 0.8706\n","Epoch 157/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4063 - accuracy: 0.8690 - val_loss: 0.4230 - val_accuracy: 0.8705\n","Epoch 158/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4075 - accuracy: 0.8683 - val_loss: 0.4279 - val_accuracy: 0.8688\n","Epoch 159/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4114 - accuracy: 0.8672 - val_loss: 0.4253 - val_accuracy: 0.8672\n","Epoch 160/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4089 - accuracy: 0.8677 - val_loss: 0.4238 - val_accuracy: 0.8719\n","Epoch 161/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4059 - accuracy: 0.8691 - val_loss: 0.4265 - val_accuracy: 0.8693\n","Epoch 162/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4086 - accuracy: 0.8695 - val_loss: 0.4250 - val_accuracy: 0.8695\n","Epoch 163/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4052 - accuracy: 0.8693 - val_loss: 0.4200 - val_accuracy: 0.8711\n","Epoch 164/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4050 - accuracy: 0.8697 - val_loss: 0.4258 - val_accuracy: 0.8683\n","Epoch 165/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4065 - accuracy: 0.8693 - val_loss: 0.4279 - val_accuracy: 0.8685\n","Epoch 166/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4061 - accuracy: 0.8704 - val_loss: 0.4241 - val_accuracy: 0.8674\n","Epoch 167/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4052 - accuracy: 0.8699 - val_loss: 0.4243 - val_accuracy: 0.8701\n","Epoch 168/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4072 - accuracy: 0.8676 - val_loss: 0.4285 - val_accuracy: 0.8672\n","Epoch 169/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4060 - accuracy: 0.8690 - val_loss: 0.4269 - val_accuracy: 0.8711\n","Epoch 170/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4041 - accuracy: 0.8698 - val_loss: 0.4270 - val_accuracy: 0.8689\n","Epoch 171/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4064 - accuracy: 0.8699 - val_loss: 0.4220 - val_accuracy: 0.8694\n","Epoch 172/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4064 - accuracy: 0.8699 - val_loss: 0.4235 - val_accuracy: 0.8719\n","Epoch 173/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4024 - accuracy: 0.8700 - val_loss: 0.4220 - val_accuracy: 0.8711\n","Epoch 174/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4061 - accuracy: 0.8682 - val_loss: 0.4236 - val_accuracy: 0.8692\n","Epoch 175/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4029 - accuracy: 0.8696 - val_loss: 0.4220 - val_accuracy: 0.8705\n","Epoch 176/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4020 - accuracy: 0.8699 - val_loss: 0.4209 - val_accuracy: 0.8699\n","Epoch 177/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4052 - accuracy: 0.8702 - val_loss: 0.4195 - val_accuracy: 0.8734\n","Epoch 178/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4017 - accuracy: 0.8700 - val_loss: 0.4254 - val_accuracy: 0.8694\n","Epoch 179/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4048 - accuracy: 0.8705 - val_loss: 0.4258 - val_accuracy: 0.8691\n","Epoch 180/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4051 - accuracy: 0.8704 - val_loss: 0.4237 - val_accuracy: 0.8700\n","Epoch 181/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4028 - accuracy: 0.8695 - val_loss: 0.4296 - val_accuracy: 0.8689\n","Epoch 182/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4006 - accuracy: 0.8709 - val_loss: 0.4252 - val_accuracy: 0.8695\n","Epoch 183/1000\n","42/42 [==============================] - 4s 95ms/step - loss: 0.4006 - accuracy: 0.8701 - val_loss: 0.4248 - val_accuracy: 0.8678\n","Epoch 184/1000\n","42/42 [==============================] - 4s 95ms/step - loss: 0.4024 - accuracy: 0.8709 - val_loss: 0.4273 - val_accuracy: 0.8694\n","Epoch 185/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4053 - accuracy: 0.8704 - val_loss: 0.4266 - val_accuracy: 0.8691\n","Epoch 186/1000\n","42/42 [==============================] - 4s 90ms/step - loss: 0.4010 - accuracy: 0.8706 - val_loss: 0.4249 - val_accuracy: 0.8692\n","Epoch 187/1000\n","42/42 [==============================] - 4s 92ms/step - loss: 0.4010 - accuracy: 0.8704 - val_loss: 0.4257 - val_accuracy: 0.8705\n","Epoch 188/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4015 - accuracy: 0.8696 - val_loss: 0.4259 - val_accuracy: 0.8702\n","Epoch 189/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4021 - accuracy: 0.8703 - val_loss: 0.4264 - val_accuracy: 0.8715\n","Epoch 190/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4005 - accuracy: 0.8704 - val_loss: 0.4261 - val_accuracy: 0.8702\n","Epoch 191/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4020 - accuracy: 0.8699 - val_loss: 0.4246 - val_accuracy: 0.8706\n","Epoch 192/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3977 - accuracy: 0.8704 - val_loss: 0.4244 - val_accuracy: 0.8705\n","Epoch 193/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4028 - accuracy: 0.8700 - val_loss: 0.4254 - val_accuracy: 0.8706\n","Epoch 194/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4046 - accuracy: 0.8710 - val_loss: 0.4270 - val_accuracy: 0.8687\n","Epoch 195/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3991 - accuracy: 0.8703 - val_loss: 0.4261 - val_accuracy: 0.8684\n","Epoch 196/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3998 - accuracy: 0.8711 - val_loss: 0.4230 - val_accuracy: 0.8725\n","Epoch 197/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3970 - accuracy: 0.8714 - val_loss: 0.4248 - val_accuracy: 0.8703\n","Epoch 198/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3999 - accuracy: 0.8709 - val_loss: 0.4216 - val_accuracy: 0.8715\n","Epoch 199/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4018 - accuracy: 0.8695 - val_loss: 0.4232 - val_accuracy: 0.8702\n","Epoch 200/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3963 - accuracy: 0.8712 - val_loss: 0.4238 - val_accuracy: 0.8702\n","Epoch 201/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3947 - accuracy: 0.8719 - val_loss: 0.4212 - val_accuracy: 0.8712\n","Epoch 202/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3988 - accuracy: 0.8723 - val_loss: 0.4216 - val_accuracy: 0.8706\n","Epoch 203/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3998 - accuracy: 0.8720 - val_loss: 0.4234 - val_accuracy: 0.8694\n","Epoch 204/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3961 - accuracy: 0.8717 - val_loss: 0.4271 - val_accuracy: 0.8698\n","Epoch 205/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3940 - accuracy: 0.8728 - val_loss: 0.4244 - val_accuracy: 0.8686\n","Epoch 206/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3954 - accuracy: 0.8729 - val_loss: 0.4225 - val_accuracy: 0.8683\n","Epoch 207/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3888 - accuracy: 0.8733 - val_loss: 0.4196 - val_accuracy: 0.8725\n","Epoch 208/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3937 - accuracy: 0.8720 - val_loss: 0.4247 - val_accuracy: 0.8690\n","Epoch 209/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3949 - accuracy: 0.8721 - val_loss: 0.4253 - val_accuracy: 0.8704\n","Epoch 210/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3914 - accuracy: 0.8737 - val_loss: 0.4262 - val_accuracy: 0.8688\n","Epoch 211/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3953 - accuracy: 0.8711 - val_loss: 0.4256 - val_accuracy: 0.8695\n","Epoch 212/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.3940 - accuracy: 0.8733 - val_loss: 0.4224 - val_accuracy: 0.8695\n","Epoch 213/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3960 - accuracy: 0.8704 - val_loss: 0.4260 - val_accuracy: 0.8721\n","Epoch 214/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3929 - accuracy: 0.8730 - val_loss: 0.4226 - val_accuracy: 0.8683\n","Epoch 215/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3909 - accuracy: 0.8726 - val_loss: 0.4293 - val_accuracy: 0.8676\n","Epoch 216/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3906 - accuracy: 0.8733 - val_loss: 0.4239 - val_accuracy: 0.8697\n","Epoch 217/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3944 - accuracy: 0.8716 - val_loss: 0.4220 - val_accuracy: 0.8693\n","Epoch 218/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3883 - accuracy: 0.8734 - val_loss: 0.4237 - val_accuracy: 0.8721\n","Epoch 219/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3920 - accuracy: 0.8723 - val_loss: 0.4244 - val_accuracy: 0.8733\n","Epoch 220/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3898 - accuracy: 0.8735 - val_loss: 0.4232 - val_accuracy: 0.8697\n","Epoch 221/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3888 - accuracy: 0.8734 - val_loss: 0.4241 - val_accuracy: 0.8699\n","Epoch 222/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3894 - accuracy: 0.8745 - val_loss: 0.4229 - val_accuracy: 0.8703\n","Epoch 223/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3945 - accuracy: 0.8718 - val_loss: 0.4264 - val_accuracy: 0.8714\n","Epoch 224/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.3893 - accuracy: 0.8726 - val_loss: 0.4247 - val_accuracy: 0.8697\n","Epoch 225/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3886 - accuracy: 0.8738 - val_loss: 0.4266 - val_accuracy: 0.8691\n","Epoch 226/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3904 - accuracy: 0.8741 - val_loss: 0.4257 - val_accuracy: 0.8711\n","Epoch 227/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3889 - accuracy: 0.8734 - val_loss: 0.4226 - val_accuracy: 0.8701\n","Epoch 00227: early stopping\n","13/13 [==============================] - 0s 11ms/step\n","######### Training on Fold 5  #############\n","Epoch 1/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 1.9281 - accuracy: 0.3488 - val_loss: 1.7183 - val_accuracy: 0.3693\n","Epoch 2/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 1.7111 - accuracy: 0.3745 - val_loss: 1.6701 - val_accuracy: 0.4318\n","Epoch 3/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 1.6706 - accuracy: 0.3932 - val_loss: 1.6296 - val_accuracy: 0.5175\n","Epoch 4/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 1.6011 - accuracy: 0.4563 - val_loss: 1.4458 - val_accuracy: 0.6234\n","Epoch 5/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 1.3580 - accuracy: 0.6067 - val_loss: 1.0213 - val_accuracy: 0.7062\n","Epoch 6/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 1.0599 - accuracy: 0.6998 - val_loss: 0.8943 - val_accuracy: 0.7278\n","Epoch 7/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.9348 - accuracy: 0.7296 - val_loss: 0.8220 - val_accuracy: 0.7619\n","Epoch 8/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.8726 - accuracy: 0.7486 - val_loss: 0.7748 - val_accuracy: 0.7770\n","Epoch 9/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.8280 - accuracy: 0.7578 - val_loss: 0.7254 - val_accuracy: 0.7889\n","Epoch 10/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.7817 - accuracy: 0.7730 - val_loss: 0.6898 - val_accuracy: 0.8023\n","Epoch 11/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.7461 - accuracy: 0.7833 - val_loss: 0.6521 - val_accuracy: 0.8130\n","Epoch 12/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.7149 - accuracy: 0.7936 - val_loss: 0.6263 - val_accuracy: 0.8163\n","Epoch 13/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.6869 - accuracy: 0.8027 - val_loss: 0.6012 - val_accuracy: 0.8221\n","Epoch 14/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.6592 - accuracy: 0.8089 - val_loss: 0.5734 - val_accuracy: 0.8284\n","Epoch 15/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.6246 - accuracy: 0.8178 - val_loss: 0.5504 - val_accuracy: 0.8361\n","Epoch 16/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.6102 - accuracy: 0.8236 - val_loss: 0.5398 - val_accuracy: 0.8389\n","Epoch 17/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5932 - accuracy: 0.8269 - val_loss: 0.5253 - val_accuracy: 0.8416\n","Epoch 18/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.5790 - accuracy: 0.8306 - val_loss: 0.5142 - val_accuracy: 0.8445\n","Epoch 19/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5650 - accuracy: 0.8347 - val_loss: 0.5123 - val_accuracy: 0.8479\n","Epoch 20/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5619 - accuracy: 0.8355 - val_loss: 0.5084 - val_accuracy: 0.8453\n","Epoch 21/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5549 - accuracy: 0.8354 - val_loss: 0.5071 - val_accuracy: 0.8449\n","Epoch 22/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5438 - accuracy: 0.8390 - val_loss: 0.4974 - val_accuracy: 0.8482\n","Epoch 23/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5398 - accuracy: 0.8397 - val_loss: 0.5003 - val_accuracy: 0.8451\n","Epoch 24/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5314 - accuracy: 0.8423 - val_loss: 0.5027 - val_accuracy: 0.8469\n","Epoch 25/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5332 - accuracy: 0.8407 - val_loss: 0.4868 - val_accuracy: 0.8513\n","Epoch 26/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5304 - accuracy: 0.8407 - val_loss: 0.4842 - val_accuracy: 0.8504\n","Epoch 27/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5222 - accuracy: 0.8437 - val_loss: 0.4914 - val_accuracy: 0.8489\n","Epoch 28/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5212 - accuracy: 0.8435 - val_loss: 0.4752 - val_accuracy: 0.8536\n","Epoch 29/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5163 - accuracy: 0.8462 - val_loss: 0.4757 - val_accuracy: 0.8537\n","Epoch 30/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5183 - accuracy: 0.8433 - val_loss: 0.4790 - val_accuracy: 0.8532\n","Epoch 31/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5150 - accuracy: 0.8448 - val_loss: 0.4729 - val_accuracy: 0.8535\n","Epoch 32/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5093 - accuracy: 0.8466 - val_loss: 0.4777 - val_accuracy: 0.8515\n","Epoch 33/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5052 - accuracy: 0.8470 - val_loss: 0.4863 - val_accuracy: 0.8480\n","Epoch 34/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.5076 - accuracy: 0.8468 - val_loss: 0.4773 - val_accuracy: 0.8527\n","Epoch 35/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5007 - accuracy: 0.8482 - val_loss: 0.4657 - val_accuracy: 0.8545\n","Epoch 36/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5015 - accuracy: 0.8483 - val_loss: 0.4726 - val_accuracy: 0.8514\n","Epoch 37/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4961 - accuracy: 0.8495 - val_loss: 0.4679 - val_accuracy: 0.8539\n","Epoch 38/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4934 - accuracy: 0.8505 - val_loss: 0.4666 - val_accuracy: 0.8548\n","Epoch 39/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4910 - accuracy: 0.8497 - val_loss: 0.4663 - val_accuracy: 0.8546\n","Epoch 40/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4902 - accuracy: 0.8511 - val_loss: 0.4593 - val_accuracy: 0.8575\n","Epoch 41/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4899 - accuracy: 0.8511 - val_loss: 0.4640 - val_accuracy: 0.8542\n","Epoch 42/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4914 - accuracy: 0.8503 - val_loss: 0.4620 - val_accuracy: 0.8574\n","Epoch 43/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4886 - accuracy: 0.8518 - val_loss: 0.4595 - val_accuracy: 0.8564\n","Epoch 44/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4860 - accuracy: 0.8512 - val_loss: 0.4636 - val_accuracy: 0.8553\n","Epoch 45/1000\n","42/42 [==============================] - 4s 93ms/step - loss: 0.4855 - accuracy: 0.8511 - val_loss: 0.4545 - val_accuracy: 0.8578\n","Epoch 46/1000\n","42/42 [==============================] - 4s 94ms/step - loss: 0.4818 - accuracy: 0.8524 - val_loss: 0.4633 - val_accuracy: 0.8551\n","Epoch 47/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4851 - accuracy: 0.8519 - val_loss: 0.4551 - val_accuracy: 0.8578\n","Epoch 48/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4762 - accuracy: 0.8519 - val_loss: 0.4625 - val_accuracy: 0.8535\n","Epoch 49/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4772 - accuracy: 0.8526 - val_loss: 0.4613 - val_accuracy: 0.8548\n","Epoch 50/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4776 - accuracy: 0.8528 - val_loss: 0.4538 - val_accuracy: 0.8569\n","Epoch 51/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4718 - accuracy: 0.8560 - val_loss: 0.4534 - val_accuracy: 0.8585\n","Epoch 52/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4767 - accuracy: 0.8540 - val_loss: 0.4590 - val_accuracy: 0.8577\n","Epoch 53/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4750 - accuracy: 0.8540 - val_loss: 0.4479 - val_accuracy: 0.8600\n","Epoch 54/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4724 - accuracy: 0.8548 - val_loss: 0.4505 - val_accuracy: 0.8575\n","Epoch 55/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4695 - accuracy: 0.8543 - val_loss: 0.4458 - val_accuracy: 0.8600\n","Epoch 56/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4665 - accuracy: 0.8553 - val_loss: 0.4497 - val_accuracy: 0.8580\n","Epoch 57/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4682 - accuracy: 0.8567 - val_loss: 0.4470 - val_accuracy: 0.8600\n","Epoch 58/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4678 - accuracy: 0.8556 - val_loss: 0.4503 - val_accuracy: 0.8582\n","Epoch 59/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4669 - accuracy: 0.8553 - val_loss: 0.4480 - val_accuracy: 0.8578\n","Epoch 60/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4608 - accuracy: 0.8573 - val_loss: 0.4430 - val_accuracy: 0.8609\n","Epoch 61/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4624 - accuracy: 0.8563 - val_loss: 0.4431 - val_accuracy: 0.8614\n","Epoch 62/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4613 - accuracy: 0.8568 - val_loss: 0.4445 - val_accuracy: 0.8591\n","Epoch 63/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4598 - accuracy: 0.8574 - val_loss: 0.4420 - val_accuracy: 0.8612\n","Epoch 64/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4609 - accuracy: 0.8583 - val_loss: 0.4407 - val_accuracy: 0.8607\n","Epoch 65/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4580 - accuracy: 0.8595 - val_loss: 0.4424 - val_accuracy: 0.8585\n","Epoch 66/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4564 - accuracy: 0.8594 - val_loss: 0.4392 - val_accuracy: 0.8638\n","Epoch 67/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4575 - accuracy: 0.8583 - val_loss: 0.4420 - val_accuracy: 0.8610\n","Epoch 68/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4549 - accuracy: 0.8587 - val_loss: 0.4429 - val_accuracy: 0.8629\n","Epoch 69/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4536 - accuracy: 0.8582 - val_loss: 0.4444 - val_accuracy: 0.8605\n","Epoch 70/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4586 - accuracy: 0.8576 - val_loss: 0.4418 - val_accuracy: 0.8595\n","Epoch 71/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4574 - accuracy: 0.8582 - val_loss: 0.4384 - val_accuracy: 0.8628\n","Epoch 72/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4563 - accuracy: 0.8590 - val_loss: 0.4432 - val_accuracy: 0.8631\n","Epoch 73/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4527 - accuracy: 0.8606 - val_loss: 0.4415 - val_accuracy: 0.8615\n","Epoch 74/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4514 - accuracy: 0.8612 - val_loss: 0.4409 - val_accuracy: 0.8609\n","Epoch 75/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4517 - accuracy: 0.8594 - val_loss: 0.4382 - val_accuracy: 0.8617\n","Epoch 76/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4505 - accuracy: 0.8594 - val_loss: 0.4382 - val_accuracy: 0.8615\n","Epoch 77/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4558 - accuracy: 0.8583 - val_loss: 0.4362 - val_accuracy: 0.8638\n","Epoch 78/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4467 - accuracy: 0.8598 - val_loss: 0.4364 - val_accuracy: 0.8625\n","Epoch 79/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4503 - accuracy: 0.8594 - val_loss: 0.4329 - val_accuracy: 0.8624\n","Epoch 80/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4491 - accuracy: 0.8604 - val_loss: 0.4474 - val_accuracy: 0.8583\n","Epoch 81/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4526 - accuracy: 0.8589 - val_loss: 0.4346 - val_accuracy: 0.8637\n","Epoch 82/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4503 - accuracy: 0.8588 - val_loss: 0.4411 - val_accuracy: 0.8629\n","Epoch 83/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4448 - accuracy: 0.8605 - val_loss: 0.4338 - val_accuracy: 0.8615\n","Epoch 84/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4480 - accuracy: 0.8598 - val_loss: 0.4436 - val_accuracy: 0.8598\n","Epoch 85/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4458 - accuracy: 0.8605 - val_loss: 0.4373 - val_accuracy: 0.8642\n","Epoch 86/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4424 - accuracy: 0.8621 - val_loss: 0.4311 - val_accuracy: 0.8639\n","Epoch 87/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4439 - accuracy: 0.8613 - val_loss: 0.4343 - val_accuracy: 0.8632\n","Epoch 88/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4411 - accuracy: 0.8612 - val_loss: 0.4345 - val_accuracy: 0.8636\n","Epoch 89/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4459 - accuracy: 0.8600 - val_loss: 0.4321 - val_accuracy: 0.8642\n","Epoch 90/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4423 - accuracy: 0.8626 - val_loss: 0.4366 - val_accuracy: 0.8612\n","Epoch 91/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4461 - accuracy: 0.8595 - val_loss: 0.4309 - val_accuracy: 0.8644\n","Epoch 92/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4431 - accuracy: 0.8614 - val_loss: 0.4318 - val_accuracy: 0.8640\n","Epoch 93/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4423 - accuracy: 0.8619 - val_loss: 0.4342 - val_accuracy: 0.8610\n","Epoch 94/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4358 - accuracy: 0.8625 - val_loss: 0.4267 - val_accuracy: 0.8652\n","Epoch 95/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4382 - accuracy: 0.8617 - val_loss: 0.4362 - val_accuracy: 0.8634\n","Epoch 96/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4387 - accuracy: 0.8624 - val_loss: 0.4346 - val_accuracy: 0.8624\n","Epoch 97/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4390 - accuracy: 0.8616 - val_loss: 0.4284 - val_accuracy: 0.8656\n","Epoch 98/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4336 - accuracy: 0.8639 - val_loss: 0.4314 - val_accuracy: 0.8646\n","Epoch 99/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4364 - accuracy: 0.8617 - val_loss: 0.4300 - val_accuracy: 0.8676\n","Epoch 100/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4356 - accuracy: 0.8640 - val_loss: 0.4315 - val_accuracy: 0.8634\n","Epoch 101/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4338 - accuracy: 0.8632 - val_loss: 0.4299 - val_accuracy: 0.8647\n","Epoch 102/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4340 - accuracy: 0.8635 - val_loss: 0.4302 - val_accuracy: 0.8669\n","Epoch 103/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4325 - accuracy: 0.8630 - val_loss: 0.4273 - val_accuracy: 0.8663\n","Epoch 104/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4322 - accuracy: 0.8634 - val_loss: 0.4289 - val_accuracy: 0.8645\n","Epoch 105/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4306 - accuracy: 0.8639 - val_loss: 0.4320 - val_accuracy: 0.8657\n","Epoch 106/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4344 - accuracy: 0.8634 - val_loss: 0.4323 - val_accuracy: 0.8625\n","Epoch 107/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4312 - accuracy: 0.8649 - val_loss: 0.4269 - val_accuracy: 0.8671\n","Epoch 108/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4297 - accuracy: 0.8652 - val_loss: 0.4277 - val_accuracy: 0.8645\n","Epoch 109/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4323 - accuracy: 0.8631 - val_loss: 0.4313 - val_accuracy: 0.8639\n","Epoch 110/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4295 - accuracy: 0.8651 - val_loss: 0.4282 - val_accuracy: 0.8644\n","Epoch 111/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4297 - accuracy: 0.8649 - val_loss: 0.4375 - val_accuracy: 0.8629\n","Epoch 112/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4312 - accuracy: 0.8642 - val_loss: 0.4268 - val_accuracy: 0.8647\n","Epoch 113/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4293 - accuracy: 0.8633 - val_loss: 0.4293 - val_accuracy: 0.8645\n","Epoch 114/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4278 - accuracy: 0.8653 - val_loss: 0.4271 - val_accuracy: 0.8662\n","Epoch 115/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4285 - accuracy: 0.8631 - val_loss: 0.4321 - val_accuracy: 0.8648\n","Epoch 116/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4293 - accuracy: 0.8647 - val_loss: 0.4216 - val_accuracy: 0.8694\n","Epoch 117/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4248 - accuracy: 0.8646 - val_loss: 0.4271 - val_accuracy: 0.8668\n","Epoch 118/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4264 - accuracy: 0.8648 - val_loss: 0.4301 - val_accuracy: 0.8664\n","Epoch 119/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4276 - accuracy: 0.8657 - val_loss: 0.4249 - val_accuracy: 0.8652\n","Epoch 120/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4255 - accuracy: 0.8651 - val_loss: 0.4275 - val_accuracy: 0.8652\n","Epoch 121/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4249 - accuracy: 0.8649 - val_loss: 0.4265 - val_accuracy: 0.8660\n","Epoch 122/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4225 - accuracy: 0.8656 - val_loss: 0.4292 - val_accuracy: 0.8649\n","Epoch 123/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4274 - accuracy: 0.8645 - val_loss: 0.4256 - val_accuracy: 0.8646\n","Epoch 124/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.4241 - accuracy: 0.8642 - val_loss: 0.4323 - val_accuracy: 0.8639\n","Epoch 125/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4259 - accuracy: 0.8645 - val_loss: 0.4279 - val_accuracy: 0.8648\n","Epoch 126/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4254 - accuracy: 0.8650 - val_loss: 0.4273 - val_accuracy: 0.8651\n","Epoch 127/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4207 - accuracy: 0.8654 - val_loss: 0.4202 - val_accuracy: 0.8668\n","Epoch 128/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4218 - accuracy: 0.8653 - val_loss: 0.4242 - val_accuracy: 0.8683\n","Epoch 129/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4211 - accuracy: 0.8649 - val_loss: 0.4254 - val_accuracy: 0.8675\n","Epoch 130/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4215 - accuracy: 0.8661 - val_loss: 0.4229 - val_accuracy: 0.8665\n","Epoch 131/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4194 - accuracy: 0.8666 - val_loss: 0.4200 - val_accuracy: 0.8662\n","Epoch 132/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4187 - accuracy: 0.8671 - val_loss: 0.4291 - val_accuracy: 0.8644\n","Epoch 133/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4179 - accuracy: 0.8660 - val_loss: 0.4233 - val_accuracy: 0.8663\n","Epoch 134/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4201 - accuracy: 0.8656 - val_loss: 0.4225 - val_accuracy: 0.8666\n","Epoch 135/1000\n","42/42 [==============================] - 4s 93ms/step - loss: 0.4227 - accuracy: 0.8666 - val_loss: 0.4256 - val_accuracy: 0.8666\n","Epoch 136/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4184 - accuracy: 0.8667 - val_loss: 0.4225 - val_accuracy: 0.8677\n","Epoch 137/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4205 - accuracy: 0.8658 - val_loss: 0.4274 - val_accuracy: 0.8655\n","Epoch 138/1000\n","42/42 [==============================] - 4s 89ms/step - loss: 0.4168 - accuracy: 0.8674 - val_loss: 0.4241 - val_accuracy: 0.8647\n","Epoch 139/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.4174 - accuracy: 0.8677 - val_loss: 0.4201 - val_accuracy: 0.8672\n","Epoch 140/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4185 - accuracy: 0.8669 - val_loss: 0.4242 - val_accuracy: 0.8670\n","Epoch 141/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4131 - accuracy: 0.8685 - val_loss: 0.4216 - val_accuracy: 0.8682\n","Epoch 142/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4158 - accuracy: 0.8659 - val_loss: 0.4225 - val_accuracy: 0.8662\n","Epoch 143/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4196 - accuracy: 0.8661 - val_loss: 0.4236 - val_accuracy: 0.8655\n","Epoch 144/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4181 - accuracy: 0.8664 - val_loss: 0.4257 - val_accuracy: 0.8688\n","Epoch 145/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4172 - accuracy: 0.8675 - val_loss: 0.4245 - val_accuracy: 0.8642\n","Epoch 146/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4163 - accuracy: 0.8661 - val_loss: 0.4267 - val_accuracy: 0.8656\n","Epoch 147/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4170 - accuracy: 0.8661 - val_loss: 0.4215 - val_accuracy: 0.8673\n","Epoch 148/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4160 - accuracy: 0.8681 - val_loss: 0.4265 - val_accuracy: 0.8661\n","Epoch 149/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4147 - accuracy: 0.8677 - val_loss: 0.4244 - val_accuracy: 0.8669\n","Epoch 150/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4151 - accuracy: 0.8677 - val_loss: 0.4246 - val_accuracy: 0.8685\n","Epoch 151/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4126 - accuracy: 0.8673 - val_loss: 0.4233 - val_accuracy: 0.8678\n","Epoch 152/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4128 - accuracy: 0.8685 - val_loss: 0.4236 - val_accuracy: 0.8681\n","Epoch 153/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4123 - accuracy: 0.8677 - val_loss: 0.4250 - val_accuracy: 0.8672\n","Epoch 154/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4136 - accuracy: 0.8683 - val_loss: 0.4216 - val_accuracy: 0.8678\n","Epoch 155/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4083 - accuracy: 0.8691 - val_loss: 0.4288 - val_accuracy: 0.8657\n","Epoch 156/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4098 - accuracy: 0.8691 - val_loss: 0.4230 - val_accuracy: 0.8699\n","Epoch 157/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4089 - accuracy: 0.8674 - val_loss: 0.4264 - val_accuracy: 0.8650\n","Epoch 158/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4106 - accuracy: 0.8683 - val_loss: 0.4221 - val_accuracy: 0.8662\n","Epoch 159/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4100 - accuracy: 0.8690 - val_loss: 0.4211 - val_accuracy: 0.8686\n","Epoch 160/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4107 - accuracy: 0.8677 - val_loss: 0.4249 - val_accuracy: 0.8675\n","Epoch 161/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4108 - accuracy: 0.8694 - val_loss: 0.4221 - val_accuracy: 0.8680\n","Epoch 162/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4115 - accuracy: 0.8678 - val_loss: 0.4252 - val_accuracy: 0.8672\n","Epoch 163/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4118 - accuracy: 0.8689 - val_loss: 0.4221 - val_accuracy: 0.8664\n","Epoch 164/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4099 - accuracy: 0.8693 - val_loss: 0.4179 - val_accuracy: 0.8708\n","Epoch 165/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4090 - accuracy: 0.8681 - val_loss: 0.4214 - val_accuracy: 0.8654\n","Epoch 166/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4106 - accuracy: 0.8679 - val_loss: 0.4198 - val_accuracy: 0.8695\n","Epoch 167/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4084 - accuracy: 0.8698 - val_loss: 0.4225 - val_accuracy: 0.8677\n","Epoch 168/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4073 - accuracy: 0.8692 - val_loss: 0.4236 - val_accuracy: 0.8682\n","Epoch 169/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4086 - accuracy: 0.8694 - val_loss: 0.4241 - val_accuracy: 0.8687\n","Epoch 170/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4061 - accuracy: 0.8687 - val_loss: 0.4211 - val_accuracy: 0.8705\n","Epoch 171/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4063 - accuracy: 0.8678 - val_loss: 0.4234 - val_accuracy: 0.8672\n","Epoch 172/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4064 - accuracy: 0.8702 - val_loss: 0.4237 - val_accuracy: 0.8691\n","Epoch 173/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4107 - accuracy: 0.8682 - val_loss: 0.4199 - val_accuracy: 0.8676\n","Epoch 174/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4028 - accuracy: 0.8704 - val_loss: 0.4255 - val_accuracy: 0.8661\n","Epoch 175/1000\n","42/42 [==============================] - 4s 96ms/step - loss: 0.4070 - accuracy: 0.8688 - val_loss: 0.4227 - val_accuracy: 0.8676\n","Epoch 176/1000\n","42/42 [==============================] - 4s 96ms/step - loss: 0.4053 - accuracy: 0.8692 - val_loss: 0.4280 - val_accuracy: 0.8653\n","Epoch 177/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4079 - accuracy: 0.8681 - val_loss: 0.4239 - val_accuracy: 0.8673\n","Epoch 178/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4092 - accuracy: 0.8685 - val_loss: 0.4290 - val_accuracy: 0.8668\n","Epoch 179/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4034 - accuracy: 0.8699 - val_loss: 0.4182 - val_accuracy: 0.8695\n","Epoch 180/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4008 - accuracy: 0.8690 - val_loss: 0.4254 - val_accuracy: 0.8662\n","Epoch 181/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4023 - accuracy: 0.8699 - val_loss: 0.4211 - val_accuracy: 0.8672\n","Epoch 182/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4025 - accuracy: 0.8693 - val_loss: 0.4286 - val_accuracy: 0.8654\n","Epoch 183/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4027 - accuracy: 0.8698 - val_loss: 0.4291 - val_accuracy: 0.8663\n","Epoch 184/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4010 - accuracy: 0.8715 - val_loss: 0.4207 - val_accuracy: 0.8673\n","Epoch 185/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4013 - accuracy: 0.8700 - val_loss: 0.4219 - val_accuracy: 0.8679\n","Epoch 186/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4036 - accuracy: 0.8700 - val_loss: 0.4238 - val_accuracy: 0.8677\n","Epoch 187/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4012 - accuracy: 0.8710 - val_loss: 0.4204 - val_accuracy: 0.8685\n","Epoch 188/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3954 - accuracy: 0.8721 - val_loss: 0.4219 - val_accuracy: 0.8681\n","Epoch 189/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3992 - accuracy: 0.8712 - val_loss: 0.4268 - val_accuracy: 0.8650\n","Epoch 190/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4022 - accuracy: 0.8707 - val_loss: 0.4214 - val_accuracy: 0.8706\n","Epoch 191/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4000 - accuracy: 0.8704 - val_loss: 0.4198 - val_accuracy: 0.8688\n","Epoch 192/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4037 - accuracy: 0.8684 - val_loss: 0.4253 - val_accuracy: 0.8670\n","Epoch 193/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4002 - accuracy: 0.8702 - val_loss: 0.4222 - val_accuracy: 0.8679\n","Epoch 194/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4006 - accuracy: 0.8711 - val_loss: 0.4192 - val_accuracy: 0.8686\n","Epoch 195/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3978 - accuracy: 0.8700 - val_loss: 0.4211 - val_accuracy: 0.8668\n","Epoch 196/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4015 - accuracy: 0.8697 - val_loss: 0.4245 - val_accuracy: 0.8684\n","Epoch 197/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4006 - accuracy: 0.8709 - val_loss: 0.4226 - val_accuracy: 0.8683\n","Epoch 198/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3971 - accuracy: 0.8712 - val_loss: 0.4238 - val_accuracy: 0.8675\n","Epoch 199/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3985 - accuracy: 0.8718 - val_loss: 0.4215 - val_accuracy: 0.8698\n","Epoch 200/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3996 - accuracy: 0.8710 - val_loss: 0.4237 - val_accuracy: 0.8690\n","Epoch 201/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3954 - accuracy: 0.8727 - val_loss: 0.4221 - val_accuracy: 0.8678\n","Epoch 202/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3966 - accuracy: 0.8718 - val_loss: 0.4242 - val_accuracy: 0.8671\n","Epoch 203/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3963 - accuracy: 0.8721 - val_loss: 0.4224 - val_accuracy: 0.8695\n","Epoch 204/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3976 - accuracy: 0.8719 - val_loss: 0.4217 - val_accuracy: 0.8708\n","Epoch 205/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3975 - accuracy: 0.8713 - val_loss: 0.4275 - val_accuracy: 0.8672\n","Epoch 206/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3986 - accuracy: 0.8714 - val_loss: 0.4254 - val_accuracy: 0.8678\n","Epoch 207/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3956 - accuracy: 0.8721 - val_loss: 0.4211 - val_accuracy: 0.8682\n","Epoch 208/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3916 - accuracy: 0.8729 - val_loss: 0.4222 - val_accuracy: 0.8687\n","Epoch 209/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3967 - accuracy: 0.8708 - val_loss: 0.4223 - val_accuracy: 0.8669\n","Epoch 210/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.3964 - accuracy: 0.8715 - val_loss: 0.4181 - val_accuracy: 0.8689\n","Epoch 211/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3953 - accuracy: 0.8722 - val_loss: 0.4184 - val_accuracy: 0.8700\n","Epoch 212/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3916 - accuracy: 0.8726 - val_loss: 0.4242 - val_accuracy: 0.8669\n","Epoch 213/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.3972 - accuracy: 0.8722 - val_loss: 0.4269 - val_accuracy: 0.8663\n","Epoch 214/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.3975 - accuracy: 0.8700 - val_loss: 0.4208 - val_accuracy: 0.8699\n","Epoch 00214: early stopping\n","13/13 [==============================] - 0s 11ms/step\n","######### Training on Fold 1  #############\n","Epoch 1/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 1.9270 - accuracy: 0.3503 - val_loss: 1.6899 - val_accuracy: 0.4063\n","Epoch 2/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 1.7101 - accuracy: 0.3767 - val_loss: 1.6670 - val_accuracy: 0.4712\n","Epoch 3/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 1.6672 - accuracy: 0.3960 - val_loss: 1.6057 - val_accuracy: 0.4722\n","Epoch 4/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 1.5944 - accuracy: 0.4641 - val_loss: 1.4177 - val_accuracy: 0.6413\n","Epoch 5/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 1.3213 - accuracy: 0.6228 - val_loss: 1.0021 - val_accuracy: 0.7145\n","Epoch 6/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 1.0433 - accuracy: 0.7038 - val_loss: 0.8629 - val_accuracy: 0.7431\n","Epoch 7/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.9186 - accuracy: 0.7380 - val_loss: 0.7879 - val_accuracy: 0.7724\n","Epoch 8/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.8562 - accuracy: 0.7526 - val_loss: 0.7347 - val_accuracy: 0.7841\n","Epoch 9/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.8182 - accuracy: 0.7614 - val_loss: 0.7275 - val_accuracy: 0.7887\n","Epoch 10/1000\n","42/42 [==============================] - 4s 88ms/step - loss: 0.7692 - accuracy: 0.7749 - val_loss: 0.6703 - val_accuracy: 0.8102\n","Epoch 11/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.7336 - accuracy: 0.7837 - val_loss: 0.6432 - val_accuracy: 0.8141\n","Epoch 12/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.7047 - accuracy: 0.7945 - val_loss: 0.6187 - val_accuracy: 0.8211\n","Epoch 13/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.6756 - accuracy: 0.8047 - val_loss: 0.5972 - val_accuracy: 0.8263\n","Epoch 14/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.6426 - accuracy: 0.8137 - val_loss: 0.5544 - val_accuracy: 0.8374\n","Epoch 15/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.6150 - accuracy: 0.8224 - val_loss: 0.5339 - val_accuracy: 0.8423\n","Epoch 16/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5937 - accuracy: 0.8268 - val_loss: 0.5140 - val_accuracy: 0.8486\n","Epoch 17/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5762 - accuracy: 0.8319 - val_loss: 0.5091 - val_accuracy: 0.8473\n","Epoch 18/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5699 - accuracy: 0.8341 - val_loss: 0.5027 - val_accuracy: 0.8495\n","Epoch 19/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.5608 - accuracy: 0.8348 - val_loss: 0.4957 - val_accuracy: 0.8506\n","Epoch 20/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5530 - accuracy: 0.8378 - val_loss: 0.4911 - val_accuracy: 0.8510\n","Epoch 21/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5421 - accuracy: 0.8399 - val_loss: 0.4918 - val_accuracy: 0.8510\n","Epoch 22/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5368 - accuracy: 0.8419 - val_loss: 0.4827 - val_accuracy: 0.8580\n","Epoch 23/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.5283 - accuracy: 0.8438 - val_loss: 0.4794 - val_accuracy: 0.8559\n","Epoch 24/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5255 - accuracy: 0.8438 - val_loss: 0.4763 - val_accuracy: 0.8582\n","Epoch 25/1000\n","42/42 [==============================] - 3s 82ms/step - loss: 0.5262 - accuracy: 0.8440 - val_loss: 0.4783 - val_accuracy: 0.8559\n","Epoch 26/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5192 - accuracy: 0.8458 - val_loss: 0.4712 - val_accuracy: 0.8592\n","Epoch 27/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5147 - accuracy: 0.8464 - val_loss: 0.4655 - val_accuracy: 0.8582\n","Epoch 28/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.5139 - accuracy: 0.8476 - val_loss: 0.4681 - val_accuracy: 0.8589\n","Epoch 29/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5091 - accuracy: 0.8474 - val_loss: 0.4612 - val_accuracy: 0.8598\n","Epoch 30/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.5073 - accuracy: 0.8484 - val_loss: 0.4633 - val_accuracy: 0.8591\n","Epoch 31/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.5014 - accuracy: 0.8489 - val_loss: 0.4662 - val_accuracy: 0.8580\n","Epoch 32/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4995 - accuracy: 0.8486 - val_loss: 0.4617 - val_accuracy: 0.8582\n","Epoch 33/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4981 - accuracy: 0.8504 - val_loss: 0.4573 - val_accuracy: 0.8616\n","Epoch 34/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4953 - accuracy: 0.8521 - val_loss: 0.4565 - val_accuracy: 0.8617\n","Epoch 35/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4925 - accuracy: 0.8505 - val_loss: 0.4555 - val_accuracy: 0.8625\n","Epoch 36/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4887 - accuracy: 0.8518 - val_loss: 0.4596 - val_accuracy: 0.8591\n","Epoch 37/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4904 - accuracy: 0.8522 - val_loss: 0.4729 - val_accuracy: 0.8607\n","Epoch 38/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4855 - accuracy: 0.8526 - val_loss: 0.4503 - val_accuracy: 0.8630\n","Epoch 39/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4880 - accuracy: 0.8529 - val_loss: 0.4484 - val_accuracy: 0.8646\n","Epoch 40/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4825 - accuracy: 0.8541 - val_loss: 0.4485 - val_accuracy: 0.8633\n","Epoch 41/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4803 - accuracy: 0.8547 - val_loss: 0.4485 - val_accuracy: 0.8619\n","Epoch 42/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4765 - accuracy: 0.8545 - val_loss: 0.4517 - val_accuracy: 0.8633\n","Epoch 43/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4786 - accuracy: 0.8558 - val_loss: 0.4498 - val_accuracy: 0.8633\n","Epoch 44/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4756 - accuracy: 0.8555 - val_loss: 0.4485 - val_accuracy: 0.8620\n","Epoch 45/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4742 - accuracy: 0.8550 - val_loss: 0.4470 - val_accuracy: 0.8639\n","Epoch 46/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4761 - accuracy: 0.8545 - val_loss: 0.4485 - val_accuracy: 0.8616\n","Epoch 47/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4710 - accuracy: 0.8571 - val_loss: 0.4377 - val_accuracy: 0.8650\n","Epoch 48/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4682 - accuracy: 0.8569 - val_loss: 0.4403 - val_accuracy: 0.8650\n","Epoch 49/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4681 - accuracy: 0.8575 - val_loss: 0.4475 - val_accuracy: 0.8623\n","Epoch 50/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4719 - accuracy: 0.8555 - val_loss: 0.4422 - val_accuracy: 0.8641\n","Epoch 51/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4650 - accuracy: 0.8576 - val_loss: 0.4417 - val_accuracy: 0.8634\n","Epoch 52/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4583 - accuracy: 0.8597 - val_loss: 0.4413 - val_accuracy: 0.8656\n","Epoch 53/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4616 - accuracy: 0.8596 - val_loss: 0.4392 - val_accuracy: 0.8646\n","Epoch 54/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4602 - accuracy: 0.8585 - val_loss: 0.4444 - val_accuracy: 0.8630\n","Epoch 55/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4628 - accuracy: 0.8583 - val_loss: 0.4358 - val_accuracy: 0.8683\n","Epoch 56/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4610 - accuracy: 0.8568 - val_loss: 0.4406 - val_accuracy: 0.8641\n","Epoch 57/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4596 - accuracy: 0.8601 - val_loss: 0.4358 - val_accuracy: 0.8649\n","Epoch 58/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4567 - accuracy: 0.8595 - val_loss: 0.4340 - val_accuracy: 0.8685\n","Epoch 59/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4572 - accuracy: 0.8606 - val_loss: 0.4387 - val_accuracy: 0.8632\n","Epoch 60/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4553 - accuracy: 0.8594 - val_loss: 0.4403 - val_accuracy: 0.8674\n","Epoch 61/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4571 - accuracy: 0.8603 - val_loss: 0.4415 - val_accuracy: 0.8631\n","Epoch 62/1000\n","42/42 [==============================] - 4s 90ms/step - loss: 0.4528 - accuracy: 0.8596 - val_loss: 0.4348 - val_accuracy: 0.8650\n","Epoch 63/1000\n","42/42 [==============================] - 4s 97ms/step - loss: 0.4533 - accuracy: 0.8609 - val_loss: 0.4343 - val_accuracy: 0.8642\n","Epoch 64/1000\n","42/42 [==============================] - 4s 95ms/step - loss: 0.4502 - accuracy: 0.8606 - val_loss: 0.4382 - val_accuracy: 0.8650\n","Epoch 65/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4544 - accuracy: 0.8595 - val_loss: 0.4345 - val_accuracy: 0.8651\n","Epoch 66/1000\n","42/42 [==============================] - 4s 97ms/step - loss: 0.4502 - accuracy: 0.8612 - val_loss: 0.4338 - val_accuracy: 0.8648\n","Epoch 67/1000\n","42/42 [==============================] - 4s 92ms/step - loss: 0.4521 - accuracy: 0.8607 - val_loss: 0.4366 - val_accuracy: 0.8646\n","Epoch 68/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4502 - accuracy: 0.8605 - val_loss: 0.4311 - val_accuracy: 0.8668\n","Epoch 69/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4478 - accuracy: 0.8619 - val_loss: 0.4331 - val_accuracy: 0.8666\n","Epoch 70/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4467 - accuracy: 0.8606 - val_loss: 0.4350 - val_accuracy: 0.8648\n","Epoch 71/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4480 - accuracy: 0.8627 - val_loss: 0.4307 - val_accuracy: 0.8692\n","Epoch 72/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4444 - accuracy: 0.8625 - val_loss: 0.4380 - val_accuracy: 0.8649\n","Epoch 73/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4463 - accuracy: 0.8624 - val_loss: 0.4313 - val_accuracy: 0.8672\n","Epoch 74/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4482 - accuracy: 0.8614 - val_loss: 0.4310 - val_accuracy: 0.8678\n","Epoch 75/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4446 - accuracy: 0.8620 - val_loss: 0.4284 - val_accuracy: 0.8668\n","Epoch 76/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4443 - accuracy: 0.8621 - val_loss: 0.4271 - val_accuracy: 0.8713\n","Epoch 77/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4423 - accuracy: 0.8637 - val_loss: 0.4305 - val_accuracy: 0.8692\n","Epoch 78/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4427 - accuracy: 0.8636 - val_loss: 0.4309 - val_accuracy: 0.8682\n","Epoch 79/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4424 - accuracy: 0.8637 - val_loss: 0.4294 - val_accuracy: 0.8673\n","Epoch 80/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4396 - accuracy: 0.8633 - val_loss: 0.4279 - val_accuracy: 0.8676\n","Epoch 81/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4410 - accuracy: 0.8639 - val_loss: 0.4310 - val_accuracy: 0.8663\n","Epoch 82/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4438 - accuracy: 0.8625 - val_loss: 0.4240 - val_accuracy: 0.8689\n","Epoch 83/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4395 - accuracy: 0.8647 - val_loss: 0.4261 - val_accuracy: 0.8692\n","Epoch 84/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4364 - accuracy: 0.8635 - val_loss: 0.4296 - val_accuracy: 0.8695\n","Epoch 85/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4408 - accuracy: 0.8647 - val_loss: 0.4309 - val_accuracy: 0.8675\n","Epoch 86/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4373 - accuracy: 0.8632 - val_loss: 0.4293 - val_accuracy: 0.8680\n","Epoch 87/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4376 - accuracy: 0.8627 - val_loss: 0.4273 - val_accuracy: 0.8664\n","Epoch 88/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4410 - accuracy: 0.8643 - val_loss: 0.4252 - val_accuracy: 0.8687\n","Epoch 89/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4361 - accuracy: 0.8642 - val_loss: 0.4231 - val_accuracy: 0.8687\n","Epoch 90/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4325 - accuracy: 0.8658 - val_loss: 0.4239 - val_accuracy: 0.8681\n","Epoch 91/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4331 - accuracy: 0.8651 - val_loss: 0.4274 - val_accuracy: 0.8678\n","Epoch 92/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4353 - accuracy: 0.8648 - val_loss: 0.4240 - val_accuracy: 0.8711\n","Epoch 93/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4345 - accuracy: 0.8645 - val_loss: 0.4256 - val_accuracy: 0.8680\n","Epoch 94/1000\n","42/42 [==============================] - 4s 95ms/step - loss: 0.4306 - accuracy: 0.8669 - val_loss: 0.4252 - val_accuracy: 0.8685\n","Epoch 95/1000\n","42/42 [==============================] - 4s 90ms/step - loss: 0.4352 - accuracy: 0.8642 - val_loss: 0.4282 - val_accuracy: 0.8711\n","Epoch 96/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4318 - accuracy: 0.8656 - val_loss: 0.4235 - val_accuracy: 0.8696\n","Epoch 97/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4274 - accuracy: 0.8678 - val_loss: 0.4350 - val_accuracy: 0.8644\n","Epoch 98/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4313 - accuracy: 0.8662 - val_loss: 0.4241 - val_accuracy: 0.8680\n","Epoch 99/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4264 - accuracy: 0.8668 - val_loss: 0.4264 - val_accuracy: 0.8690\n","Epoch 100/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4306 - accuracy: 0.8650 - val_loss: 0.4247 - val_accuracy: 0.8690\n","Epoch 101/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4292 - accuracy: 0.8661 - val_loss: 0.4251 - val_accuracy: 0.8698\n","Epoch 102/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4274 - accuracy: 0.8653 - val_loss: 0.4245 - val_accuracy: 0.8697\n","Epoch 103/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4266 - accuracy: 0.8666 - val_loss: 0.4257 - val_accuracy: 0.8672\n","Epoch 104/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4294 - accuracy: 0.8649 - val_loss: 0.4226 - val_accuracy: 0.8681\n","Epoch 105/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4267 - accuracy: 0.8669 - val_loss: 0.4253 - val_accuracy: 0.8710\n","Epoch 106/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4258 - accuracy: 0.8676 - val_loss: 0.4238 - val_accuracy: 0.8702\n","Epoch 107/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4253 - accuracy: 0.8667 - val_loss: 0.4222 - val_accuracy: 0.8696\n","Epoch 108/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4246 - accuracy: 0.8681 - val_loss: 0.4232 - val_accuracy: 0.8714\n","Epoch 109/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4247 - accuracy: 0.8672 - val_loss: 0.4223 - val_accuracy: 0.8684\n","Epoch 110/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4248 - accuracy: 0.8664 - val_loss: 0.4243 - val_accuracy: 0.8691\n","Epoch 111/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4239 - accuracy: 0.8684 - val_loss: 0.4256 - val_accuracy: 0.8677\n","Epoch 112/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4226 - accuracy: 0.8670 - val_loss: 0.4228 - val_accuracy: 0.8694\n","Epoch 113/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4238 - accuracy: 0.8664 - val_loss: 0.4240 - val_accuracy: 0.8711\n","Epoch 114/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4228 - accuracy: 0.8664 - val_loss: 0.4251 - val_accuracy: 0.8694\n","Epoch 115/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4264 - accuracy: 0.8660 - val_loss: 0.4243 - val_accuracy: 0.8683\n","Epoch 116/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4202 - accuracy: 0.8674 - val_loss: 0.4228 - val_accuracy: 0.8710\n","Epoch 117/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4215 - accuracy: 0.8671 - val_loss: 0.4186 - val_accuracy: 0.8695\n","Epoch 118/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4213 - accuracy: 0.8678 - val_loss: 0.4250 - val_accuracy: 0.8700\n","Epoch 119/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4177 - accuracy: 0.8686 - val_loss: 0.4181 - val_accuracy: 0.8722\n","Epoch 120/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4219 - accuracy: 0.8679 - val_loss: 0.4229 - val_accuracy: 0.8687\n","Epoch 121/1000\n","42/42 [==============================] - 3s 83ms/step - loss: 0.4164 - accuracy: 0.8682 - val_loss: 0.4226 - val_accuracy: 0.8706\n","Epoch 122/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4190 - accuracy: 0.8679 - val_loss: 0.4199 - val_accuracy: 0.8713\n","Epoch 123/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4197 - accuracy: 0.8682 - val_loss: 0.4197 - val_accuracy: 0.8672\n","Epoch 124/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4211 - accuracy: 0.8680 - val_loss: 0.4166 - val_accuracy: 0.8704\n","Epoch 125/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4187 - accuracy: 0.8682 - val_loss: 0.4202 - val_accuracy: 0.8678\n","Epoch 126/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4201 - accuracy: 0.8673 - val_loss: 0.4168 - val_accuracy: 0.8700\n","Epoch 127/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4197 - accuracy: 0.8680 - val_loss: 0.4206 - val_accuracy: 0.8710\n","Epoch 128/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4215 - accuracy: 0.8676 - val_loss: 0.4258 - val_accuracy: 0.8694\n","Epoch 129/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4197 - accuracy: 0.8675 - val_loss: 0.4234 - val_accuracy: 0.8693\n","Epoch 130/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4151 - accuracy: 0.8689 - val_loss: 0.4152 - val_accuracy: 0.8712\n","Epoch 131/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4133 - accuracy: 0.8684 - val_loss: 0.4235 - val_accuracy: 0.8691\n","Epoch 132/1000\n","42/42 [==============================] - 4s 87ms/step - loss: 0.4151 - accuracy: 0.8692 - val_loss: 0.4217 - val_accuracy: 0.8700\n","Epoch 133/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4123 - accuracy: 0.8702 - val_loss: 0.4204 - val_accuracy: 0.8715\n","Epoch 134/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4120 - accuracy: 0.8706 - val_loss: 0.4258 - val_accuracy: 0.8685\n","Epoch 135/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4123 - accuracy: 0.8713 - val_loss: 0.4183 - val_accuracy: 0.8701\n","Epoch 136/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4171 - accuracy: 0.8683 - val_loss: 0.4220 - val_accuracy: 0.8699\n","Epoch 137/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4143 - accuracy: 0.8696 - val_loss: 0.4178 - val_accuracy: 0.8702\n","Epoch 138/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4095 - accuracy: 0.8701 - val_loss: 0.4212 - val_accuracy: 0.8689\n","Epoch 139/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4154 - accuracy: 0.8686 - val_loss: 0.4184 - val_accuracy: 0.8703\n","Epoch 140/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4118 - accuracy: 0.8707 - val_loss: 0.4196 - val_accuracy: 0.8688\n","Epoch 141/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4160 - accuracy: 0.8700 - val_loss: 0.4197 - val_accuracy: 0.8694\n","Epoch 142/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4101 - accuracy: 0.8685 - val_loss: 0.4182 - val_accuracy: 0.8697\n","Epoch 143/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4103 - accuracy: 0.8699 - val_loss: 0.4191 - val_accuracy: 0.8694\n","Epoch 144/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4119 - accuracy: 0.8693 - val_loss: 0.4203 - val_accuracy: 0.8699\n","Epoch 145/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4096 - accuracy: 0.8705 - val_loss: 0.4211 - val_accuracy: 0.8701\n","Epoch 146/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4101 - accuracy: 0.8693 - val_loss: 0.4222 - val_accuracy: 0.8679\n","Epoch 147/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4140 - accuracy: 0.8682 - val_loss: 0.4180 - val_accuracy: 0.8698\n","Epoch 148/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4091 - accuracy: 0.8699 - val_loss: 0.4198 - val_accuracy: 0.8687\n","Epoch 149/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4119 - accuracy: 0.8688 - val_loss: 0.4190 - val_accuracy: 0.8710\n","Epoch 150/1000\n","42/42 [==============================] - 4s 91ms/step - loss: 0.4051 - accuracy: 0.8718 - val_loss: 0.4196 - val_accuracy: 0.8715\n","Epoch 151/1000\n","42/42 [==============================] - 4s 106ms/step - loss: 0.4121 - accuracy: 0.8700 - val_loss: 0.4162 - val_accuracy: 0.8714\n","Epoch 152/1000\n","42/42 [==============================] - 4s 99ms/step - loss: 0.4094 - accuracy: 0.8712 - val_loss: 0.4184 - val_accuracy: 0.8706\n","Epoch 153/1000\n","42/42 [==============================] - 4s 93ms/step - loss: 0.4057 - accuracy: 0.8714 - val_loss: 0.4151 - val_accuracy: 0.8718\n","Epoch 154/1000\n","42/42 [==============================] - 4s 94ms/step - loss: 0.4057 - accuracy: 0.8713 - val_loss: 0.4212 - val_accuracy: 0.8683\n","Epoch 155/1000\n","42/42 [==============================] - 4s 93ms/step - loss: 0.4056 - accuracy: 0.8715 - val_loss: 0.4229 - val_accuracy: 0.8704\n","Epoch 156/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4077 - accuracy: 0.8706 - val_loss: 0.4242 - val_accuracy: 0.8700\n","Epoch 157/1000\n","42/42 [==============================] - 4s 86ms/step - loss: 0.4030 - accuracy: 0.8723 - val_loss: 0.4161 - val_accuracy: 0.8700\n","Epoch 158/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4055 - accuracy: 0.8708 - val_loss: 0.4149 - val_accuracy: 0.8705\n","Epoch 159/1000\n","42/42 [==============================] - 4s 85ms/step - loss: 0.4090 - accuracy: 0.8707 - val_loss: 0.4165 - val_accuracy: 0.8716\n","Epoch 160/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4059 - accuracy: 0.8721 - val_loss: 0.4189 - val_accuracy: 0.8712\n","Epoch 161/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4095 - accuracy: 0.8699 - val_loss: 0.4149 - val_accuracy: 0.8740\n","Epoch 162/1000\n","42/42 [==============================] - 4s 84ms/step - loss: 0.4013 - accuracy: 0.8722 - val_loss: 0.4214 - val_accuracy: 0.8695\n","Epoch 163/1000\n","42/42 [==============================] - 4s 83ms/step - loss: 0.4070 - accuracy: 0.8712 - val_loss: 0.4122 - val_accuracy: 0.8720\n","Epoch 164/1000\n","26/42 [=================>............] - ETA: 1s - loss: 0.4032 - accuracy: 0.8722Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AZYVQqHigQHa","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-qLuHP0jgQ8P","colab_type":"code","colab":{}},"source":["!mkdir '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_CNN_RONNY'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LT2Y7wuWgx6I","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599547996760,"user_tz":0,"elapsed":5461,"user":{"displayName":"Ronny Polle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSUHi8xY87CD_SAU1iZlf4pZkMVcGnWvyQr3uhhQ=s64","userId":"03851089912616657277"}}},"source":["!cp 0_fold0.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_CNN_RONNY' \n","!cp 0_fold1.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_CNN_RONNY' \n","!cp 0_fold2.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_CNN_RONNY' \n","!cp 0_fold3.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_CNN_RONNY' \n","!cp 0_fold4.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_CNN_RONNY' \n","!cp 0_main.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_CNN_RONNY' "],"execution_count":19,"outputs":[]}]}