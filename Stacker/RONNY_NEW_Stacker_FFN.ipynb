{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RONNY_NEW_Stacker_FFN.ipynb","provenance":[{"file_id":"1FXi3zbfBALx2XXt1jIIKwQNEDHamDAF5","timestamp":1599517612626},{"file_id":"1Rq3CggdBxoUZfFxO5ltiJuMAW9ZfP2eo","timestamp":1599461231248},{"file_id":"1VyIF-R13cftYaFnZuZiWNIGO7Cv4w1Iv","timestamp":1599418520736}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KOnYzVBxcT93","colab_type":"code","colab":{}},"source":["!pip install --upgrade pandas==0.25.3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3arOHSJwCtNq","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3a3kmo_dFfJ","colab_type":"code","colab":{}},"source":["#import necessary dependecies\n","import plotly.express as px\n","import seaborn as sns\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier,ExtraTreesClassifier,VotingClassifier\n"," \n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.cluster import KMeans\n","import math\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.pipeline import Pipeline\n","import os\n","import warnings\n","import numpy as np  \n","import seaborn as sns\n","import pandas as pd, os, gc\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc, log_loss\n","from sklearn.feature_selection import mutual_info_classif\n","from sklearn.preprocessing import StandardScaler, RobustScaler\n","%matplotlib inline\n","warnings.filterwarnings('ignore')\n","from typing import List\n","import tensorflow as tf\n","import random\n","from tqdm import tqdm \n","import copy\n"," \n","tf.random.set_seed(111)\n","np.random.seed(111)\n","random.seed(111)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nrGyB3OIzd78","colab_type":"code","colab":{}},"source":["import keras\n","from keras.layers import *\n","from keras.optimizers import Adam\n","from keras.models import Model\n","from keras.initializers import glorot_normal\n","from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n","from keras.regularizers import l2\n","\n","def get_model_ffn(): \n","\n","  tf.random.set_seed(1)\n","  np.random.seed(1)\n","  random.seed(1)\n","\n","  input_tensor = Input(shape=(df_train.shape[1],))\n","\n","  x = Dense(32, kernel_initializer='uniform', activation='relu')(input_tensor)\n","\n","  x = Dense(64, kernel_initializer='uniform', activation ='relu')(x)\n","\n","  x = Dense(128, kernel_initializer='uniform', activation ='relu')(x)\n","\n","  # added skip connections - you can remove them and train to see\n","\n","  x = add([x, Dense(128, activation='relu')(x)])\n","  x = add([x, Dense(128, activation='relu')(x)])\n","\n","  x = Dropout(0.2)(x)\n","\n","  out = Dense(21,kernel_initializer=glorot_normal(seed=1),\n","              bias_initializer=glorot_normal(seed=1),\n","              activation=\"softmax\")(x)\n","\n","  model = Model(inputs=input_tensor,outputs =out)\n","\n","  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hHXGrWSwdpQp","colab_type":"code","colab":{}},"source":["from sklearn.multiclass import OneVsRestClassifier,OneVsOneClassifier\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n","from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,AdaBoostClassifier,GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import GridSearchCV,StratifiedKFold\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.pipeline import make_pipeline\n","from sklearn.impute import SimpleImputer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j4sxXpQoHqFu","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder,StandardScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3ZCXtzKDiDe","colab_type":"code","colab":{}},"source":["train_ = pd.read_csv('/content/drive/My Drive/ZimnatInsurance/Train.csv')\n","test_ = pd.read_csv('/content/drive/My Drive/ZimnatInsurance/Test.csv')\n","submission_ = pd.read_csv('/content/drive/My Drive/ZimnatInsurance/SampleSubmission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rx1uOaRsGG2M","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import KFold,GroupKFold\n","\n","def get_train_test_names(train_, test_, submission_):\n","  kf = KFold(n_splits=5, shuffle=False)\n","  for r, (train_index, test_index) in enumerate(kf.split(train_)):\n","    test = train_.iloc[test_index]\n","\n","    X_test = []\n","    X_test_columns = test.columns\n","    for v in test.values:\n","      info = v[:8]\n","      binary = v[8:]\n","      index = [k for k, i in enumerate(binary) if i == 1]\n","      for i in index:\n","        for k in range(len(binary)):\n","          if k == i:\n","            binary_transformed = list(copy.copy(binary))\n","            binary_transformed[i] = 0\n","            X_test.append(list(info) + binary_transformed)\n","\n","    X_test = pd.DataFrame(X_test)\n","    X_test.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n","          'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n","          '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n","          'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3']\n","    X_test['ID'] = [str(r)+'_'+str(i) for i in range(X_test.shape[0])]\n","\n","    yield train_.iloc[train_index], X_test, submission_, '0_fold' + str(r) + '.csv'\n","  yield train_, test_, submission_, '0_main.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pq9Hzf6Ms0BH","colab_type":"code","colab":{}},"source":["def process(df):\n","  binary_features = []\n","  df['IS_30H5'] = df['branch_code'] == '30H5'\n","  df['IS_30H5'] = df['IS_30H5'].astype('int')\n","\n","  df['IS_748L'] = df['branch_code'] == '748L'\n","  df['IS_748L'] = df['IS_748L'].astype('int')\n","\n","  df['IS_1X1H'] = df['branch_code'] == '1X1H'\n","  df['IS_1X1H'] = df['IS_1X1H'].astype('int')\n","\n","  df['IS_XX25'] = df['branch_code'] == 'XX25'\n","  df['IS_XX25'] = df['IS_XX25'].astype('int')\n","\n","  df['IS_O67J'] = df['branch_code'] == 'O67J'\n","  df['IS_O67J'] = df['IS_O67J'].astype('int')\n","\n","  df['IS_BOAS'] = df['branch_code'] == 'BOAS'\n","  df['IS_BOAS'] = df['IS_BOAS'].astype('int')\n","  \n","  df['IS_90QI'] = df['occupation_category_code'] == '90QI'\n","  df['IS_90QI'] = df['IS_90QI'].astype('int')\n","\n","  df['IS_56SI'] = df['occupation_category_code'] == '56SI'\n","  df['IS_56SI'] = df['IS_56SI'].astype('int')\n","\n","  \n","  \n","  df['IS_1982_1993_1984'] = df['birth_year'].apply(lambda x : 1 if x in [1993,1984,1982] else 0)\n","  df['IS_1982_1993_1984'] = df['IS_1982_1993_1984'].astype('int')\n","  \n","  #df['date3'] = df['date3'].astype('int')\n","  #df['IS_2019_2018'] = df['date3'].apply(lambda x : 1 if x in [2019,2018] else 0)\n","  #df['IS_2019_2018'] = df['IS_2019_2018'].astype('int')\n","  \n","  df['join_month'] = df['join_month'].astype('int')\n","  df['IS_5_4'] = df['join_month'].apply(lambda x : 1 if x in [4,5] else 0)\n","  df['IS_5_4'] = df['IS_5_4'].astype('int')\n","  \n","  df['age'] = df['age'].astype('int')\n","  df['IS_33_34_to_38'] = df['age'].apply(lambda x : 1 if x in [33,34,35,36,37,38] else 0)\n","  df['IS_33_34_to_38'] = df['IS_33_34_to_38'].astype('int')\n","\n","\n","  #df['IS_2019_2018_and_748L'] = df.apply(lambda x : 1 if (x['branch_code']=='748L' and x['date3'] in [2019,2018])  else 0 ,axis=1)\n","  \n","  #df['IS_2019_2018_and_T4MS'] = df.apply(lambda x : 1 if (x['occupation_category_code']=='90QI' and x['date3'] in [2019,2018])  else 0,axis=1)\n","\n","  df['IS_1993_1982_1984_and_748L'] = df.apply(lambda x : 1 if (x['branch_code']=='748L' and x['birth_year'] in [1993,1984,1982])  else 0,axis=1)\n","  \n","\n","  df['IS_1993_1982_1984_and_T4MS'] = df.apply(lambda x : 1 if (x['occupation_category_code']=='90QI' and x['birth_year'] in [1993,1984,1982])  else 0,axis=1)\n","  \n","\n","  df['IS_1993_1982_1984_and_month4'] = df.apply(lambda x : 1 if (x['join_month']==4 and x['birth_year'] in [1993,1984,1982])  else 0,axis=1)\n","  df['IS_1993_1982_1984_and_month5'] = df.apply(lambda x : 1 if (x['join_month']==5 and x['birth_year'] in [1993,1984,1982])  else 0,axis=1)\n","  \n","\n","\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_ELVeoVgv3v","colab_type":"text"},"source":["### Get folds"]},{"cell_type":"code","metadata":{"id":"oxjj_QAfEyZw","colab_type":"code","colab":{}},"source":["for train, test, submission, name in get_train_test_names(train_, test_, submission_):\n","  X_train = []\n","  X_train_columns = train.columns\n","  c = 0\n","  for v in train.values:\n","    info = v[:8]\n","    binary = v[8:]\n","    index = [k for k, i in enumerate(binary) if i == 1]\n","    for i in index:\n","      c+=1\n","      for k in range(len(binary)):\n","        if k == i:\n","          binary_transformed = list(copy.copy(binary))\n","          binary_transformed[i] = 0\n","          X_train.append(list(info) + binary_transformed + [X_train_columns[8+k]] + [c])\n","\n","  X_train = pd.DataFrame(X_train)\n","  X_train.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n","        'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n","        '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n","        'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'product_pred', 'ID2']\n","\n","\n","  X_test = []\n","  true_values = []\n","  c = 0\n","  for v in test.values:\n","    c += 1\n","    info = v[:8]\n","    binary = v[8:]\n","    index = [k for k, i in enumerate(binary) if i == 1]\n","    X_test.append(list(info) + list(binary) + [c])\n","    for k in test.columns[8:][index]:\n","      true_values.append(v[0] + ' X ' + k)\n","\n","  X_test = pd.DataFrame(X_test)\n","  X_test.columns = ['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n","        'occupation_code', 'occupation_category_code', 'P5DA', 'RIBP', '8NN1',\n","        '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', 'N2MW', 'AHXO',\n","        'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', 'ECY3', 'ID2']\n","\n","\n","  features_train = []\n","  features_test = []\n","  columns = []\n","\n","  append_features = ['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ', 'LJR9', \n","  'N2MW', 'AHXO','BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', 'GHYX', \n","  'ECY3', 'ID', 'ID2', 'join_date', 'sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code',\n","  'birth_year']\n","  for v in append_features:\n","    features_train.append(X_train[v].values.reshape(-1, 1))\n","    features_test.append(X_test[v].values.reshape(-1, 1))\n","    columns.append(np.array([v]))\n","\n","  y_train = X_train[['product_pred']]\n","\n","\n","  features_train = np.concatenate(features_train, axis=1)\n","  features_test = np.concatenate(features_test, axis=1)\n","  columns = np.concatenate(np.array(columns))\n","\n","  X_train = pd.DataFrame(features_train)\n","  X_train.columns = columns\n","  X_test = pd.DataFrame(features_test)\n","  X_test.columns = columns\n","############################## fix code ##############################\n","  X_train.join_date = pd.to_datetime(X_train.join_date,)\n","  X_test.join_date = pd.to_datetime(X_test.join_date,)\n","\n","  X_train.join_date = pd.to_datetime(X_train.join_date, format=\"%Y-%m-%d\")\n","  X_test.join_date = pd.to_datetime(X_test.join_date, format=\"%Y-%m-%d\")\n","\n","  # new features\n","  X_train['num_products_subscribed'] = X_train.apply(lambda x : sum(x[X_train.columns[:21]]), axis = 1)\n","  X_train['join_month'] = X_train['join_date'].dt.month\n","  X_train['day_of_week'] = X_train['join_date'].dt.dayofweek\n","  X_train['day_of_week_name'] = X_train['join_date'].dt.weekday_name\n","  X_train['age'] = np.abs(X_train['join_date'].dt.year - X_train['birth_year'])\n","  X_train['join_time_elapsed'] = np.abs(2020 - X_train['join_date'].dt.year)\n","  X_train['current_age'] = np.abs(2020 - X_train['birth_year'])\n","  \n","  X_test['num_products_subscribed'] = X_test.apply(lambda x : sum(x[X_test.columns[:21]]), axis = 1)\n","  X_test['join_month'] = X_test['join_date'].dt.month\n","  X_test['day_of_week'] = X_test['join_date'].dt.dayofweek\n","  X_test['day_of_week_name'] = X_test['join_date'].dt.weekday_name\n","  X_test['join_time_elapsed'] = np.abs(2020 - X_test['join_date'].dt.year)\n","  X_test['age'] = np.abs( X_test['join_date'].dt.year - X_test['birth_year'])\n","  X_test['current_age'] = np.abs(2020 - X_test['birth_year'])\n","\n","\n","\n","        \n","  X_train = X_train.fillna(0)\n","  X_test = X_test.fillna(0)\n","  y_train = y_train.fillna(0)\n","\n","  X_train = process(X_train)\n","  X_test = process(X_test)\n","  \n","  # LABEL ENCODE\n","  enc = LabelEncoder()\n","  def encode_LE(train,test,cols,verbose=True):\n","    for col in cols:\n","  \n","      df_comb = pd.concat([train[col].astype('str'),test[col].astype('str')],axis=0)\n","      df_comb = enc.fit_transform(df_comb)\n","      nm = col\n","      if df_comb.max()>32000: \n","        train[nm] = df_comb[:len(train)].astype('int32')\n","        test[nm] = df_comb[len(train):].astype('int32')\n","      else:\n","        train[nm] = df_comb[:len(train)].astype('int16')\n","        test[nm] = df_comb[len(train):].astype('int16')\n","      del df_comb; x=gc.collect()\n","      if verbose: print(nm,', ',end='')\n","\n","  X_train.day_of_week_name = X_train.day_of_week_name.astype('str')\n","  X_test.day_of_week_name = X_test.day_of_week_name.astype('str')\n","  X_train.join_date = X_train.join_date.astype('str')\n","  X_test.join_date = X_test.join_date.astype('str')\n","\n","  data = X_train.append(X_test)\n","  for v in ['sex', 'marital_status', 'branch_code', 'occupation_code', 'occupation_category_code','day_of_week_name','join_date']:\n","    data.loc[:,v] = enc.fit_transform(data.loc[:,v])\n","  X_train = data[:X_train.shape[0]]\n","  X_test = data[-X_test.shape[0]:]\n","\n","  enc.fit(y_train.iloc[:,0])\n","  y_train = pd.DataFrame(enc.transform(y_train.iloc[:,0]))\n","  y_train.columns = ['target']\n","\n","  X = X_train.drop(['ID','ID2'], axis=1)\n","  test = X_test.drop(['ID','ID2'], axis=1)\n","\n","  scaler = StandardScaler()\n","  \n","  \n","  X[['age']] = scaler.fit_transform(X[['age']])\n","  test[['age']] = scaler.fit_transform(test[['age']])\n","  \n","\n","  X[['birth_year']] = scaler.fit_transform(X[['birth_year']])\n","  test[['birth_year']] = scaler.fit_transform(test[['birth_year']])\n","\n","\n","  df_train =X.values\n","  df_test = test.values\n","  y = y_train.target\n","\n","############################### MODELING CODE : PAY attention :) ######################################\n"," \n","  sk = StratifiedKFold(n_splits= 5,random_state=1,shuffle=True)\n","\n","  es = EarlyStopping(monitor =\"val_loss\", mode =\"min\", verbose =1, patience = 50)\n","    \n","  ffn_predictions = list()\n","  \n","  for fold, (train_idx, test_idx) in enumerate(sk.split(df_train,y)):\n","  \n","    model = get_model_ffn()\n","  \n","    print('######### Training on Fold %i  #############'%(fold+1))\n","    \n","    #print(model.summary())\n","  \n","    model.fit( \n","        df_train[train_idx],\n","        y[train_idx],\n","        validation_data =(df_train[test_idx], y[test_idx]),\n","        callbacks =[es],\n","        epochs = 1000,\n","        batch_size = 1024)\n","    \n","    preds = model.predict(df_test, batch_size= 1024, verbose =1)\n","    ffn_predictions.append(preds)\n","    \n","  # get preds :D\n","  proba = np.average(ffn_predictions, axis=0)\n","  y_test = pd.DataFrame(proba)\n","  y_test.columns = enc.inverse_transform(y_test.columns)\n","\n","  answer_mass = []\n","  for i in range(X_test.shape[0]):\n","    id = X_test['ID'].iloc[i]\n","    for c in y_test.columns:\n","      answer_mass.append([id + ' X ' + c, y_test[c].iloc[i]])\n","\n","  df_answer = pd.DataFrame(answer_mass)\n","  df_answer.columns = ['ID X PCODE', 'Label']\n","  for i in range(df_answer.shape[0]):\n","    if df_answer['ID X PCODE'].iloc[i] in true_values:\n","      df_answer['Label'].iloc[i] = 1.0\n","\n","  df_answer.reset_index(drop=True, inplace=True)\n","  df_answer.to_csv(name, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AZYVQqHigQHa","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-qLuHP0jgQ8P","colab_type":"code","colab":{}},"source":["!mkdir '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_FFN_RONNY'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LT2Y7wuWgx6I","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599566336240,"user_tz":0,"elapsed":3377,"user":{"displayName":"Ronny Polle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSUHi8xY87CD_SAU1iZlf4pZkMVcGnWvyQr3uhhQ=s64","userId":"03851089912616657277"}}},"source":["!cp 0_fold0.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_FFN_RONNY' \n","!cp 0_fold1.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_FFN_RONNY' \n","!cp 0_fold2.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_FFN_RONNY' \n","!cp 0_fold3.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_FFN_RONNY' \n","!cp 0_fold4.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_FFN_RONNY' \n","!cp 0_main.csv  '/content/drive/My Drive/ZimnatInsurance/Stack_NEW_FFN_RONNY' "],"execution_count":21,"outputs":[]}]}